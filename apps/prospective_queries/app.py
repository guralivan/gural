# -*- coding: utf-8 -*-
"""
–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ —Ä–∞—Å—á–µ—Ç–æ–º –≤—ã—Ä—É—á–∫–∏ –Ω–∞ –µ–¥–∏–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞
"""
import os
import sys
import json
import pandas as pd
import streamlit as st
from streamlit import column_config as cc
from pathlib import Path
import time
import re
from urllib.parse import quote

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ OpenAI
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ü–æ–∏—Å–∫ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –º–∏–Ω—É—Å —Å–ª–æ–≤–∞–º–∏
MINUS_WORDS_FILE = os.path.join(os.path.dirname(__file__), "minus_words.json")
# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–æ —Å–ª–æ–≤–∞–º–∏ –∏–∑ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ OpenAI
OPENAI_TYPOS_FILE = os.path.join(os.path.dirname(__file__), "openai_typos.json")
# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –±—Ä–µ–Ω–¥–æ–≤—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
BRAND_QUERIES_FILE = os.path.join(os.path.dirname(__file__), "brand_queries.json")
# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
ENGLISH_QUERIES_FILE = os.path.join(os.path.dirname(__file__), "english_queries.json")
# –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏
PROJECTS_DIR = os.path.join(os.path.dirname(__file__), "projects")
# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É projects, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
os.makedirs(PROJECTS_DIR, exist_ok=True)

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ OpenAI API –∫–ª—é—á–∞ –∏–∑ secrets.toml –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
if "openai_api_key" not in st.session_state:
    try:
        default_key = st.secrets.get('openai_api_key', '')
        if default_key:
            st.session_state['openai_api_key'] = default_key
    except:
        pass

def find_typos_in_data(df):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç —Å–ª–æ–≤–∞ —Å –æ—à–∏–±–∫–∞–º–∏ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    if df is None or df.empty or "–ó–∞–ø—Ä–æ—Å" not in df.columns:
        return []
    
    # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
    correct_words = {
        # –ü–ª–∞—Ç—å–µ
        '–ø–ª–∞—Ç—å–µ', '–ø–ª–∞—Ç—å—è', '–ø–ª–∞—Ç—å–∏—Ü–µ', '–ø–ª–∞—Ç—å–∏—Ü–∞',
        # –í–µ—á–µ—Ä–Ω–µ–µ
        '–≤–µ—á–µ—Ä–Ω–µ–µ', '–≤–µ—á–µ—Ä–Ω–∏–µ', '–≤–µ—á–µ—Ä–Ω–∏–π', '–≤–µ—á–µ—Ä–Ω—è—è', '–≤–µ—á–µ—Ä–Ω–∏–µ',
        # –ö—É—Ä—Ç–∫–∞
        '–∫—É—Ä—Ç–∫–∞', '–∫—É—Ä—Ç–∫–∏', '–∫—É—Ä—Ç–æ—á–∫–∞', '–∫—É—Ä—Ç–æ—á–∫–∏',
        # –ó–∏–º–∞
        '–∑–∏–º–Ω—è—è', '–∑–∏–º–Ω–∏–µ', '–∑–∏–º–Ω–∏–π', '–∑–∏–º–∞', '–∑–∏–º–Ω–µ–µ',
        # –®—É–±–∞
        '—à—É–±–∞', '—à—É–±—ã', '—à—É–±–∫–∞', '—à—É–±–∫–∏', '—à—É–±', '—à—É–±—É',
        # –ü—É—Ö–æ–≤–∏–∫
        '–ø—É—Ö–æ–≤–∏–∫', '–ø—É—Ö–æ–≤–∏–∫–∏',
        # –ñ–µ–Ω—Å–∫–∏–π
        '–∂–µ–Ω—Å–∫–∞—è', '–∂–µ–Ω—Å–∫–∏–π', '–∂–µ–Ω—Å–∫–∏–µ', '–∂–µ–Ω—Å–∫–æ–µ',
        # –û–±—É–≤—å
        '–æ–±—É–≤—å', '—Ç—É—Ñ–ª–∏', '–±–æ—Ç–∏–Ω–∫–∏', '–∫—Ä–æ—Å—Å–æ–≤–∫–∏', '—Å–∞–ø–æ–≥–∏',
        # –®—Ç–∞–Ω—ã/–±—Ä—é–∫–∏
        '—à—Ç–∞–Ω—ã', '–±—Ä—é–∫–∏', '–±—Ä—é–∫',
        # –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ
        '–¥–ª–∏–Ω–Ω—ã–µ', '–¥–ª–∏–Ω–Ω–æ–µ', '–¥–ª–∏–Ω–Ω—ã–π', '–¥–ª–∏–Ω–Ω–∞—è', '–¥–ª–∏–Ω–Ω—ã—Ö', '–¥–ª–∏–Ω–Ω—ã–º', '–¥–ª–∏–Ω–Ω—ã–º–∏',
        '–Ω–∞—Ä—è–¥–Ω–æ–µ', '–Ω–∞—Ä—è–¥–Ω—ã–µ', '–Ω–∞—Ä—è–¥–Ω—ã–π', '–Ω–∞—Ä—è–¥–Ω–∞—è', '–Ω–∞—Ä—è–¥–Ω—ã—Ö', '–Ω–∞—Ä—è–¥–Ω—ã–º', '–Ω–∞—Ä—è–¥–Ω—ã–º–∏',
        '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω–æ–µ', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–π', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω–∞—è', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã—Ö', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–º', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–º–∏',
        '–Ω–æ–≤–æ–≥–æ–¥–Ω–µ–µ', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏–µ', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏–π', '–Ω–æ–≤–æ–≥–æ–¥–Ω—è—è', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏—Ö', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏–º', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏–º–∏',
        '—Å—Ç–∏–ª—å–Ω–æ–µ', '—Å—Ç–∏–ª—å–Ω—ã–µ', '—Å—Ç–∏–ª—å–Ω—ã–π', '—Å—Ç–∏–ª—å–Ω–∞—è', '—Å—Ç–∏–ª—å–Ω—ã—Ö', '—Å—Ç–∏–ª—å–Ω—ã–º', '—Å—Ç–∏–ª—å–Ω—ã–º–∏',
        '–∫—Ä–∞—Å–∏–≤–æ–µ', '–∫—Ä–∞—Å–∏–≤—ã–µ', '–∫—Ä–∞—Å–∏–≤—ã–π', '–∫—Ä–∞—Å–∏–≤–∞—è', '–∫—Ä–∞—Å–∏–≤—ã—Ö', '–∫—Ä–∞—Å–∏–≤—ã–º', '–∫—Ä–∞—Å–∏–≤—ã–º–∏',
        '—á–µ—Ä–Ω–æ–µ', '—á–µ—Ä–Ω—ã–µ', '—á–µ—Ä–Ω—ã–π', '—á–µ—Ä–Ω–∞—è', '—á–µ—Ä–Ω—ã—Ö', '—á–µ—Ä–Ω—ã–º', '—á–µ—Ä–Ω—ã–º–∏',
        # –î–µ—Ç—Å–∫–∏–µ
        '–¥–µ—Ç—Å–∫–∏–µ', '–¥–µ—Ç—Å–∫–æ–µ', '–¥–µ—Ç—Å–∫–∏–π', '–¥–µ—Ç—Å–∫–∞—è', '–¥–µ—Ç—Å–∫–∏—Ö', '–¥–µ—Ç—Å–∫–∏–º', '–¥–µ—Ç—Å–∫–∏–º–∏',
        # –î—Ä—É–≥–∏–µ
        '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏', '–æ–¥–µ–∂–¥–∞', '–æ–¥–µ–∂–¥—É',
        '–Ω–∞—Ä—è–¥', '–Ω–∞—Ä—è–¥—ã', '–æ–±—Ä–∞–∑', '–æ–±—Ä–∞–∑—ã'
    }
    
    typos_found = set()
    queries = df["–ó–∞–ø—Ä–æ—Å"].astype(str).dropna().tolist()
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤
    all_words = set()
    for query in queries:
        query_lower = query.lower().strip('"')
        words = query_lower.split()
        all_words.update(words)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ
    for word in all_words:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ –∏ —á–∏—Å–ª–∞
        if len(word) < 3 or word.isdigit():
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        if word in correct_words:
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        is_typo = False
        for correct in correct_words:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –¥—Ä—É–≥–∏–º –æ–∫–æ–Ω—á–∞–Ω–∏–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞
            # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–∞ —Å–ª–æ–≤–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç (–ø–µ—Ä–≤—ã–µ 4-5 –±—É–∫–≤), —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ —Å –¥—Ä—É–≥–∏–º –æ–∫–æ–Ω—á–∞–Ω–∏–µ–º
            if len(word) >= 4 and len(correct) >= 4:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤—É —Å–ª–æ–≤–∞ (–ø–µ—Ä–≤—ã–µ 4-5 –±—É–∫–≤)
                word_base = word[:min(5, len(word))]
                correct_base = correct[:min(5, len(correct))]
                
                # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç –∏ —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –¥–ª–∏–Ω–µ –Ω–µ–±–æ–ª—å—à–∞—è - —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ —Å –¥—Ä—É–≥–∏–º –æ–∫–æ–Ω—á–∞–Ω–∏–µ–º
                if word_base == correct_base and abs(len(word) - len(correct)) <= 3:
                    # –≠—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    is_typo = False
                    break
            
            # 1. –û–ø–µ—á–∞—Ç–∫–∏ –≤ –Ω–∞—á–∞–ª–µ —Å–ª–æ–≤–∞ (–ø–µ—Ä–≤—ã–µ 3 –±—É–∫–≤—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç)
            if len(word) >= 3 and len(correct) >= 3:
                if word[:3] == correct[:3]:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –¥—Ä—É–≥–æ–µ –æ–∫–æ–Ω—á–∞–Ω–∏–µ
                    # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤—ã —Å–∏–ª—å–Ω–æ —Å–æ–≤–ø–∞–¥–∞—é—Ç, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ
                    word_base = word[:min(4, len(word))]
                    correct_base = correct[:min(4, len(correct))]
                    if word_base == correct_base:
                        # –û—Å–Ω–æ–≤–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç - —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        is_typo = False
                        break
                    
                    if abs(len(word) - len(correct)) <= 3:
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–∏–º–≤–æ–ª–æ–≤
                        matches = sum(1 for a, b in zip(word, correct) if a == b)
                        similarity = matches / max(len(word), len(correct))
                        # –ü–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è —Å–ª–æ–≤ —Å –ø–æ—Ö–æ–∂–µ–π –æ—Å–Ω–æ–≤–æ–π
                        if similarity >= 0.75 and word != correct:
                            is_typo = True
                            break
                
                # 2. –û–ø–µ—á–∞—Ç–∫–∏ –≤ –∫–æ–Ω—Ü–µ —Å–ª–æ–≤–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –±—É–∫–≤—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç)
                if len(word) >= 4 and len(correct) >= 4:
                    if word[-3:] == correct[-3:]:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤—É —Å–ª–æ–≤–∞
                        word_base = word[:min(4, len(word))]
                        correct_base = correct[:min(4, len(correct))]
                        if word_base == correct_base:
                            # –û—Å–Ω–æ–≤–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç - —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                            is_typo = False
                            break
                        
                        matches = sum(1 for a, b in zip(word, correct) if a == b)
                        similarity = matches / max(len(word), len(correct))
                        # –ü–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è —Å–ª–æ–≤ —Å –ø–æ—Ö–æ–∂–µ–π –æ—Å–Ω–æ–≤–æ–π
                        if similarity >= 0.75 and word != correct:
                            is_typo = True
                            break
                
                # 3. –°–ª–æ–≤–∞ –ø–æ—Ö–æ–∂–µ–π –¥–ª–∏–Ω—ã —Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –æ—Ç–ª–∏—á–∏—è–º–∏
                if abs(len(word) - len(correct)) <= 2:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤—É —Å–ª–æ–≤–∞
                    word_base = word[:min(4, len(word))]
                    correct_base = correct[:min(4, len(correct))]
                    if word_base == correct_base:
                        # –û—Å–Ω–æ–≤–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç - —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        is_typo = False
                        break
                    
                    matches = sum(1 for a, b in zip(word, correct) if a == b)
                    similarity = matches / max(len(word), len(correct))
                    # –ü–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è —Å–ª–æ–≤ —Å –ø–æ—Ö–æ–∂–µ–π –æ—Å–Ω–æ–≤–æ–π
                    if similarity >= 0.8 and word != correct:
                        is_typo = True
                        break
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ–ø–µ—á–∞—Ç–∫–∏ –≤ —Ä–∞—Å–∫–ª–∞–¥–∫–µ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã
        # –ï—Å–ª–∏ —Å–ª–æ–≤–æ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü—É –∏ –ø–æ—Ö–æ–∂–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–µ —Å–ª–æ–≤–æ
        if not is_typo and len(word) >= 3:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å–ª–æ–≤–æ —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü—É (–±–µ–∑ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã)
            has_cyrillic = any(ord(c) >= 1040 and ord(c) <= 1103 for c in word)
            has_latin = any(ord(c) >= 97 and ord(c) <= 122 for c in word)
            
            # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü–∞ –∏ –¥–ª–∏–Ω–∞ –ø–æ–¥—Ö–æ–¥—è—â–∞—è - –≤–æ–∑–º–æ–∂–Ω–æ –æ–ø–µ—á–∞—Ç–∫–∞ –≤ —Ä–∞—Å–∫–ª–∞–¥–∫–µ
            if has_latin and not has_cyrillic and 3 <= len(word) <= 15:
                is_typo = True
        
        if is_typo:
            typos_found.add(word)
    
    return sorted(list(typos_found))

def filter_valid_typos(typos_list, df=None):
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤, —É–±–∏—Ä–∞—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞, –ø—Ä–µ–¥–ª–æ–≥–∏ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
    
    Args:
        typos_list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        df: DataFrame —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤)
    """
    # –°–ø–∏—Å–æ–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–ø–∞–¥–∞—Ç—å –≤ —Å–ø–∏—Å–æ–∫
    valid_words = {
        # –û–¥–µ–∂–¥–∞ –∏ –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã
        '–¥–∂–∏–Ω—Å—ã', '—à—É–±–∞', '—à—É–±–∫–∞', '–±—Ä—é–∫–∏', '–∫–æ–º–±–∏–Ω–µ–∑–æ–Ω', '–∫–∞–ø—é—à–æ–Ω–æ–º',
        # –¶–≤–µ—Ç–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏—è
        '–±–µ–ª–∞—è', '–±–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–∞—è', '–∫–æ—Ä–∏—á–Ω–µ–≤–∞—è', '—Å–µ—Ä–∞—è', '—á–µ—Ä–Ω—ã–µ', '—à–æ–∫–æ–ª–∞–¥–Ω–æ–≥–æ',
        '—Ü–≤–µ—Ç–∞', '—à–∏—Ä–æ–∫–∏–µ', '—É—Ç–µ–ø–ª–µ–Ω–Ω—ã–µ', '–Ω–∞—Ç—É—Ä–∞–ª—å–Ω–∞—è', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–∞—è',
        # –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –¥–µ—Ç–∞–ª–∏
        '–Ω–æ—Ä–∫–∞', '–Ω–æ—Ä–∫–æ–≤–∞—è', '–Ω–æ—Ä–∫—É', '–Ω–∞—á–µ—Å–æ–º', '–∫–æ–ª–µ–Ω–∞', '—ç–∫–æ',
        # –¢–µ—Ö–Ω–∏–∫–∞ –∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        '—ç–∫—Ä–∞–Ω–æ–º', '–≥–æ—Ä–Ω–æ–ª—ã–∂–Ω—ã–π',
        # –î—Ä—É–≥–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        '–∞–ª–∏—Å–∞', '–∞–ª–∏—Å–æ–π', '–∞–≤—Ç–æ–ª–µ–¥–∏', '–ø–∞–ª–∞—Ü—Ü–æ', '—Ç–µ–¥–¥–∏', '—Ç–µ–ª–æ–¥–≤–∏–∂–µ–Ω–∏–µ', 
        '—Ç–µ–ª–æ–¥–≤–∏–∂–µ–Ω–∏—è', '—Ç—Ä—É–±—ã', '—É–º–Ω–∞—è', '–∫–æ–ª–æ–Ω–∫–∞', '–∫–æ—Ä–æ—Ç–∫–∞—è', '–≤—ã—Å–æ–∫–∏–π', 
        '—Ä–æ—Å—Ç', '—Å—Ç–∞–Ω—Ü–∏—è', '—è–Ω–¥–µ–∫—Å', '—è–Ω–¥–µ–∫—Å.—Å—Ç–∞–Ω—Ü–∏—è', '–¥–æ–º–∞', '–∫–∞', '–∫–æ', 
        '4–∫', '–∫–ª–µ—à'
    }
    
    # –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–≥–æ–≤ –∏ —Å–æ—é–∑–æ–≤ (–∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞)
    prepositions = {
        '–≤–æ', '–∫', '—Å', '–æ—Ç', '–ø–æ', '–Ω–∞', '–∑–∞', '–¥–ª—è', '–¥–æ', '–Ω–µ', '–Ω–æ', 
        '–æ–±', '—Ç–µ', '–¥–∞', '–≤', '–æ', '—É', '–∏–∑', '—Å–æ', '–ø–æ–¥', '–Ω–∞–¥', '–ø—Ä–∏',
        '–ø—Ä–æ', '–±–µ–∑', '—á–µ—Ä–µ–∑', '–º–µ–∂–¥—É', '—Å—Ä–µ–¥–∏', '–ø–µ—Ä–µ–¥', '–ø–æ—Å–ª–µ', '–æ–∫–æ–ª–æ'
    }
    
    filtered = []
    for word in typos_list:
        word_lower = word.lower().strip()
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–ª–æ–≤–∞
        if not word_lower:
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (1-2 –±—É–∫–≤—ã) - —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–≥–∏/—Å–æ—é–∑—ã
        # –ù–û: –µ—Å–ª–∏ —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–º—É—Å–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å), –æ—Å—Ç–∞–≤–ª—è–µ–º –µ–≥–æ
        if len(word_lower) <= 2:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º (–º—É—Å–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å)
            if df is not None and "–ó–∞–ø—Ä–æ—Å" in df.columns:
                is_standalone_query = df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.lower().str.strip().eq(word_lower).any()
                if is_standalone_query:
                    # –≠—Ç–æ –º—É—Å–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–µ–¥–ª–æ–≥/–±—É–∫–≤–∞), –æ—Å—Ç–∞–≤–ª—è–µ–º –µ–≥–æ
                    filtered.append(word)
            # –ï—Å–ª–∏ –Ω–µ—Ç DataFrame –∏–ª–∏ —ç—Ç–æ –Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        if word_lower in valid_words:
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–ª–æ–≥–∏ –∏ —Å–æ—é–∑—ã
        # –ù–û: –µ—Å–ª–∏ —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–º—É—Å–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å), –æ—Å—Ç–∞–≤–ª—è–µ–º –µ–≥–æ
        if word_lower in prepositions:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º (–º—É—Å–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å)
            if df is not None and "–ó–∞–ø—Ä–æ—Å" in df.columns:
                is_standalone_query = df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.lower().str.strip().eq(word_lower).any()
                if is_standalone_query:
                    # –≠—Ç–æ –º—É—Å–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–µ–¥–ª–æ–≥), –æ—Å—Ç–∞–≤–ª—è–µ–º –µ–≥–æ
                    filtered.append(word)
            # –ï—Å–ª–∏ –Ω–µ—Ç DataFrame –∏–ª–∏ —ç—Ç–æ –Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue
        
        filtered.append(word)
    
    return filtered

def find_typos_with_openai(df, api_key):
    """–ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–ª–æ–≤ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂: (—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏, –æ—Ç—á–µ—Ç –æ—Ç OpenAI)
    
    –ë–∞—Ç—á (batch) - —ç—Ç–æ –≥—Ä—É–ø–ø–∞ –∑–∞–ø—Ä–æ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –∫ OpenAI API –∑–∞ –æ–¥–∏–Ω —Ä–∞–∑.
    –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ —É –≤–∞—Å 1000 –∑–∞–ø—Ä–æ—Å–æ–≤, –∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ 50, —Ç–æ –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ 20 –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API.
    –≠—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è –¥–ª—è:
    - –≠–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ (–º–µ–Ω—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤ = –º–µ–Ω—å—à–µ —Å—Ç–æ–∏–º–æ—Å—Ç—å)
    - –°–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API (–Ω–µ –ø—Ä–µ–≤—ã—à–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É)
    - –ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø)
    """
    if df is None or df.empty or "–ó–∞–ø—Ä–æ—Å" not in df.columns:
        return [], ""
    
    if not OPENAI_AVAILABLE:
        return [], ""
    
    if not api_key:
        return [], ""
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (—É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ 2000 –¥–ª—è –±–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)
        queries = df["–ó–∞–ø—Ä–æ—Å"].astype(str).dropna().unique()[:2000]
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏ –ø–æ 1000 –∑–∞–ø—Ä–æ—Å–æ–≤ (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏)
        # –ë–∞—Ç—á - —ç—Ç–æ –≥—Ä—É–ø–ø–∞ –∑–∞–ø—Ä–æ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∫ API
        batch_size = 1000
        all_typos = set()
        report_lines = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_batches = (len(queries) + batch_size - 1) // batch_size
        report_lines.append(f"üìä –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ OpenAI (—Ç–æ–ª—å–∫–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã):")
        report_lines.append(f"   ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(queries)} (–ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤)")
        report_lines.append(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size} –∑–∞–ø—Ä–æ—Å–æ–≤")
        report_lines.append(f"   ‚Ä¢ –í—Å–µ–≥–æ –±–∞—Ç—á–µ–π: {total_batches}")
        report_lines.append("")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–π –±–∞—Ç—á –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        first_batch_example = None
        
        for batch_idx in range(0, len(queries), batch_size):
            batch = queries[batch_idx:batch_idx+batch_size]
            batch_num = batch_idx // batch_size + 1
            queries_text = "\n".join([f"- {q}" for q in batch])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–π –±–∞—Ç—á –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
            if batch_num == 1:
                first_batch_example = {
                    "queries": list(batch),
                    "queries_text": queries_text
                }
            
            status_text.text(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–∞—Ç—á {batch_num} –∏–∑ {total_batches}...")
            progress_bar.progress(batch_num / total_batches)
            
            prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä—É—Å—Å–∫–æ–π –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–∞–π—Ç–∏ —Å–ª–æ–≤–∞ —Å –û–†–§–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ú–ò –û–®–ò–ë–ö–ê–ú–ò –∏ –ú–£–°–û–†–ù–´–ï –ó–ê–ü–†–û–°–´ –≤ —Å–ª–µ–¥—É—é—â–∏—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö.

–ó–∞–ø—Ä–æ—Å—ã:
{queries_text}

–ì–õ–ê–í–ù–û–ï –ü–†–ê–í–ò–õ–û: –ù–∞—Ö–æ–¥–∏:
1. –°–ª–æ–≤–∞ —Å –û–†–§–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ú–ò –û–®–ò–ë–ö–ê–ú–ò
2. –ú–£–°–û–†–ù–´–ï –ó–ê–ü–†–û–°–´ (–æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–≥–∏, —Å–æ—é–∑—ã, –±—É–∫–≤—ã, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è —Ü–µ–ª—ã–º –∑–∞–ø—Ä–æ—Å–æ–º)

–í–ê–ñ–ù–û: –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ—Å—Ç–æ–∏—Ç –¢–û–õ–¨–ö–û –∏–∑ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–≥–∞, —Å–æ—é–∑–∞ –∏–ª–∏ –±—É–∫–≤—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–≤", "–ø–æ", "–∑–∞", "–¥–æ", "–∫", "–¥–∞", "–Ω–æ", "–æ–±", "–≤–æ", "r") - —ç—Ç–æ –ú–£–°–û–†–ù–´–ô –ó–ê–ü–†–û–°, –≤–∫–ª—é—á–∞–π –µ–≥–æ –≤ —Å–ø–∏—Å–æ–∫!

–ß—Ç–æ —Ç–∞–∫–æ–µ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞:
- –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–∞–ø–∏—Å–∞–Ω–Ω–∞—è –±—É–∫–≤–∞: "—Ç–µ—Ä–º–æ–±–µ–ª—å–µ" -> "—Ç–µ—Ä–º–æ–±–∫–ª—å–µ" (–∫ –≤–º–µ—Å—Ç–æ –ª), "—Ç–µ—Ä–º–æ–±–æ–ª—å–µ" (–æ –≤–º–µ—Å—Ç–æ –µ)
- –ü—Ä–æ–ø—É—â–µ–Ω–Ω–∞—è –±—É–∫–≤–∞: "–¥–∂–∏–Ω—Å—ã" -> "–¥–∂–Ω—Å—ã" (–ø—Ä–æ–ø—É—â–µ–Ω–∞ –∏), "–¥–∂—Ä–Ω—Å—ã" (–ø—Ä–æ–ø—É—â–µ–Ω–∞ –∏)
- –õ–∏—à–Ω—è—è –±—É–∫–≤–∞: "–¥—É–±–ª–µ–Ω–∫–∞" -> "–¥—É–±–µ–Ω–∫–∞" (–ø—Ä–æ–ø—É—â–µ–Ω–∞ –ª)
- –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞—Å–∫–ª–∞–¥–∫–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã: "rehnrf" –≤–º–µ—Å—Ç–æ "–∫—É—Ä—Ç–∫–∞"
- –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–∫–æ–Ω—á–∞–Ω–∏–µ: "–∑–∏–º–Ω—è—è" -> "–∑–∏–º–Ω—è—è—è" (–¥–≤–æ–π–Ω–∞—è —è)
- –ó–∞–º–µ–Ω–∞ –±—É–∫–≤: "—Å—Ç–∞–Ω—Ü–∏—è" -> "—Å—Ç–∞–Ω—Ü—ã—è" (—ã –≤–º–µ—Å—Ç–æ –∏), "–∫–ª–µ—à" -> "–∫–ª–µ—à—å" (—å –≤–º–µ—Å—Ç–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ)

–ß—Ç–æ –ù–ï —è–≤–ª—è–µ—Ç—Å—è –æ—à–∏–±–∫–æ–π (–ù–ï –≤–∫–ª—é—á–∞–π –≤ —Å–ø–∏—Å–æ–∫ - —ç—Ç–æ –ü–†–ê–í–ò–õ–¨–ù–´–ï —Å–ª–æ–≤–∞, –µ—Å–ª–∏ –æ–Ω–∏ –≤ —Å–æ—Å—Ç–∞–≤–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞):
- –û–¥–µ–∂–¥–∞ –∏ –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã: –¥–∂–∏–Ω—Å—ã, —à—É–±–∞, —à—É–±–∫–∞, –±—Ä—é–∫–∏, –∫–æ–º–±–∏–Ω–µ–∑–æ–Ω, –∫–∞–ø—é—à–æ–Ω–æ–º
- –¶–≤–µ—Ç–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏—è: –±–µ–ª–∞—è, –±–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–∞—è, –∫–æ—Ä–∏—á–Ω–µ–≤–∞—è, —Å–µ—Ä–∞—è, —á–µ—Ä–Ω—ã–µ, —à–æ–∫–æ–ª–∞–¥–Ω–æ–≥–æ, —Ü–≤–µ—Ç–∞, —à–∏—Ä–æ–∫–∏–µ, —É—Ç–µ–ø–ª–µ–Ω–Ω—ã–µ, –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–∞—è, –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–∞—è
- –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –¥–µ—Ç–∞–ª–∏: –Ω–æ—Ä–∫–∞, –Ω–æ—Ä–∫–æ–≤–∞—è, –Ω–æ—Ä–∫—É, –Ω–∞—á–µ—Å–æ–º, –∫–æ–ª–µ–Ω–∞, —ç–∫–æ
- –¢–µ—Ö–Ω–∏–∫–∞: —ç–∫—Ä–∞–Ω–æ–º, –≥–æ—Ä–Ω–æ–ª—ã–∂–Ω—ã–π
- –î—Ä—É–≥–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞: –∞–ª–∏—Å–∞, –∞–≤—Ç–æ–ª–µ–¥–∏, –ø–∞–ª–∞—Ü—Ü–æ, —Ç–µ–¥–¥–∏, —Ç–µ–ª–æ–¥–≤–∏–∂–µ–Ω–∏–µ, —Ç—Ä—É–±—ã, —É–º–Ω–∞—è, –∫–æ–ª–æ–Ω–∫–∞, –∫–æ—Ä–æ—Ç–∫–∞—è, –≤—ã—Å–æ–∫–∏–π, —Ä–æ—Å—Ç, —Å—Ç–∞–Ω—Ü–∏—è, —è–Ω–¥–µ–∫—Å, –∫–ª–µ—à
- –ö–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ: –∫–∞, –∫–æ, 4–∫

–í–ê–ñ–ù–û: –ü—Ä–µ–¥–ª–æ–≥–∏ –∏ —Å–æ—é–∑—ã (–≤–æ, –∫, —Å, –æ—Ç, –ø–æ, –Ω–∞, –∑–∞, –¥–ª—è, –¥–æ, –Ω–µ, –Ω–æ, –æ–±, —Ç–µ, –¥–∞, –≤, –æ, —É, –∏–∑, —Å–æ, –ø–æ–¥, –Ω–∞–¥, –ø—Ä–∏, –ø—Ä–æ, –±–µ–∑) –≤–∫–ª—é—á–∞–π –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –æ–Ω–∏ —è–≤–ª—è—é—Ç—Å—è –û–¢–î–ï–õ–¨–ù–´–ú –ó–ê–ü–†–û–°–û–ú (–º—É—Å–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å). –ï—Å–ª–∏ –æ–Ω–∏ –≤ —Å–æ—Å—Ç–∞–≤–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ - –Ω–µ –≤–∫–ª—é—á–∞–π.

–ê–õ–ì–û–†–ò–¢–ú –ü–†–û–í–ï–†–ö–ò:
1. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–æ–≤–µ—Ä—å:
   - –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ—Å—Ç–æ–∏—Ç –¢–û–õ–¨–ö–û –∏–∑ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–≥–∞/—Å–æ—é–∑–∞/–±—É–∫–≤—ã (1-2 —Å–∏–º–≤–æ–ª–∞) - —ç—Ç–æ –ú–£–°–û–†–ù–´–ô –ó–ê–ü–†–û–°, –≤–∫–ª—é—á–∞–π –µ–≥–æ
   - –ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ –µ—Å—Ç—å —Å–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - –≤–∫–ª—é—á–∞–π –∏—Ö
2. –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ –º—É—Å–æ—Ä–Ω—ã–µ) - –ø—Ä–æ–ø—É—Å—Ç–∏ –µ–≥–æ
3. –ï—Å–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—à—å—Å—è - –ª—É—á—à–µ –ù–ï –≤–∫–ª—é—á–∞–π (–≤–∫–ª—é—á–∞–π —Ç–æ–ª—å–∫–æ —è–≤–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ –º—É—Å–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã)

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Å–ø–∏—Å–æ–∫:
- –°–ª–æ–≤ —Å –û–†–§–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ú–ò –û–®–ò–ë–ö–ê–ú–ò
- –ú–£–°–û–†–ù–´–• –ó–ê–ü–†–û–°–û–í (–æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–≥–∏, —Å–æ—é–∑—ã, –±—É–∫–≤—ã)

–ü–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
–ö–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ/–∑–∞–ø—Ä–æ—Å –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ."""

            client = openai.OpenAI(api_key=api_key)
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –¥–µ—à–µ–≤—É—é –º–æ–¥–µ–ª—å
                messages=[
                    {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä—É—Å—Å–∫–æ–π –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–∞–π—Ç–∏ —Å–ª–æ–≤–∞ —Å –û–†–§–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ú–ò –û–®–ò–ë–ö–ê–ú–ò –∏ –ú–£–°–û–†–ù–´–ï –ó–ê–ü–†–û–°–´ (–æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–≥–∏, —Å–æ—é–∑—ã, –±—É–∫–≤—ã –∫–∞–∫ —Ü–µ–ª—ã–π –∑–∞–ø—Ä–æ—Å). –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ—Å—Ç–æ–∏—Ç –¢–û–õ–¨–ö–û –∏–∑ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–≥–∞/—Å–æ—é–∑–∞/–±—É–∫–≤—ã (1-2 —Å–∏–º–≤–æ–ª–∞) - —ç—Ç–æ –º—É—Å–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å, –≤–∫–ª—é—á–∞–π –µ–≥–æ. –í–∫–ª—é—á–∞–π —Å–ª–æ–≤–∞ —Å —è–≤–Ω—ã–º–∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—à—å –¢–û–õ–¨–ö–û —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤/–∑–∞–ø—Ä–æ—Å–æ–≤, –ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # –°–Ω–∏–∂–∞–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                max_tokens=3000  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤
            )
            
            result = response.choices[0].message.content.strip()
            batch_typos = []
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ —Å–ª–æ–≤–∞
            lines = result.split("\n")
            for line in lines:
                line = line.strip().lstrip("- ").strip().strip('"').strip("'")
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç—Ä–æ–∫–∏ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
                if line and len(line) > 1 and not line.startswith("–í–µ—Ä–Ω–∏") and not line.startswith("–£—á–∏—Ç—ã–≤–∞–π"):
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞, –µ—Å–ª–∏ –≤ —Å—Ç—Ä–æ–∫–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤
                    words = line.split()
                    for word in words:
                        word = word.strip().strip('"').strip("'").strip(",").strip(".")
                        if word and len(word) > 1:
                            all_typos.add(word)
                            batch_typos.append(word)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - —É–±–∏—Ä–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ –ø—Ä–µ–¥–ª–æ–≥–∏
            # –ü–µ—Ä–µ–¥–∞–µ–º df –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
            batch_typos = filter_valid_typos(batch_typos, df)
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ —Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            for word in batch_typos:
                all_typos.add(word)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–∞—Ç—á–µ –≤ –æ—Ç—á–µ—Ç
            report_lines.append(f"   –ë–∞—Ç—á {batch_num}/{total_batches}: –Ω–∞–π–¥–µ–Ω–æ {len(batch_typos)} —Å–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏")
            if batch_typos:
                report_lines.append(f"      –ü—Ä–∏–º–µ—Ä—ã: {', '.join(batch_typos[:5])}{'...' if len(batch_typos) > 5 else ''}")
            
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(0.5)
        
        progress_bar.empty()
        status_text.empty()
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤
        # –ü–µ—Ä–µ–¥–∞–µ–º df –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
        all_typos_filtered = filter_valid_typos(list(all_typos), df)
        all_typos = set(all_typos_filtered)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        report_lines.append("")
        report_lines.append(f"‚úÖ –ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏): {len(all_typos)}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
        if first_batch_example:
            report_lines.append("")
            report_lines.append("üìù –ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞:")
            report_lines.append("   –ó–∞–ø—Ä–æ—Å—ã –≤ –±–∞—Ç—á–µ:")
            for q in first_batch_example["queries"][:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –∑–∞–ø—Ä–æ—Å–æ–≤
                report_lines.append(f"   ‚Ä¢ {q}")
            if len(first_batch_example["queries"]) > 10:
                report_lines.append(f"   ... –∏ –µ—â–µ {len(first_batch_example['queries']) - 10} –∑–∞–ø—Ä–æ—Å–æ–≤")
        
        report = "\n".join(report_lines)
        
        return sorted(list(all_typos)), report
        
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —á–µ—Ä–µ–∑ OpenAI: {str(e)}"
        st.error(error_msg)
        return [], error_msg

def get_default_garbage_words():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º—É—Å–æ—Ä–Ω—ã—Ö —Å–ª–æ–≤ (—Å –æ—à–∏–±–∫–∞–º–∏ –∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ)"""
    # –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –æ—Ç–∫–ª—é—á–µ–Ω—ã
    return []
    # –°—Ç–∞—Ä—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ (–∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω):
    return [
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - –ø–ª–∞—Ç—å–µ
        "–ø–ª–∞—Ç—è –≤–µ—á–µ—Ä–Ω–∞—è",
        "–ø–æ–ø—Ç—å–µ –≤–µ—á–µ—Ä–Ω–µ–µ",
        "–≤–µ—á–µ—Ä–Ω–µ–µ –ø–æ–≤—Ç—å–µ",
        "–≤–µ—á–µ—Ä–Ω–µ–µ –ø–ª—Ç—å–µ",
        "–ø–ª—Ç—å–µ",
        "–ø–ª–∞—å–µ",
        "–ø–∞—Ç—å–µ",
        "–ø–ª—Ç—å–µ –ø–∏–¥–∂–∞–∫",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - –∫—É—Ä—Ç–∫–∞
        "–∫–∫—Ä—Ç–∫–∞ –∑–∏–º–Ω—è—è",
        "–∫—Ä—É—Ç–∫–∞ –∑–∏–º–Ω—è—è",
        "–∫—Ü—Ä—Ç–∫–∞ –∑–∏–º–Ω—è—è",
        "–∑–∏–º–Ω—è—è –µ—É—Ä—Ç–∫–∞",
        "–∫—É—Ç—Ä–∫–∞ –∑–∏–º–Ω—è—è",
        "—É—É—Ä—Ç–∫–∞ –∑–∏–º–Ω—è—è",
        "–∫—É—Ä—Ç–∫–µ –∑–∏–º–Ω—è—è",
        "–∫—É–ø–∏—Ç—å –∑–∏–º–Ω—é—é –∫—É—Ä—Ç–∫—É",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - —à—É–±–∞
        "—ç–∫–æ—â—É–±–∞",
        "—ç–∫–æ—à—É—å–∞",
        "—ç–∫–æ —à—É—å–∞",
        "—à–±–∞",
        "—à—É–±—É–∞",
        "—à–∫–±–∫–∞",
        "—à—Ü–±–∞",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - –ø—É—Ö–æ–≤–∏–∫
        "–ø—É—Ö—Ä–≤–∏–∫",
        "–ø—É—Ö–æ–≤—Ç–∫",
        "–ø—É–∑–æ–≤–∏–∫ –¥–ª–∏–Ω–Ω—ã–π",
        # –°–ª–æ–≤–∞ —Å –æ–ø–µ—á–∞—Ç–∫–∞–º–∏ –≤ —Ä–∞—Å–∫–ª–∞–¥–∫–µ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã
        "rehnrf pbvyzz ;tycrfz",
        "rehnrf",
        "pbvyzz",
        ";tycrfz",
        "ge[jdbr",
        "ie,f",
        # –î—Ä—É–≥–∏–µ —Å–ª–æ–≤–∞ —Å –æ—à–∏–±–∫–∞–º–∏
        "–∑–∏–º–Ω—è—è –∫–∫—Ä—Ç–∫–∞",
        "—Å—Ç–∞—Ä—Ä–∏–µ—Ä –æ–±—É–≤—å",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - –¥–∂–∏–Ω—Å—ã
        "–¥–∂–∏—Å—ã",
        "–¥–∂–Ω—Å—ã",
        "–¥–∂—Ä–Ω—Å—ã",
        "–¥–∂–∏–Ω—Ü–∏",
        "–¥–∂–∏–Ω—Ü—ã",
        "–¥–∂–∏–Ω—Å—Ü",
        "–¥–∂–∏–Ω—Ü–≤",
        "–∂—ã–Ω—Å—ã",
        "–∂–¥–∏–Ω—Å—ã",
        "–∂–¥—ã–Ω—Å—ã",
        "–¥–∂–∏–≥—Å—ã",
        "–¥–∑–∏–Ω—Å—ã",
        "–∂–∏–Ω—Å–∏",
        "–¥–∂—ã–Ω—Ü—ã",
        "–¥–∂–∏–Ω—Å—ã –∫–ª–µ–ª",
        "–¥–∂–∏–Ω—Å—ã –∫–ª–µ–≥",
        "–¥–∂–∏–Ω—Å—ã –∫–ª–µ—à",
        "–¥–∂–∏–≥—Å—ã –∫–ª–µ—à",
        "–∂–¥–∏–Ω—Å—ã –∫–ª–µ—à",
        "–¥–∂–∏–Ω—Ü—ã —Ç—Ä—É–±—ã",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - —à—Ç–∞–Ω—ã
        "—à–∞—Ç–Ω—ã –∫–ª–µ—à",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - —É–≥–≥–∏
        "—É—É–≥–∏",
        "—ç—É–¥–∏",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - —à—É–±–∞
        "—é–±—É–∞",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - –¥—É—Ç–∏–∫–∏
        "–¥—É—å–∏–∫–∏",
        "–ª—É—Ç–∏–∫–∏",
        "–¥–∫—Ç–∏–∫–∏",
        "–¥—É—Ç–∏—É–∏",
        "–¥—É—Ç–º–∫–∏",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - –ø–∏–¥–∂–∞–∫
        "–ø–∏–Ω–¥–∂–∞–∫",
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ —Å –æ–ø–µ—á–∞—Ç–∫–∞–º–∏ –∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
        "–æ–±—É–≤—å",
        "—Ç—É—Ñ–ª–∏",
        "–±–æ—Ç–∏–Ω–∫–∏",
        "–∫—Ä–æ—Å—Å–æ–≤–∫–∏",
        "—Å–∞–ø–æ–≥–∏",
        "–±–æ—Å–æ–Ω–æ–∂–∫–∏",
        "—Å–∞–Ω–¥–∞–ª–∏–∏",
        "—Ç–∞–ø–æ—á–∫–∏",
        "–∫–µ–¥—ã",
        "–º–æ–∫–∞—Å–∏–Ω—ã",
        "–ª–æ—Ñ–µ—Ä—ã",
        "–±–∞–ª–µ—Ç–∫–∏",
        "—É–≥–≥–∏",
        "–≤–∞–ª–µ–Ω–∫–∏",
        "—Ä–µ–∑–∏–Ω–æ–≤—ã–µ —Å–∞–ø–æ–≥–∏",
        "—á–µ—à–∫–∏",
        "—à–ª–µ–ø–∞–Ω—Ü—ã",
        "–≤—å–µ—Ç–Ω–∞–º–∫–∏",
        "—Å–ª–∞–Ω—Ü—ã",
        "–±–µ—Ä—Ü—ã",
        "—Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è –æ–±—É–≤—å",
        "–¥–æ–º–∞—à–Ω—è—è –æ–±—É–≤—å",
        "—Ä–∞–±–æ—á–∞—è –æ–±—É–≤—å",
        "–¥–µ—Ç—Å–∫–∞—è –æ–±—É–≤—å",
        "–º—É–∂—Å–∫–∞—è –æ–±—É–≤—å",
        "–∂–µ–Ω—Å–∫–∞—è –æ–±—É–≤—å",
        # –°–ª–æ–≤–∞ —Å –æ–ø–µ—á–∞—Ç–∫–∞–º–∏ –≤ —Ä–∞—Å–∫–ª–∞–¥–∫–µ
        "rehnrf",
        "pbvyzz",
        ";tycrfz",
        "ge[jdbr",
        # –î—Ä—É–≥–∏–µ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        "–∞–∫—Å–µ—Å—Å—É–∞—Ä—ã",
        "—Å—É–º–∫–∞",
        "—Å—É–º–∫–∏",
        "—Ä—é–∫–∑–∞–∫",
        "—Ä—é–∫–∑–∞–∫–∏",
        "–ø–æ—Ä—Ç—Ñ–µ–ª—å",
        "–∫–æ—à–µ–ª–µ–∫",
        "–∫–æ—à–µ–ª—å–∫–∏",
        "—Ä–µ–º–µ–Ω—å",
        "—Ä–µ–º–Ω–∏",
        "–≥–∞–ª—Å—Ç—É–∫",
        "–≥–∞–ª—Å—Ç—É–∫–∏",
        "—à–∞—Ä—Ñ",
        "—à–∞—Ä—Ñ—ã",
        "–ø–µ—Ä—á–∞—Ç–∫–∏",
        "–≤–∞—Ä–µ–∂–∫–∏",
        "—à–∞–ø–∫–∞",
        "—à–∞–ø–∫–∏",
        "–∫–µ–ø–∫–∞",
        "–∫–µ–ø–∫–∏",
        "–ø–∞–Ω–∞–º–∞",
        "–ø–∞–Ω–∞–º—ã",
        "–±–µ—Ä–µ—Ç",
        "–±–µ—Ä–µ—Ç—ã",
        "—à–ª—è–ø–∞",
        "—à–ª—è–ø—ã",
        # –ù–æ–≤—ã–µ —Å–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏
        "—à–±–∞",
        "—à–∫–±–ø",
        "–∞–ª–∏—Å–∞ —è–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∞",
        "–∫—É–ø–∏—Ç—å —à—É–±—É",
        "—à—É–±—É –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–∞—è",
        "—Ç–µ—Ä–º–∞ –±–∏–ª—å–µ",
        "—Ç–µ—Ä–º–æ–±–µ–ª–±–µ",
        "–Ω–∞ –∫–æ—Ä–ø–∞—Ä–∞—Ç–∏–≤",
        "—è–Ω–¥–µ–∫—Å —Å—Ç–∞–Ω—Ü–∏–∏ –∞–ª–∏—Å–∞",
        "–∫—É–ø–∏—Ç—å —Ç–µ—Ä–º–æ –±–µ–ª—å–µ",
        "–∫–ª—ç—à",
        "—É–ª–µ—à",
        "—è–Ω–¥–µ–∫—Å –ø–ª–∏—Å–∞",
        "—è–Ω–¥–µ–∫—Å —Å—Ç–∞–Ω—É–∏—è",
        "—Å—Ç–∞–Ω—Ü–∏—è –≤–ª–∏—Å–∞",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - —É–≥–≥–∏
        "—é–≥–≥–∏",
        "—É–≥–≥—É",
        "—É–≥—à–∏",
        "—É–≥–Ω–º",
        "—É–≥–∏ –¥–µ—à–µ–≤—ã–µ",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - –∞–ª–∏—Å–∞
        "–∞–ª—Ç—Å–∞",
        # –°–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ - –¥—Ä—É–≥–∏–µ
        "–ø–∞—Ä—É–∞",
        "—á–Ω–¥–µ–∫—Å —Å—Ç–∞–Ω—Ü–∏—è",
        "—à—É–±—É –∫–æ—Ä–æ—Ç–∫–∞—è",
        "—Ç–µ–ø–ª—ã–µ –∂–¥–∏–Ω—Å—ã",
        "—Ç–µ–ø–ª—ã–µ –¥–¥–∏–Ω—Å—ã",
        "—Ç–µ—Ä–º–æ–±–µ–ª–µ",
        "–∫–æ—Ä–ø–∞—Ä–∞—Ç–∏–≤",
        "–∫–ª—à–µ",
        "—Ç–µ—Ä–º–æ–±–∞–ª—å–µ",
        "—Ç–µ–æ–º–æ–±–µ–ª—å–µ",
        "—Ç–µ—Ä–º–æ–±–µ",
        "–ª–¥–∏–Ω—Å—ã",
        "—Ç–µ—Ä–º–æ–±–µ–ª—å√´",
        "—É–º–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∏ –∞–ª–∏—Å–∞",
        "–∫–æ–ª–æ–Ω–∫–∞ —è–Ω–¥–µ–∫—Å —Å –∞–ª–∏—Å–æ–π",
        "–¥–∂–∏–Ω—á—ã –∫–ª–µ—à",
        "–¥–∂–∏–µ—Å—ã",
        "—Ç–µ—Ä–º–æ –±–µ–ª—å—è",
        "—Ç–µ—Ä–º–æ–±–µ–ª—å–∫",
        "—Ç–µ—Ä–º–æ –±–µ–ª—å√´",
        "—Ç–µ—Ä–º–æ–±–µ–ª—å—é",
        "–¥—É–±–ª–µ–∫–∞",
        "—Ç–µ—Ä–º–æ–±–µ–¥—å–µ",
        "—Ç–µ–ø–º–æ–±–µ–ª—å–µ",
        "–∫–æ–ª–æ–Ω–∫–∞ –∞–ª–∏—Å–ø",
        "—Å—Ç–∞–Ω—Ü–∏—è —è–Ω–¥–µ–∫—Å —Å –∞–ª–∏—Å–æ–π",
        "—É–º–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ —è–Ω–¥–µ–∫—Å —Å—Ç–∞–Ω—Ü–∏—è —Å –∞–ª–∏—Å–æ–π",
        "–∞–ª–∏—Å–∞ –∫–æ–ª–æ–Ω–∫–∞ —è–Ω–¥–µ–∫—Å —Å—Ç–∞–Ω—Ü–∏—è",
        "–¥–∂–∏–Ω—á—ã",
        "–¥–∂–º–Ω—Å—ã",
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏
        "—Ç–µ—Ä–º–æ–±–∫–ª—å–µ",
        "—å–µ—Ä–º–æ–±–µ–ª—å–µ",
        "—Ç–µ—Ä–º–æ—å–µ–ª—å–µ",
        "–¥–∂—Ä–Ω—Å—ã",
        "–¥–∂–Ω—Å—ã",
        "—Ç–µ—Ä–º–æ–±–æ–ª—å–µ",
        "–¥–∂–∏–Ω—Ü–∏",
        "–¥—É–±–µ–Ω–∫–∞",
        "–¥—É–±–ª–µ–Ω–∫—É –±–æ–ª—å—à–∏—Ö —Ä–∞–∑–º–µ—Ä–æ–≤",
        "—Å—Ç–∞–Ω—Ü—ã—è –∞–ª–∏—Å–∞",
        "–¥–∂–∏–Ω—Ü—ã –∫–ª–µ—à—å"
    ]

def load_minus_words():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–∏–Ω—É—Å —Å–ª–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ 'brand_words' –∏ 'other_words'
    –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: –µ—Å–ª–∏ —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –µ–≥–æ –≤ —Å–ª–æ–≤–∞—Ä—å
    """
    if os.path.exists(MINUS_WORDS_FILE):
        try:
            with open(MINUS_WORDS_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                # –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –µ—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
                if isinstance(data, list):
                    return {"brand_words": [], "other_words": data}
                elif isinstance(data, dict):
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –æ–±–∞ –∫–ª—é—á–∞
                    return {
                        "brand_words": data.get("brand_words", []),
                        "other_words": data.get("other_words", [])
                    }
                else:
                    return {"brand_words": [], "other_words": []}
        except Exception:
            return {"brand_words": [], "other_words": []}
    return {"brand_words": [], "other_words": []}

def save_minus_words(words_dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ª–æ–≤–∞—Ä—å –º–∏–Ω—É—Å —Å–ª–æ–≤ –≤ —Ñ–∞–π–ª
    
    Args:
        words_dict: –°–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ 'brand_words' –∏ 'other_words'
    """
    try:
        with open(MINUS_WORDS_FILE, "w", encoding="utf-8") as f:
            json.dump(words_dict, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False

def get_all_minus_words(words_dict):
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –±—Ä–µ–Ω–¥–æ–≤—ã–µ –∏ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–∏–Ω—É—Å —Å–ª–æ–≤–∞ –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫"""
    brand_words = words_dict.get("brand_words", [])
    other_words = words_dict.get("other_words", [])
    return brand_words + other_words

def load_brand_queries():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
    if os.path.exists(BRAND_QUERIES_FILE):
        try:
            with open(BRAND_QUERIES_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    return data
                elif isinstance(data, dict):
                    return data.get("brand_queries", [])
                else:
                    return []
        except Exception:
            return []
    return []

def save_brand_queries(brand_queries):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Ñ–∞–π–ª"""
    try:
        with open(BRAND_QUERIES_FILE, "w", encoding="utf-8") as f:
            json.dump(brand_queries, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False

def load_english_queries():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
    if os.path.exists(ENGLISH_QUERIES_FILE):
        try:
            with open(ENGLISH_QUERIES_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    return data
                elif isinstance(data, dict):
                    return data.get("english_queries", [])
                else:
                    return []
        except Exception:
            return []
    return []

def save_english_queries(english_queries):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Ñ–∞–π–ª"""
    try:
        with open(ENGLISH_QUERIES_FILE, "w", encoding="utf-8") as f:
            json.dump(english_queries, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False

def save_project(project_name, df, settings, project_dir=PROJECTS_DIR):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–µ–∫—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é: –¥–∞–Ω–Ω—ã–µ, —Ñ–∏–ª—å—Ç—Ä—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    
    Parameters:
    -----------
    project_name : str
        –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
    df : pandas.DataFrame
        DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
    settings : dict
        –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø—Ä–æ–µ–∫—Ç–∞
    project_dir : str
        –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏
    
    Returns:
    --------
    tuple (bool, str)
        (–£—Å–ø–µ—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ø—Ä–æ–µ–∫—Ç–∞ –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ)
    """
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞
        project_path = os.path.join(project_dir, project_name)
        os.makedirs(project_path, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV
        data_file = os.path.join(project_path, "data.csv")
        if df is not None and not df.empty:
            df.to_csv(data_file, index=False, encoding='utf-8-sig')
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ JSON
        settings_file = os.path.join(project_path, "settings.json")
        settings_data = {
            "project_name": project_name,
            "created_at": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
            "data_file": "data.csv",
            "settings": settings
        }
        
        with open(settings_file, "w", encoding="utf-8") as f:
            json.dump(settings_data, f, ensure_ascii=False, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã (–∫–æ–ø–∏—Ä—É–µ–º JSON —Ñ–∞–π–ª—ã)
        filters_to_copy = {
            "brand_queries.json": BRAND_QUERIES_FILE,
            "minus_words.json": MINUS_WORDS_FILE,
            "english_queries.json": ENGLISH_QUERIES_FILE,
            "openai_typos.json": OPENAI_TYPOS_FILE
        }
        
        for target_name, source_file in filters_to_copy.items():
            if os.path.exists(source_file):
                import shutil
                shutil.copy2(source_file, os.path.join(project_path, target_name))
        
        return True, project_path
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞: {str(e)}"

def load_project(project_name, project_dir=PROJECTS_DIR):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç: –¥–∞–Ω–Ω—ã–µ, —Ñ–∏–ª—å—Ç—Ä—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    
    Parameters:
    -----------
    project_name : str
        –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
    project_dir : str
        –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏
    
    Returns:
    --------
    tuple (DataFrame, dict, str)
        (DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏, –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏, –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –∏–ª–∏ None)
    """
    try:
        project_path = os.path.join(project_dir, project_name)
        
        if not os.path.exists(project_path):
            return None, None, f"–ü—Ä–æ–µ–∫—Ç '{project_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        settings_file = os.path.join(project_path, "settings.json")
        if not os.path.exists(settings_file):
            return None, None, "–§–∞–π–ª –Ω–∞—Å—Ç—Ä–æ–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω"
        
        with open(settings_file, "r", encoding="utf-8") as f:
            settings_data = json.load(f)
        
        settings = settings_data.get("settings", {})
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data_file = os.path.join(project_path, "data.csv")
        df = None
        if os.path.exists(data_file):
            df = pd.read_csv(data_file, encoding='utf-8-sig')
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã (–∫–æ–ø–∏—Ä—É–µ–º JSON —Ñ–∞–π–ª—ã –æ–±—Ä–∞—Ç–Ω–æ)
        filters_to_restore = {
            BRAND_QUERIES_FILE: "brand_queries.json",
            MINUS_WORDS_FILE: "minus_words.json",
            ENGLISH_QUERIES_FILE: "english_queries.json",
            OPENAI_TYPOS_FILE: "openai_typos.json"
        }
        
        for target_file, source_name in filters_to_restore.items():
            source_file = os.path.join(project_path, source_name)
            if os.path.exists(source_file):
                import shutil
                shutil.copy2(source_file, target_file)
        
        return df, settings, None
    except Exception as e:
        return None, None, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞: {str(e)}"

def list_projects(project_dir=PROJECTS_DIR):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
    
    Parameters:
    -----------
    project_dir : str
        –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏
    
    Returns:
    --------
    list
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–æ–µ–∫—Ç–∞—Ö
    """
    projects = []
    try:
        if not os.path.exists(project_dir):
            return projects
        
        for item in os.listdir(project_dir):
            project_path = os.path.join(project_dir, item)
            if os.path.isdir(project_path):
                settings_file = os.path.join(project_path, "settings.json")
                if os.path.exists(settings_file):
                    try:
                        with open(settings_file, "r", encoding="utf-8") as f:
                            settings_data = json.load(f)
                        projects.append({
                            "name": item,
                            "created_at": settings_data.get("created_at", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                            "path": project_path
                        })
                    except:
                        pass
    except Exception as e:
        pass
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    projects.sort(key=lambda x: x.get("created_at", ""), reverse=True)
    return projects

def delete_project(project_name, project_dir=PROJECTS_DIR):
    """
    –£–¥–∞–ª—è–µ—Ç –ø—Ä–æ–µ–∫—Ç
    
    Parameters:
    -----------
    project_name : str
        –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
    project_dir : str
        –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏
    
    Returns:
    --------
    tuple (bool, str)
        (–£—Å–ø–µ—Ö —É–¥–∞–ª–µ–Ω–∏—è, –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –∏–ª–∏ None)
    """
    try:
        project_path = os.path.join(project_dir, project_name)
        if not os.path.exists(project_path):
            return False, f"–ü—Ä–æ–µ–∫—Ç '{project_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω"
        
        import shutil
        shutil.rmtree(project_path)
        return True, None
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞: {str(e)}"

def get_known_brands():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"""
    return [
        # –û–¥–µ–∂–¥–∞ –∏ –æ–±—É–≤—å
        "nike", "–Ω–∞–π–∫", "adidas", "–∞–¥–∏–¥–∞—Å", "puma", "–ø—É–º–∞", "reebok", "—Ä–∏–±–æ–∫",
        "new balance", "–Ω—å—é –±–∞–ª–∞–Ω—Å", "converse", "–∫–æ–Ω–≤–µ—Ä—Å", "vans", "–≤–∞–Ω—Å",
        "zara", "–∑–∞—Ä–∞", "h&m", "hm", "h&m", "bershka", "–±–µ—Ä—à–∫–∞", "pull&bear",
        "stradivarius", "—Å—Ç—Ä–∞–¥–∏–≤–∞—Ä–∏—É—Å", "massimo dutti", "–º–∞—Å—Å–∏–º–æ –¥—É—Ç—Ç–∏",
        "mango", "–º–∞–Ω–≥–æ", "reserved", "—Ä–µ–∑–µ—Ä–≤", "cropp", "–∫—Ä–æpp", "house",
        "lime", "–ª–∞–π–º", "zarina", "–∑–∞—Ä–∏–Ω–∞", "befree", "–±–∏—Ñ—Ä–∏", "sinsay",
        "–∏–Ω—Å–∞–π", "love republic", "–ª–∞–≤ —Ä–µ—Å–ø—É–±–ª–∏–∫", "mango", "–º–∞–Ω–≥–æ",
        "colin's", "–∫–æ–ª–∏–Ω—Å", "ostin", "–æ—Å—Ç–∏–Ω", "gloria jeans", "–≥–ª–æ—Ä–∏—è –¥–∂–∏–Ω—Å",
        "incity", "–∏–Ω—Å–∏—Ç–∏", "twinset", "—Ç–≤–∏–Ω—Å–µ—Ç", "baon", "–±–∞–æ–Ω",
        # –ö–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –ø–∞—Ä—Ñ—é–º–µ—Ä–∏—è
        "l'oreal", "–ª–æ—Ä–µ–∞–ª—å", "loreal", "maybelline", "–º–µ–π–±–µ–ª–ª–∏–Ω", "revlon",
        "—Ä–µ–≤–ª–æ–Ω", "max factor", "–º–∞–∫—Å —Ñ–∞–∫—Ç–æ—Ä", "rimmel", "—Ä–∏–º–º–µ–ª", "essence",
        "—ç—Å—Å–µ–Ω—Å", "catrice", "–∫–∞—Ç—Ä–∏—Å", "nyx", "–Ω–∏–∫—Å", "mac", "–º–∞–∫", "clinique",
        "–∫–ª–∏–Ω–∏–∫", "estee lauder", "—ç—Å—Ç–µ –ª–∞—É–¥–µ—Ä", "lancome", "–ª–∞–Ω–∫–æ–º", "dior",
        "–¥–∏–æ—Ä", "chanel", "—à–∞–Ω–µ–ª—å", "ysl", "–∏–≤–µ —Å–µ–Ω –ª–æ—Ä–∞–Ω", "ysl",
        "tom ford", "—Ç–æ–º —Ñ–æ—Ä–¥", "gucci", "–≥—É—á—á–∏", "versace", "–≤–µ—Ä—Å–∞—á–µ",
        # –î—Ä—É–≥–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –±—Ä–µ–Ω–¥—ã
        "apple", "—ç–ø–ª", "samsung", "—Å–∞–º—Å—É–Ω–≥", "sony", "—Å–æ–Ω–∏", "lg", "—ç–ª–¥–∂–∏",
        "huawei", "—Ö—É–∞–≤–µ–π", "xiaomi", "—Å—è–æ–º–∏", "realme", "—Ä–∏–ª–º–∏",
        "ikea", "–∏–∫–µ–∞", "lego", "–ª–µ–≥–æ", "nintendo", "–Ω–∏–Ω—Ç–µ–Ω–¥–æ", "playstation",
        "–ø–ª–µ–π—Å—Ç–µ–π—à–Ω", "xbox", "–∏–∫—Å–±–æ–∫—Å"
    ]

def detect_brands_in_queries(df):
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –±—Ä–µ–Ω–¥—ã –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö
    
    Args:
        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–æ–π "–ó–∞–ø—Ä–æ—Å"
    
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –±—Ä–µ–Ω–¥–∞–º–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
              {"brand": count, ...}
    """
    if df is None or df.empty or "–ó–∞–ø—Ä–æ—Å" not in df.columns:
        return {}
    
    known_brands = get_known_brands()
    found_brands = {}
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã
    queries = df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.lower().str.strip()
    
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ –±—Ä–µ–Ω–¥–∞ –∏—â–µ–º –µ–≥–æ –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö
    for brand in known_brands:
        brand_lower = brand.lower().strip()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º word boundary –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–ª–æ–≤
        pattern = r'\b' + re.escape(brand_lower) + r'\b'
        matches = queries.str.contains(pattern, case=False, na=False, regex=True)
        count = matches.sum()
        
        if count > 0:
            found_brands[brand_lower] = count
    
    # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –±—Ä–µ–Ω–¥—ã –∏–∑ —Ñ–∞–π–ª–∞
    existing_brands = load_brand_queries()
    for brand in existing_brands:
        if brand not in found_brands:
            brand_lower = brand.lower().strip()
            pattern = r'\b' + re.escape(brand_lower) + r'\b'
            matches = queries.str.contains(pattern, case=False, na=False, regex=True)
            count = matches.sum()
            
            if count > 0:
                found_brands[brand_lower] = count
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —É–ø–æ–º–∏–Ω–∞–Ω–∏–π (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)
    return dict(sorted(found_brands.items(), key=lambda x: x[1], reverse=True))

def detect_potential_brands(df):
    """
    –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–µ –±—Ä–µ–Ω–¥—ã –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    (–æ—Å–æ–±–µ–Ω–Ω–æ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –±—Ä–µ–Ω–¥–∞–º–∏)
    
    Args:
        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–æ–π "–ó–∞–ø—Ä–æ—Å"
    
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–º–∏ –±—Ä–µ–Ω–¥–∞–º–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
              {"brand": count, ...}
    """
    if df is None or df.empty or "–ó–∞–ø—Ä–æ—Å" not in df.columns:
        return {}
    
    potential_brands = {}
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã
    queries = df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.strip()
    
    # –°–ø–∏—Å–æ–∫ –æ–±—ã—á–Ω—ã—Ö –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï —è–≤–ª—è—é—Ç—Å—è –±—Ä–µ–Ω–¥–∞–º–∏
    common_english_words = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'from', 'up', 'about', 'into', 'through', 'during',
        'before', 'after', 'above', 'below', 'out', 'off', 'over', 'under',
        'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where',
        'why', 'how', 'all', 'each', 'both', 'few', 'more', 'most', 'other',
        'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',
        'than', 'too', 'very', 'can', 'will', 'just', 'should', 'now',
        'new', 'old', 'good', 'bad', 'big', 'small', 'long', 'short', 'high',
        'low', 'right', 'left', 'best', 'free', 'sale', 'buy', 'shop', 'store',
        'price', 'cost', 'cheap', 'expensive', 'discount', 'promo', 'code',
        'size', 'color', 'black', 'white', 'red', 'blue', 'green', 'yellow',
        'men', 'women', 'kids', 'baby', 'child', 'adult', 'male', 'female',
        'home', 'house', 'room', 'bed', 'kitchen', 'bath', 'living', 'dining',
        'plus', 'pro', 'max', 'mini', 'super', 'ultra', 'mega', 'extra',
        'style', 'design', 'model', 'version', 'type', 'kind', 'sort', 'set',
        'pack', 'box', 'piece', 'pair', 'pair', 'unit', 'item', 'product',
        'online', 'offline', 'delivery', 'shipping', 'fast', 'quick', 'slow',
        'easy', 'hard', 'soft', 'hard', 'light', 'heavy', 'warm', 'cold',
        'hot', 'cool', 'fresh', 'clean', 'dirty', 'wet', 'dry'
    }
    
    # –°–ø–∏—Å–æ–∫ –æ–±—ã—á–Ω—ã—Ö —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–∞–ø–∏—Å–∞–Ω—ã –ª–∞—Ç–∏–Ω–∏—Ü–µ–π (–Ω–µ –±—Ä–µ–Ω–¥—ã)
    common_russian_words_latin = {
        'kurska', 'kurtka', 'shuba', 'shubka', 'dzhinsy', 'platye', 'platya',
        'futbolka', 'mayka', 'sviter', 'kardigan', 'pidzhak', 'palto',
        'palto', 'pulover', 'bluza', 'rubashka', 'yubka', 'bryuki', 'shorty',
        'kepka', 'shapka', 'sharf', 'perchatki', 'noski', 'chulki', 'tufly',
        'krossovki', 'botinki', 'sapogi', 'tufli', 'sandalii', 'tapochki',
        'sumka', 'ryukzak', 'koshel', 'portfel', 'remen', 'poyas', 'chasy',
        'ochki', 'sergi', 'braslet', 'kolco', 'podveska', 'brosh', 'zaponka'
    }
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤
    all_words = {}
    
    for query in queries:
        if pd.isna(query) or not query:
            continue
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å–ª–æ–≤–∞
        words = re.findall(r'\b\w+\b', query.lower())
        
        for word in words:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–º–µ–Ω—å—à–µ 3 —Å–∏–º–≤–æ–ª–æ–≤)
            if len(word) < 3:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ (–±–æ–ª—å—à–µ 20 —Å–∏–º–≤–æ–ª–æ–≤) - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –Ω–µ –±—Ä–µ–Ω–¥
            if len(word) > 20:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–æ–≤–∞, —Å–æ—Å—Ç–æ—è—â–∏–µ —Ç–æ–ª—å–∫–æ –∏–∑ —Ü–∏—Ñ—Ä
            if word.isdigit():
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å–ª–æ–≤–æ —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü—É (–∞–Ω–≥–ª–æ—è–∑—ã—á–Ω–æ–µ —Å–ª–æ–≤–æ)
            has_cyrillic = any(ord(c) >= 1040 and ord(c) <= 1103 for c in word)
            has_latin = any(ord(c) >= 97 and ord(c) <= 122 for c in word)
            has_digits = any(c.isdigit() for c in word)
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–æ–≤–∞ —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π (—Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞)
            if has_cyrillic:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–æ–≤–∞ —Ç–æ–ª—å–∫–æ —Å —Ü–∏—Ñ—Ä–∞–º–∏
            if not has_latin:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ã—á–Ω—ã–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞
            if word in common_english_words:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ã—á–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–µ –ª–∞—Ç–∏–Ω–∏—Ü–µ–π
            if word in common_russian_words_latin:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –±—Ä–µ–Ω–¥–∞–º–∏ (—É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã)
            known_brands = get_known_brands()
            existing_brands = load_brand_queries()
            all_known = [b.lower() for b in known_brands + existing_brands]
            if word in all_known:
                continue
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
            if word not in all_words:
                all_words[word] = 0
            all_words[word] += 1
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–æ–≤–∞ –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —É–ø–æ–º–∏–Ω–∞–Ω–∏–π (–º–∏–Ω–∏–º—É–º 2)
    # –∏ –ø–æ –¥–ª–∏–Ω–µ (3-15 —Å–∏–º–≤–æ–ª–æ–≤ - —Ç–∏–ø–∏—á–Ω–∞—è –¥–ª–∏–Ω–∞ –±—Ä–µ–Ω–¥–æ–≤)
    for word, count in all_words.items():
        if count >= 2 and 3 <= len(word) <= 15:
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —Å–ª–æ–≤–æ –¥–æ–ª–∂–Ω–æ –≤—ã–≥–ª—è–¥–µ—Ç—å –∫–∞–∫ –±—Ä–µ–Ω–¥
            # (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –±—É–∫–≤—ã, –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã)
            if word[0].isalpha():
                potential_brands[word] = count
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —É–ø–æ–º–∏–Ω–∞–Ω–∏–π (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)
    return dict(sorted(potential_brands.items(), key=lambda x: x[1], reverse=True))

def detect_english_queries(df):
    """
    –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (—Ü–µ–ª—ã–µ –∑–∞–ø—Ä–æ—Å—ã, —Å–æ—Å—Ç–æ—è—â–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏–∑ –ª–∞—Ç–∏–Ω–∏—Ü—ã)
    
    Args:
        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–æ–π "–ó–∞–ø—Ä–æ—Å"
    
    Returns:
        DataFrame: DataFrame —Å –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∏ –∏—Ö –¥–∞–Ω–Ω—ã–º–∏
    """
    if df is None or df.empty or "–ó–∞–ø—Ä–æ—Å" not in df.columns:
        return pd.DataFrame()
    
    english_queries = []
    english_indices = []
    
    queries = df["–ó–∞–ø—Ä–æ—Å"].astype(str)
    
    for idx, query in queries.items():
        if pd.isna(query) or not query.strip():
            continue
        
        query_clean = query.strip()
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
        total_chars = len(query_clean)
        if total_chars == 0:
            continue
        
        cyrillic_count = sum(1 for c in query_clean if ord(c) >= 1040 and ord(c) <= 1103)
        latin_count = sum(1 for c in query_clean if (ord(c) >= 65 and ord(c) <= 90) or (ord(c) >= 97 and ord(c) <= 122))
        digit_count = sum(1 for c in query_clean if c.isdigit())
        space_count = sum(1 for c in query_clean if c.isspace())
        other_count = total_chars - cyrillic_count - latin_count - digit_count - space_count
        
        # –°—á–∏—Ç–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –ª–∞—Ç–∏–Ω–∏—Ü—ã –æ—Ç –≤—Å–µ—Ö –±—É–∫–≤–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        letter_chars = cyrillic_count + latin_count
        if letter_chars == 0:
            continue
        
        latin_percentage = (latin_count / letter_chars) * 100 if letter_chars > 0 else 0
        
        # –ó–∞–ø—Ä–æ—Å —Å—á–∏—Ç–∞–µ—Ç—Å—è –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–º, –µ—Å–ª–∏:
        # 1. –ë–æ–ª–µ–µ 70% –±—É–∫–≤–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ - –ª–∞—Ç–∏–Ω–∏—Ü–∞
        # 2. –ï—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –ª–∞—Ç–∏–Ω—Å–∫–∞—è –±—É–∫–≤–∞
        # 3. –ö–∏—Ä–∏–ª–ª–∏—Ü—ã –º–µ–Ω—å—à–µ 30% –æ—Ç –≤—Å–µ—Ö –±—É–∫–≤–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        if latin_count > 0 and latin_percentage >= 70 and cyrillic_count / letter_chars < 0.3:
            english_queries.append(query_clean)
            english_indices.append(idx)
    
    if english_indices:
        return df.loc[english_indices].copy()
    else:
        return pd.DataFrame()

def load_openai_typos():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –∏–∑ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ OpenAI"""
    if os.path.exists(OPENAI_TYPOS_FILE):
        try:
            with open(OPENAI_TYPOS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return []
    return []

def save_openai_typos(words):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –∏–∑ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ OpenAI"""
    try:
        with open(OPENAI_TYPOS_FILE, "w", encoding="utf-8") as f:
            json.dump(words, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False

def find_header_row(excel_file, max_rows=20):
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Å—Ç—Ä–æ–∫—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –≤ Excel —Ñ–∞–π–ª–µ
    –ò—â–µ—Ç —Å—Ç—Ä–æ–∫—É, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
    """
    # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ (—Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã)
    known_headers = [
        "–∑–∞–ø—Ä–æ—Å", "query", "–∑–∞–ø—Ä–æ—Å—ã",
        "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤", "—Ç–æ–≤–∞—Ä—ã", "products", "–∞—Ä—Ç–∏–∫—É–ª–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É",
        "—á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –∑–∞ 30 –¥–Ω–µ–π", "—á–∞—Å—Ç–æ—Ç–∞ wb", "—á–∞—Å—Ç–æ—Ç–∞wb",
        "–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 30 –¥–Ω–µ–π", "—Ç—Ä–µ–Ω–¥ 30 –¥–Ω–µ–π",
        "–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 60 –¥–Ω–µ–π", "—Ç—Ä–µ–Ω–¥ 60 –¥–Ω–µ–π",
        "–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 90 –¥–Ω–µ–π", "—Ç—Ä–µ–Ω–¥ 90 –¥–Ω–µ–π"
    ]
    
    # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    try:
        df_test = pd.read_excel(excel_file, header=None, nrows=max_rows)
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        best_row = 0
        best_score = 0
        
        for i in range(min(len(df_test), max_rows)):
            row_values = [str(val).lower().strip() for val in df_test.iloc[i].values if pd.notna(val)]
            score = sum(1 for header in known_headers if any(header in val for val in row_values))
            
            if score > best_score:
                best_score = score
                best_row = i
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å—Ç—Ä–æ–∫—É —Å —Ö–æ—Ç—è –±—ã 2 —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ—ë –Ω–æ–º–µ—Ä
        if best_score >= 2:
            return best_row
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
        return 0
    except:
        return 0

@st.cache_data(ttl=3600, show_spinner="–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
def load_default_file(month=None, year=2025):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –ø–∞–ø–∫–∏ trend, –æ–±—ä–µ–¥–∏–Ω—è—è —Ñ–∞–π–ª—ã "—Ä–æ—Å—Ç" –∏ "–ø–∞–¥–µ–Ω–∏–µ" –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–µ—Å—è—Ü–∞
    
    Parameters:
    -----------
    month : str or None
        –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Å—è—Ü–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–°–µ–Ω—Ç—è–±—Ä—å", "–û–∫—Ç—è–±—Ä—å"). –ï—Å–ª–∏ None, –∏—â–µ—Ç new.xlsx
    year : int
        –ì–æ–¥ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2025)
    
    Returns:
    --------
    tuple (DataFrame, str, dict) or (None, None, None)
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame, –∏–º—è —Ñ–∞–π–ª–∞ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –∏–ª–∏ (None, None, None) –ø—Ä–∏ –æ—à–∏–±–∫–µ
        dict —Å–æ–¥–µ—Ä–∂–∏—Ç: {'growth_file': str or None, 'decline_file': str or None, 'error': str or None}
    """
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ (–Ω–∞ 3 —É—Ä–æ–≤–Ω—è –≤—ã—à–µ –æ—Ç apps/prospective_queries/app.py)
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    trend_dir = os.path.join(project_root, "trend")
    
    if not os.path.exists(trend_dir):
        return None, None, {'growth_file': None, 'decline_file': None, 'error': '–ü–∞–ø–∫–∞ trend –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}
    
    # –ï—Å–ª–∏ –º–µ—Å—è—Ü –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—â–µ–º —Ñ–∞–π–ª new.xlsx (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    if month is None:
        excel_file = os.path.join(trend_dir, "new.xlsx")
        if os.path.exists(excel_file):
            try:
                header_row = find_header_row(excel_file)
                df = pd.read_excel(excel_file, header=header_row)
                return df, "new.xlsx", {'growth_file': None, 'decline_file': None, 'error': None}
            except Exception as e:
                return None, None, {'growth_file': None, 'decline_file': None, 'error': str(e)}
        return None, None, {'growth_file': None, 'decline_file': None, 'error': '–§–∞–π–ª new.xlsx –Ω–µ –Ω–∞–π–¥–µ–Ω'}
    
    # –ò—â–µ–º —Ñ–∞–π–ª—ã "—Ä–æ—Å—Ç" –∏ "–ø–∞–¥–µ–Ω–∏–µ" –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–µ—Å—è—Ü–∞
    month_variants = [
        month,  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        month.capitalize(),  # –° –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã
        month.lower(),  # –í –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        month.upper(),  # –í –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    ]
    
    # –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ –æ–ø–µ—á–∞—Ç–∫–∞–º–∏
    if month.lower() in ["—Ñ–µ–≤—Ä–∞–ª—å", "—Ñ–µ–≤—Ä–∞–ª—å"]:
        month_variants.extend(["–§–µ—Ä–≤–∞–ª—å", "—Ñ–µ—Ä–≤–∞–ª—å", "–§–ï–†–í–ê–õ–¨", "–§–µ–≤—Ä–∞–ª—å"])
    
    growth_file = None
    decline_file = None
    
    # –ò—â–µ–º —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ trend
    year_str = str(year)
    
    for file in os.listdir(trend_dir):
        if not file.endswith(('.xlsx', '.xls')):
            continue
        
        file_lower = file.lower()
        file_name_without_ext = os.path.splitext(file)[0].lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—è—Ü–∞
        for month_var in month_variants:
            month_lower = month_var.lower()
            
            # –ò—â–µ–º —Ñ–∞–π–ª "—Ä–æ—Å—Ç" - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è
            growth_patterns = [
                f"{month_lower} —Ä–æ—Å—Ç {year_str}",
                f"{month_lower} —Ä–æ—Å—Ç{year_str}",
                f"{month_lower}—Ä–æ—Å—Ç {year_str}",
                f"{month_lower}—Ä–æ—Å—Ç{year_str}",
            ]
            
            for pattern in growth_patterns:
                if pattern in file_lower or pattern in file_name_without_ext:
                    if growth_file is None:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π
                        growth_file = os.path.join(trend_dir, file)
                    break
            
            # –ò—â–µ–º —Ñ–∞–π–ª "–ø–∞–¥–µ–Ω–∏–µ" (—Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫)
            decline_patterns = [
                f"{month_lower} –ø–∞–¥–µ–Ω–∏–µ {year_str}",
                f"{month_lower} –ø–∞–¥–µ–Ω–∏–µ{year_str}",
                f"{month_lower}–ø–∞–¥–µ–Ω–∏–µ {year_str}",
                f"{month_lower}–ø–∞–¥–µ–Ω–∏–µ{year_str}",
                f"{month_lower} –ø–∞–¥–µ–Ω–∏–∏–µ {year_str}",  # –û–ø–µ—á–∞—Ç–∫–∞
                f"{month_lower} –ø–∞–¥–µ–Ω–∏–∏–µ{year_str}",  # –û–ø–µ—á–∞—Ç–∫–∞
                f"{month_lower}–ø–∞–¥–µ–Ω–∏–∏–µ {year_str}",  # –û–ø–µ—á–∞—Ç–∫–∞
                f"{month_lower}–ø–∞–¥–µ–Ω–∏–∏–µ{year_str}",  # –û–ø–µ—á–∞—Ç–∫–∞
            ]
            
            for pattern in decline_patterns:
                if pattern in file_lower or pattern in file_name_without_ext:
                    if decline_file is None:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π
                        decline_file = os.path.join(trend_dir, file)
                    break
        
        if growth_file and decline_file:
            break
    
    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ–∞–π–ª, –∑–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º
    dataframes = []
    file_names = []
    
    file_info = {'growth_file': growth_file, 'decline_file': decline_file, 'error': None}
    
    if growth_file:
        try:
            header_row = find_header_row(growth_file)
            df_growth = pd.read_excel(growth_file, header=header_row)
            if df_growth is not None and not df_growth.empty:
                dataframes.append(df_growth)
                file_names.append(os.path.basename(growth_file))
        except Exception as e:
            file_info['error'] = f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ —Ä–æ—Å—Ç–∞: {os.path.basename(growth_file)} - {str(e)}"
    
    if decline_file:
        try:
            header_row = find_header_row(decline_file)
            df_decline = pd.read_excel(decline_file, header=header_row)
            if df_decline is not None and not df_decline.empty:
                dataframes.append(df_decline)
                file_names.append(os.path.basename(decline_file))
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –ø–∞–¥–µ–Ω–∏—è: {os.path.basename(decline_file)} - {str(e)}"
            if file_info['error']:
                file_info['error'] += f"; {error_msg}"
            else:
                file_info['error'] = error_msg
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    if dataframes:
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ DataFrame
            combined_df = pd.concat(dataframes, ignore_index=True)
            combined_filename = f"{month} {year} (–æ–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {', '.join(file_names)})"
            return combined_df, combined_filename, file_info
        except Exception as e:
            file_info['error'] = f"–û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {str(e)}"
            return None, None, file_info
    
    # –ï—Å–ª–∏ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
    if not growth_file and not decline_file:
        file_info['error'] = f"–§–∞–π–ª—ã –¥–ª—è {month} {year} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ trend"
    
    return None, None, file_info

def normalize_column_names(df):
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤, –ø—Ä–∏–≤–æ–¥—è –∏—Ö –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º
    –ï—Å–ª–∏ —Å—Ç–æ–ª–±—Ü—ã –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è "Unnamed", –ø—ã—Ç–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏
    """
    if df is None or df.empty:
        return df
    
    df = df.copy()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ "Unnamed" - –∑–Ω–∞—á–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ –¥–∞–Ω–Ω—ã—Ö
    unnamed_cols = [col for col in df.columns if str(col).startswith('Unnamed')]
    if len(unnamed_cols) > 0 and len(df) > 0:
        # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        try:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            new_columns = df.iloc[0].astype(str).tolist()
            # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∏–∑ –¥–∞–Ω–Ω—ã—Ö
            df = df.iloc[1:].copy()
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–æ–≤—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            df.columns = new_columns
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å
            df = df.reset_index(drop=True)
        except Exception:
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —Ç–µ–∫—É—â–∏–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
            pass
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –º–∞–ø–ø–∏–Ω–≥–∞: –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–∑–≤–∞–Ω–∏–π -> —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    column_mapping = {}
    
    # –ú–∞–ø–ø–∏–Ω–≥ –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ (–∏—â–µ–º –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–∞–º –Ω–∞–∑–≤–∞–Ω–∏–π)
    possible_names = {
        "–ó–∞–ø—Ä–æ—Å": ["–∑–∞–ø—Ä–æ—Å", "query", "–∑–∞–ø—Ä–æ—Å—ã", "queries", "—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞", "—Ç–µ–∫—Å—Ç"],
        "–í—ã—Ä—É—á–∫–∞": ["–≤—ã—Ä—É—á–∫–∞", "revenue", "–æ–±—â–∞—è –≤—ã—Ä—É—á–∫–∞", "–≤—ã—Ä—É—á–∫–∞ –æ–±—â–∞—è", "—Å—É–º–º–∞ –≤—ã—Ä—É—á–∫–∏"],
        "–¢–æ–≤–∞—Ä—ã": ["—Ç–æ–≤–∞—Ä—ã", "products", "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤", "—Ç–æ–≤–∞—Ä–æ–≤", "–∫–æ–ª-–≤–æ —Ç–æ–≤–∞—Ä–æ–≤", "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É"],
        "–ß–∞—Å—Ç–æ—Ç–∞ WB": ["—á–∞—Å—Ç–æ—Ç–∞ wb", "—á–∞—Å—Ç–æ—Ç–∞wb", "wb —á–∞—Å—Ç–æ—Ç–∞", "wb", "—á–∞—Å—Ç–æ—Ç–∞ wildberries", "—á–∞—Å—Ç–æ—Ç–∞ –≤–±", "—á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –∑–∞ 30 –¥–Ω–µ–π"],
        "–¢—Ä–µ–Ω–¥ 30 –¥–Ω–µ–π": ["—Ç—Ä–µ–Ω–¥ 30 –¥–Ω–µ–π", "—Ç—Ä–µ–Ω–¥30", "—Ç—Ä–µ–Ω–¥ 30", "30 –¥–Ω–µ–π", "—Ç—Ä–µ–Ω–¥ –∑–∞ 30 –¥–Ω–µ–π", "–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 30 –¥–Ω–µ–π", "–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 30 –¥–Ω–µ–π, %"],
        "–¢—Ä–µ–Ω–¥ 60 –¥–Ω–µ–π": ["—Ç—Ä–µ–Ω–¥ 60 –¥–Ω–µ–π", "—Ç—Ä–µ–Ω–¥60", "—Ç—Ä–µ–Ω–¥ 60", "60 –¥–Ω–µ–π", "—Ç—Ä–µ–Ω–¥ –∑–∞ 60 –¥–Ω–µ–π", "–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 60 –¥–Ω–µ–π", "–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 60 –¥–Ω–µ–π, %"],
        "–¢—Ä–µ–Ω–¥ 90 –¥–Ω–µ–π": ["—Ç—Ä–µ–Ω–¥ 90 –¥–Ω–µ–π", "—Ç—Ä–µ–Ω–¥90", "—Ç—Ä–µ–Ω–¥ 90", "90 –¥–Ω–µ–π", "—Ç—Ä–µ–Ω–¥ –∑–∞ 90 –¥–Ω–µ–π", "–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 90 –¥–Ω–µ–π", "–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 90 –¥–Ω–µ–π, %"],
        "–°—Ä. —Ü–µ–Ω–∞": ["—Å—Ä. —Ü–µ–Ω–∞", "—Å—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞", "—Å—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞", "avg price", "—Å—Ä–µ–¥–Ω—è—è", "—Ü–µ–Ω–∞ —Å—Ä–µ–¥–Ω—è—è"],
        "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª": ["–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª", "potential", "–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –ø—Ä–æ–¥–∞–∂"],
    }
    
    # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ -> –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –≤ DataFrame
    df_columns_lower = {str(col).lower().strip(): col for col in df.columns}
    
    for standard_name, possible_variants in possible_names.items():
        # –ò—â–µ–º —Å—Ç–æ–ª–±–µ—Ü –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–∞–º –Ω–∞–∑–≤–∞–Ω–∏–π
        found_column = None
        for variant in possible_variants:
            variant_lower = variant.lower().strip()
            if variant_lower in df_columns_lower:
                found_column = df_columns_lower[variant_lower]
                break
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å—Ç–æ–ª–±–µ—Ü –∏ –æ–Ω –µ—â–µ –Ω–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –≤ –º–∞–ø–ø–∏–Ω–≥
        if found_column and found_column != standard_name:
            column_mapping[found_column] = standard_name
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ
    if column_mapping:
        df = df.rename(columns=column_mapping)
    
    return df

@st.cache_data
def process_dataframe(df):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç DataFrame: –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤, –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—Ç–æ–ª–±–µ—Ü –≤—ã—Ä—É—á–∫–∏ –Ω–∞ –µ–¥–∏–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞
    
    –ö—ç—à–∏—Ä—É–µ—Ç—Å—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    """
    df = df.copy()
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
    df = normalize_column_names(df)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    if "–¢–æ–≤–∞—Ä—ã" not in df.columns:
        st.error("–í —Ç–∞–±–ª–∏—Ü–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Å—Ç–æ–ª–±–µ—Ü: '–¢–æ–≤–∞—Ä—ã' (–∏–ª–∏ '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É')")
        st.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –≤ —Ñ–∞–π–ª–µ: {', '.join(df.columns.tolist())}")
        return None
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç–æ–ª–±—Ü—ã –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
    # –°–Ω–∞—á–∞–ª–∞ –æ—á–∏—â–∞–µ–º –æ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ç—ã—Å—è—á (–ø—Ä–æ–±–µ–ª—ã, –∑–∞–ø—è—Ç—ã–µ)
    if "–¢–æ–≤–∞—Ä—ã" in df.columns:
        if df["–¢–æ–≤–∞—Ä—ã"].dtype == 'object':
            df["–¢–æ–≤–∞—Ä—ã"] = df["–¢–æ–≤–∞—Ä—ã"].astype(str).str.replace(r'[\s,]', '', regex=True)
        df["–¢–æ–≤–∞—Ä—ã"] = pd.to_numeric(df["–¢–æ–≤–∞—Ä—ã"], errors="coerce")
    
    # –í—ã—Ä—É—á–∫–∞ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞ - –µ—Å–ª–∏ –µ—Å—Ç—å, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ—ë
    if "–í—ã—Ä—É—á–∫–∞" in df.columns:
        if df["–í—ã—Ä—É—á–∫–∞"].dtype == 'object':
            df["–í—ã—Ä—É—á–∫–∞"] = df["–í—ã—Ä—É—á–∫–∞"].astype(str).str.replace(r'[\s,]', '', regex=True)
        df["–í—ã—Ä—É—á–∫–∞"] = pd.to_numeric(df["–í—ã—Ä—É—á–∫–∞"], errors="coerce")
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥—Ä—É–≥–∏–µ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç (–∫—Ä–æ–º–µ "–ß–∞—Å—Ç–æ—Ç–∞ WB" - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å)
    numeric_columns_to_convert = ["–¢—Ä–µ–Ω–¥ 30 –¥–Ω–µ–π", "–¢—Ä–µ–Ω–¥ 60 –¥–Ω–µ–π", "–¢—Ä–µ–Ω–¥ 90 –¥–Ω–µ–π", 
                                   "–°—Ä. —Ü–µ–Ω–∞", "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª", "–ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞", "–°—Ä. —Ü–µ–Ω–∞ —Å –°–ü–ü", 
                                   "–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞", "–¢–æ–≤–∞—Ä—ã —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏",
                                   "–ü—Ä–æ–¥–∞–≤—Ü—ã", "–ü—Ä–æ–¥–∞–≤—Ü—ã —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏", "–ë—Ä–µ–Ω–¥—ã", 
                                   "–ë—Ä–µ–Ω–¥—ã —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏", "–î–æ–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∞–≤—Ç–æ—Ä–µ–∫–ª–∞–º–µ %",
                                   "–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞ %", "–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª"]
    for col in numeric_columns_to_convert:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    
    # "–ß–∞—Å—Ç–æ—Ç–∞ WB" –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã (–Ω–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    if "–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª" in df.columns:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        df = df.sort_values("–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª", ascending=False)
    elif "–¢–æ–≤–∞—Ä—ã" in df.columns:
        # –ï—Å–ª–∏ –Ω–µ—Ç —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏, —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ç–æ–≤–∞—Ä–∞–º (—É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Å—Ç–æ–ª–±–µ—Ü —á–∏—Å–ª–æ–≤–æ–π)
        if not pd.api.types.is_numeric_dtype(df["–¢–æ–≤–∞—Ä—ã"]):
            df["–¢–æ–≤–∞—Ä—ã"] = pd.to_numeric(df["–¢–æ–≤–∞—Ä—ã"], errors="coerce")
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é, NaN –∑–Ω–∞—á–µ–Ω–∏—è –∏–¥—É—Ç –≤ –∫–æ–Ω–µ—Ü
        df = df.sort_values("–¢–æ–≤–∞—Ä—ã", ascending=False, na_position='last')
    
    return df

def is_clothing_related(query):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Å–≤—è–∑–∞–Ω –ª–∏ –∑–∞–ø—Ä–æ—Å —Å –æ–¥–µ–∂–¥–æ–π"""
    if pd.isna(query):
        return False
    
    query_lower = str(query).lower()
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –æ–¥–µ–∂–¥–æ–π
    clothing_keywords = [
        '–ø–ª–∞—Ç—å–µ', '–ø–ª–∞—Ç—å—è', '–ø–ª–∞—Ç—å–∏—Ü–µ',
        '–∫—É—Ä—Ç–∫–∞', '–∫—É—Ä—Ç–∫–∏',
        '—à—É–±–∞', '—à—É–±—ã', '—à—É–±–∫–∞', '—à—É–±–∫–∏',
        '–Ω–∞—Ä—è–¥', '–Ω–∞—Ä—è–¥—ã', '–Ω–∞—Ä—è–¥–Ω–æ–µ', '–Ω–∞—Ä—è–¥–Ω—ã–π',
        '–æ–¥–µ–∂–¥–∞', '–æ–¥–µ–∂–¥—É',
        '–∫–æ—Å—Ç—é–º', '–∫–æ—Å—Ç—é–º—ã',
        '–±—Ä—é–∫–∏', '–±—Ä—é–∫–∏',
        '—é–±–∫–∞', '—é–±–∫–∏',
        '—Ä—É–±–∞—à–∫–∞', '—Ä—É–±–∞—à–∫–∏',
        '—Ñ—É—Ç–±–æ–ª–∫–∞', '—Ñ—É—Ç–±–æ–ª–∫–∏',
        '—Å–≤–∏—Ç–µ—Ä', '—Å–≤–∏—Ç–µ—Ä—ã',
        '–ø–∞–ª—å—Ç–æ', '–ø–∞–ª—å—Ç–æ',
        '–ø–∏–¥–∂–∞–∫', '–ø–∏–¥–∂–∞–∫–∏',
        '–±–ª—É–∑–∫–∞', '–±–ª—É–∑–∫–∏',
        '—Å–∞—Ä–∞—Ñ–∞–Ω', '—Å–∞—Ä–∞—Ñ–∞–Ω—ã',
        '–∫–æ–º–±–∏–Ω–µ–∑–æ–Ω', '–∫–æ–º–±–∏–Ω–µ–∑–æ–Ω—ã',
        '—Ç–æ–ø', '—Ç–æ–ø—ã',
        '–º–∞–π–∫–∞', '–º–∞–π–∫–∏',
        '–¥–∂–µ–º–ø–µ—Ä', '–¥–∂–µ–º–ø–µ—Ä—ã',
        '–∫–∞—Ä–¥–∏–≥–∞–Ω', '–∫–∞—Ä–¥–∏–≥–∞–Ω—ã',
        '–∂–∏–ª–µ—Ç', '–∂–∏–ª–µ—Ç—ã',
        '–±–æ–º–±–µ—Ä', '–±–æ–º–±–µ—Ä—ã',
        '–ø—É—Ö–æ–≤–∏–∫', '–ø—É—Ö–æ–≤–∏–∫–∏',
        '–≤–µ—Ç—Ä–æ–≤–∫–∞', '–≤–µ—Ç—Ä–æ–≤–∫–∏',
        '–¥–∂–∏–Ω—Å—ã', '–¥–∂–∏–Ω—Å—ã',
        '—à–æ—Ä—Ç—ã', '—à–æ—Ä—Ç—ã',
        '–±–ª—É–∑–∞', '–±–ª—É–∑—ã',
        '—Ç—É–Ω–∏–∫–∞', '—Ç—É–Ω–∏–∫–∏',
        '—Å–∞—Ä–∞—Ñ–∞–Ω', '—Å–∞—Ä–∞—Ñ–∞–Ω—ã',
        '—Ö–∞–ª–∞—Ç', '—Ö–∞–ª–∞—Ç—ã',
        '–∫–∏–º–æ–Ω–æ', '–∫–∏–º–æ–Ω–æ',
        '–ø–ª–∞—â', '–ø–ª–∞—â–∏',
        '—Ç—Ä–µ–Ω—á', '—Ç—Ä–µ–Ω—á–∏',
        '–ø–∞–ª—å—Ç–æ', '–ø–∞–ª—å—Ç–æ',
        '–¥—É–±–ª–µ–Ω–∫–∞', '–¥—É–±–ª–µ–Ω–∫–∏',
        '–ø–æ–ª—É—à—É–±–æ–∫', '–ø–æ–ª—É—à—É–±–∫–∏',
        '–∂–∞–∫–µ—Ç', '–∂–∞–∫–µ—Ç—ã',
        '–±–ª–µ–π–∑–µ—Ä', '–±–ª–µ–π–∑–µ—Ä—ã',
        '–∫–æ—Ñ—Ç–∞', '–∫–æ—Ñ—Ç—ã',
        '—Ç–æ–ª—Å—Ç–æ–≤–∫–∞', '—Ç–æ–ª—Å—Ç–æ–≤–∫–∏',
        '—Ö—É–¥–∏', '—Ö—É–¥–∏',
        '—Å–≤–∏—Ç—à–æ—Ç', '—Å–≤–∏—Ç—à–æ—Ç—ã',
        '–≤–æ–¥–æ–ª–∞–∑–∫–∞', '–≤–æ–¥–æ–ª–∞–∑–∫–∏',
        '–±–æ–¥–∏', '–±–æ–¥–∏',
        '–∫–æ–º–ø–ª–µ–∫—Ç', '–∫–æ–º–ø–ª–µ–∫—Ç—ã',
        '–∞–Ω—Å–∞–º–±–ª—å', '–∞–Ω—Å–∞–º–±–ª–∏',
        '–ª—É–∫', '–ª—É–∫–∏',
        '–æ–±—Ä–∞–∑', '–æ–±—Ä–∞–∑—ã',
        '–≥–∞—Ä–¥–µ—Ä–æ–±', '–≥–∞—Ä–¥–µ—Ä–æ–±',
        '–∂–µ–Ω—Å–∫', '–º—É–∂—Å–∫',
        '–¥–µ—Ç—Å–∫',
        '–≤–µ—Ä—Ö–Ω—è—è –æ–¥–µ–∂–¥–∞',
        '–Ω–∏–∂–Ω–µ–µ –±–µ–ª—å–µ',
        '—Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è –æ–¥–µ–∂–¥–∞',
        '–¥–æ–º–∞—à–Ω—è—è –æ–¥–µ–∂–¥–∞',
        '—Ä–∞–±–æ—á–∞—è –æ–¥–µ–∂–¥–∞',
        '–¥–µ–ª–æ–≤–∞—è –æ–¥–µ–∂–¥–∞',
        '–ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è –æ–¥–µ–∂–¥–∞',
        '–≤–µ—á–µ—Ä–Ω—è—è –æ–¥–µ–∂–¥–∞',
        '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω–∞—è –æ–¥–µ–∂–¥–∞',
        '–Ω–æ–≤–æ–≥–æ–¥–Ω', '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤'
    ]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ
    for keyword in clothing_keywords:
        if keyword in query_lower:
            return True
    
    return False

def detect_garbage_queries(df):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –º—É—Å–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ –∏ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ—à–∏–±–æ–∫:
    1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏
    2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
    3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∏—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ—à–∏–±–æ–∫ (–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –±—É–∫–≤—ã, –∑–∞–º–µ–Ω—ã)
    4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–ª–æ–≤–∞ (—Å–ª–æ–≤–∞, –Ω–µ –ø–æ—Ö–æ–∂–∏–µ –Ω–∏ –Ω–∞ –æ–¥–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ)
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å–∫—É –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –º—É—Å–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    if df is None or df.empty or "–ó–∞–ø—Ä–æ—Å" not in df.columns:
        return pd.Series([False] * len(df), index=df.index)
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Å–ª–æ–≤ (–æ–¥–µ–∂–¥–∞, –æ–±—É–≤—å, –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã, –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ)
    correct_words = {
        # –û–¥–µ–∂–¥–∞
        '–¥–∂–∏–Ω—Å—ã', '–ø–ª–∞—Ç—å–µ', '–∫—É—Ä—Ç–∫–∞', '—à—É–±–∞', '–ø—É—Ö–æ–≤–∏–∫', '–¥—É–±–ª–µ–Ω–∫–∞', 
        '–ø–∏–¥–∂–∞–∫', '–ø–ª–∞—Ç—å—è', '–∫—É—Ä—Ç–∫–∏', '—à—É–±—ã', '–ø—É—Ö–æ–≤–∏–∫–∏', '–¥—É–±–ª–µ–Ω–∫–∏',
        '—à—Ç–∞–Ω—ã', '–¥—É—Ç–∏–∫–∏', '–±—Ä—é–∫–∏', '–±—Ä—é–∫', '–∫–æ–º–±–∏–Ω–µ–∑–æ–Ω', '–∫–∞–ø—é—à–æ–Ω–æ–º',
        '–∫–æ—Å—Ç—é–º', '—é–±–∫–∞', '—Ä—É–±–∞—à–∫–∞', '—Ñ—É—Ç–±–æ–ª–∫–∞', '—Å–≤–∏—Ç–µ—Ä', '–ø–∞–ª—å—Ç–æ',
        '–±–ª—É–∑–∫–∞', '—Å–∞—Ä–∞—Ñ–∞–Ω', '—Ç–æ–ø', '–º–∞–π–∫–∞', '–¥–∂–µ–º–ø–µ—Ä', '–∫–∞—Ä–¥–∏–≥–∞–Ω',
        '–∂–∏–ª–µ—Ç', '–±–æ–º–±–µ—Ä', '–≤–µ—Ç—Ä–æ–≤–∫–∞', '—à–æ—Ä—Ç—ã', '–±–ª—É–∑–∞', '—Ç—É–Ω–∏–∫–∞',
        '—Ö–∞–ª–∞—Ç', '–∫–∏–º–æ–Ω–æ', '–ø–ª–∞—â', '—Ç—Ä–µ–Ω—á', '–ø–æ–ª—É—à—É–±–æ–∫', '–∂–∞–∫–µ—Ç',
        '–±–ª–µ–π–∑–µ—Ä', '–∫–æ—Ñ—Ç–∞', '—Ç–æ–ª—Å—Ç–æ–≤–∫–∞', '—Ö—É–¥–∏', '—Å–≤–∏—Ç—à–æ—Ç', '–≤–æ–¥–æ–ª–∞–∑–∫–∞',
        '–±–æ–¥–∏', '–∫–æ–º–ø–ª–µ–∫—Ç', '–∞–Ω—Å–∞–º–±–ª—å',
        # –û–±—É–≤—å
        '—É–≥–≥–∏', '–æ–±—É–≤—å', '—Ç—É—Ñ–ª–∏', '–±–æ—Ç–∏–Ω–∫–∏', '–∫—Ä–æ—Å—Å–æ–≤–∫–∏', '—Å–∞–ø–æ–≥–∏',
        # –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –æ–ø–∏—Å–∞–Ω–∏—è
        '–¥–ª–∏–Ω–Ω—ã–µ', '–¥–ª–∏–Ω–Ω–æ–µ', '–¥–ª–∏–Ω–Ω—ã–π', '–¥–ª–∏–Ω–Ω–∞—è', '–¥–ª–∏–Ω–Ω—ã—Ö', '–¥–ª–∏–Ω–Ω—ã–º', '–¥–ª–∏–Ω–Ω—ã–º–∏',
        '–Ω–∞—Ä—è–¥–Ω–æ–µ', '–Ω–∞—Ä—è–¥–Ω—ã–µ', '–Ω–∞—Ä—è–¥–Ω—ã–π', '–Ω–∞—Ä—è–¥–Ω–∞—è', '–Ω–∞—Ä—è–¥–Ω—ã—Ö', '–Ω–∞—Ä—è–¥–Ω—ã–º', '–Ω–∞—Ä—è–¥–Ω—ã–º–∏',
        '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω–æ–µ', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–π', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω–∞—è', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã—Ö', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–º', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–º–∏',
        '–Ω–æ–≤–æ–≥–æ–¥–Ω–µ–µ', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏–µ', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏–π', '–Ω–æ–≤–æ–≥–æ–¥–Ω—è—è', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏—Ö', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏–º', '–Ω–æ–≤–æ–≥–æ–¥–Ω–∏–º–∏',
        '—Å—Ç–∏–ª—å–Ω–æ–µ', '—Å—Ç–∏–ª—å–Ω—ã–µ', '—Å—Ç–∏–ª—å–Ω—ã–π', '—Å—Ç–∏–ª—å–Ω–∞—è', '—Å—Ç–∏–ª—å–Ω—ã—Ö', '—Å—Ç–∏–ª—å–Ω—ã–º', '—Å—Ç–∏–ª—å–Ω—ã–º–∏',
        '–∫—Ä–∞—Å–∏–≤–æ–µ', '–∫—Ä–∞—Å–∏–≤—ã–µ', '–∫—Ä–∞—Å–∏–≤—ã–π', '–∫—Ä–∞—Å–∏–≤–∞—è', '–∫—Ä–∞—Å–∏–≤—ã—Ö', '–∫—Ä–∞—Å–∏–≤—ã–º', '–∫—Ä–∞—Å–∏–≤—ã–º–∏',
        '—á–µ—Ä–Ω–æ–µ', '—á–µ—Ä–Ω—ã–µ', '—á–µ—Ä–Ω—ã–π', '—á–µ—Ä–Ω–∞—è', '—á–µ—Ä–Ω—ã—Ö', '—á–µ—Ä–Ω—ã–º', '—á–µ—Ä–Ω—ã–º–∏',
        '–±–µ–ª–∞—è', '–±–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–∞—è', '–∫–æ—Ä–∏—á–Ω–µ–≤–∞—è', '—Å–µ—Ä–∞—è', '—à–æ–∫–æ–ª–∞–¥–Ω–æ–≥–æ',
        '—Ü–≤–µ—Ç–∞', '—à–∏—Ä–æ–∫–∏–µ', '—É—Ç–µ–ø–ª–µ–Ω–Ω—ã–µ', '–Ω–∞—Ç—É—Ä–∞–ª—å–Ω–∞—è', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–∞—è',
        '–∂–µ–Ω—Å–∫–∞—è', '–∂–µ–Ω—Å–∫–∏–π', '–∂–µ–Ω—Å–∫–∏–µ', '–∂–µ–Ω—Å–∫–æ–µ',
        '–¥–µ—Ç—Å–∫–∏–µ', '–¥–µ—Ç—Å–∫–æ–µ', '–¥–µ—Ç—Å–∫–∏–π', '–¥–µ—Ç—Å–∫–∞—è', '–¥–µ—Ç—Å–∫–∏—Ö', '–¥–µ—Ç—Å–∫–∏–º', '–¥–µ—Ç—Å–∫–∏–º–∏',
        '–∑–∏–º–Ω—è—è', '–∑–∏–º–Ω–∏–µ', '–∑–∏–º–Ω–∏–π', '–∑–∏–º–∞', '–∑–∏–º–Ω–µ–µ',
        '–≤–µ—á–µ—Ä–Ω–µ–µ', '–≤–µ—á–µ—Ä–Ω–∏–µ', '–≤–µ—á–µ—Ä–Ω–∏–π', '–≤–µ—á–µ—Ä–Ω—è—è',
        # –î—Ä—É–≥–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        '–∫–ª–µ—à', '–∞–ª–∏—Å–∞', '—Å—Ç–∞–Ω—Ü–∏—è', '—è–Ω–¥–µ–∫—Å', '–ø–ª—é—Å',
        '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∏', '–æ–¥–µ–∂–¥–∞', '–æ–¥–µ–∂–¥—É',
        '–Ω–∞—Ä—è–¥', '–Ω–∞—Ä—è–¥—ã', '–æ–±—Ä–∞–∑', '–æ–±—Ä–∞–∑—ã', '–ª—É–∫',
        '–Ω–æ—Ä–∫–∞', '–Ω–æ—Ä–∫–æ–≤–∞—è', '–Ω–æ—Ä–∫—É', '–Ω–∞—á–µ—Å–æ–º', '–∫–æ–ª–µ–Ω–∞', '—ç–∫–æ',
        '—ç–∫—Ä–∞–Ω–æ–º', '–≥–æ—Ä–Ω–æ–ª—ã–∂–Ω—ã–π', '–∞–≤—Ç–æ–ª–µ–¥–∏', '–ø–∞–ª–∞—Ü—Ü–æ', '—Ç–µ–¥–¥–∏',
        '—Ç–µ–ª–æ–¥–≤–∏–∂–µ–Ω–∏–µ', '—Ç—Ä—É–±—ã', '—É–º–Ω–∞—è', '–∫–æ–ª–æ–Ω–∫–∞', '–∫–æ—Ä–æ—Ç–∫–∞—è',
        '–≤—ã—Å–æ–∫–∏–π', '—Ä–æ—Å—Ç', '–¥–æ–º–∞', '–∫–∞', '–∫–æ', '4–∫'
    }
    
    # –°–ª–æ–≤–∞—Ä—å —Ç–∏–ø–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
    known_typos = {
        # –î–∂–∏–Ω—Å—ã
        '–¥–∂–∏—Å—ã', '–¥–∂–Ω—Å—ã', '–¥–∂—Ä–Ω—Å—ã', '–¥–∂–∏–Ω—Ü–∏', '–¥–∂–∏–Ω—Ü—ã', '–¥–∂–∏–Ω—Å—Ü', '–¥–∂–∏–Ω—Ü–≤',
        '–∂—ã–Ω—Å—ã', '–∂–¥–∏–Ω—Å—ã', '–∂–¥—ã–Ω—Å—ã', '–¥–∂–∏–≥—Å—ã', '–¥–∑–∏–Ω—Å—ã', '–∂–∏–Ω—Å–∏', '–¥–∂—ã–Ω—Ü—ã',
        # –ü–ª–∞—Ç—å–µ
        '–ø–ª—Ç—å–µ', '–ø–ª–∞—å–µ', '–ø–∞—Ç—å–µ', '–ø–æ–ø—Ç—å–µ', '–ø–ª–∞—Ç—è',
        # –ö—É—Ä—Ç–∫–∞
        '–∫–∫—Ä—Ç–∫–∞', '–∫—Ä—É—Ç–∫–∞', '–∫—Ü—Ä—Ç–∫–∞', '–∫—É—Ç—Ä–∫–∞', '—É—É—Ä—Ç–∫–∞', '–∫—É—Ä—Ç–∫–µ', '–µ—É—Ä—Ç–∫–∞',
        # –®—É–±–∞
        '—à–±–∞', '—à—É–±—É–∞', '—à–∫–±–∫–∞', '—à—Ü–±–∞', '—ç–∫–æ—â—É–±–∞', '—ç–∫–æ—à—É—å–∞', '—é–±—É–∞',
        # –ü—É—Ö–æ–≤–∏–∫
        '–ø—É—Ö—Ä–≤–∏–∫', '–ø—É—Ö–æ–≤—Ç–∫', '–ø—É–∑–æ–≤–∏–∫',
        # –î—É–±–ª–µ–Ω–∫–∞
        '–¥—É–±–µ–Ω–∫–∞', '–¥—É–±–ª–µ–∫–∞', '–¥—É–±–ª–µ–Ω–∫—É',
        # –ö–ª–µ—à
        '–∫–ª–µ—à—å', '–∫–ª—ç—à', '–∫–ª—à–µ', '—É–ª–µ—à',
        # –ê–ª–∏—Å–∞
        '–≤–ª–∏—Å–∞', '–∞–ª–∏—Å–ø', '–∞–ª—Ç—Å–∞',
        # –°—Ç–∞–Ω—Ü–∏—è
        '—Å—Ç–∞–Ω—Ü—ã—è', '—Å—Ç–∞–Ω—É–∏—è',
        # –Ø–Ω–¥–µ–∫—Å
        '—á–Ω–¥–µ–∫—Å',
        # –ü–ª—é—Å
        '–ø–ª–∏—Å–∞',
        # –£–≥–≥–∏
        '—é–≥–≥–∏', '—É–≥–≥—É', '—É–≥—à–∏', '—É–≥–Ω–º', '—É–≥–∏', '—É—É–≥–∏', '—ç—É–¥–∏',
        # –ü–∏–¥–∂–∞–∫
        '–ø–∏–Ω–¥–∂–∞–∫',
        # –®—Ç–∞–Ω—ã
        '—à–∞—Ç–Ω—ã',
        # –î—É—Ç–∏–∫–∏
        '–¥—É—å–∏–∫–∏', '–ª—É—Ç–∏–∫–∏', '–¥–∫—Ç–∏–∫–∏', '–¥—É—Ç–∏—É–∏', '–¥—É—Ç–º–∫–∏',
        # –î—Ä—É–≥–∏–µ
        '–ø–∞—Ä—É–∞',
    }
    
    mask_garbage = pd.Series([False] * len(df), index=df.index)
    queries = df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.lower().str.strip()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å
    for idx, query in queries.items():
        if pd.isna(query) or not query:
            continue
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å–ª–æ–≤–∞
        words = query.split()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ñ—Ä–∞–∑—ã —Å –æ—à–∏–±–∫–∞–º–∏
        query_lower = query.lower().strip()
        known_garbage_phrases = [
            '—à–∞—Ç–Ω—ã –∫–ª–µ—à', '—É—É–≥–∏', '—é–±—É–∞', '–¥—É—å–∏–∫–∏', '–ª—É—Ç–∏–∫–∏', 
            '–¥–∫—Ç–∏–∫–∏', '–¥—É—Ç–∏—É–∏', '–¥—É—Ç–º–∫–∏', '–ø–∏–Ω–¥–∂–∞–∫', '—ç—É–¥–∏'
        ]
        for phrase in known_garbage_phrases:
            if phrase in query_lower:
                mask_garbage[idx] = True
                break
        
        if mask_garbage[idx]:
            continue  # –£–∂–µ –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ –º—É—Å–æ—Ä, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∞–ª—å–Ω–µ–π—à–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –≤ –∑–∞–ø—Ä–æ—Å–µ
        # –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ —Å –æ—à–∏–±–∫–æ–π –∏–ª–∏ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ - —Ñ–∏–ª—å—Ç—Ä—É–µ–º –≤–µ—Å—å –∑–∞–ø—Ä–æ—Å
        has_error = False
        valid_words_count = 0  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ
        
        for word in words:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–ø—Ä–µ–¥–ª–æ–≥–∏, —Å–æ—é–∑—ã) - –æ–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å —á–∞—Å—Ç—å—é –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            if len(word) < 3:
                # –ù–æ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ –æ–¥–Ω–æ–≥–æ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Å–ª–æ–≤–∞ - —ç—Ç–æ –º—É—Å–æ—Ä
                if len(words) == 1:
                    has_error = True
                    break
                continue
            
            # 1. –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏
            if word in known_typos:
                has_error = True
                break
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (–±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è)
            word_is_valid = False  # –§–ª–∞–≥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º
            max_similarity = 0.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
            
            for correct_word in correct_words:
                if word == correct_word:
                    word_is_valid = True  # –≠—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ
                    valid_words_count += 1
                    break
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤—É —Å–ª–æ–≤–∞ (–ø–µ—Ä–≤—ã–µ 2-3 –±—É–∫–≤—ã) - –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
                if len(word) >= 2 and len(correct_word) >= 2:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 2-3 –±—É–∫–≤—ã
                    word_start = word[:min(3, len(word))]
                    correct_start = correct_word[:min(3, len(correct_word))]
                    
                    # –ï—Å–ª–∏ –Ω–∞—á–∞–ª–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç (—Ö–æ—Ç—è –±—ã 2 –±—É–∫–≤—ã), –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–ª—å—à–µ
                    if word_start[:2] == correct_start[:2] or word_start == correct_start:
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–∏–º–≤–æ–ª–æ–≤
                        matches = sum(1 for a, b in zip(word, correct_word) if a == b)
                        similarity = matches / max(len(word), len(correct_word))
                        max_similarity = max(max_similarity, similarity)
                        
                        # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –ø–æ—Ö–æ–∂–µ—Å—Ç—å >= 0.65, —ç—Ç–æ –æ—à–∏–±–∫–∞
                        if similarity >= 0.65 and similarity < 1.0:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –¥—Ä—É–≥–æ–µ –æ–∫–æ–Ω—á–∞–Ω–∏–µ
                            # –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –¥–ª–∏–Ω–µ <= 3, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—à–∏–±–∫–∞
                            if abs(len(word) - len(correct_word)) <= 3:
                                has_error = True
                                break
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2-3 –±—É–∫–≤—ã (–¥–ª—è —Å–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏ –≤ –Ω–∞—á–∞–ª–µ)
                    if len(word) >= 2 and len(correct_word) >= 2:
                        word_end = word[-min(3, len(word)):]
                        correct_end = correct_word[-min(3, len(correct_word)):]
                        
                        # –ï—Å–ª–∏ –∫–æ–Ω–µ—Ü —Å–æ–≤–ø–∞–¥–∞–µ—Ç (—Ö–æ—Ç—è –±—ã 2 –±—É–∫–≤—ã), –Ω–æ –Ω–∞—á–∞–ª–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è
                        if (word_end[-2:] == correct_end[-2:] or word_end == correct_end) and word_start != correct_start:
                            # –ö–æ–Ω–µ—Ü —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –Ω–æ –Ω–∞—á–∞–ª–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è - –≤–æ–∑–º–æ–∂–Ω–∞ –æ—à–∏–±–∫–∞
                            matches = sum(1 for a, b in zip(word, correct_word) if a == b)
                            similarity = matches / max(len(word), len(correct_word))
                            max_similarity = max(max_similarity, similarity)
                            if similarity >= 0.6 and similarity < 1.0:
                                if abs(len(word) - len(correct_word)) <= 3:
                                    has_error = True
                                    break
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
                    # –ü—Ä–æ–ø—É—â–µ–Ω–Ω–∞—è –±—É–∫–≤–∞ (—Å–ª–æ–≤–æ –∫–æ—Ä–æ—á–µ –Ω–∞ 1-2)
                    if len(word) >= len(correct_word) - 2 and len(word) < len(correct_word):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –±—É–∫–≤
                        if word_start[:2] == correct_start[:2] or (len(word) >= 2 and len(correct_word) >= 2 and word[-2:] == correct_word[-2:]):
                            matches = sum(1 for a, b in zip(word, correct_word) if a == b)
                            similarity = matches / max(len(word), len(correct_word))
                            max_similarity = max(max_similarity, similarity)
                            if similarity >= 0.65:
                                has_error = True
                                break
                    
                    # –ó–∞–º–µ–Ω–∞ –±—É–∫–≤ (–æ–¥–∏–Ω–∞–∫–æ–≤–∞—è –∏–ª–∏ –ø–æ—á—Ç–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–∞—è –¥–ª–∏–Ω–∞)
                    if abs(len(word) - len(correct_word)) <= 2:
                        diff_count = sum(1 for a, b in zip(word, correct_word) if a != b)
                        # –ï—Å–ª–∏ 1-3 –∑–∞–º–µ–Ω—ã –∏ –Ω–∞—á–∞–ª–æ/–∫–æ–Ω–µ—Ü —Å–æ–≤–ø–∞–¥–∞—é—Ç - —ç—Ç–æ –æ—à–∏–±–∫–∞
                        if diff_count <= 3:
                            if (word_start[:2] == correct_start[:2] or 
                                (len(word) >= 2 and len(correct_word) >= 2 and word[-2:] == correct_word[-2:])):
                                matches = sum(1 for a, b in zip(word, correct_word) if a == b)
                                similarity = matches / max(len(word), len(correct_word))
                                max_similarity = max(max_similarity, similarity)
                                if similarity >= 0.65:
                                    has_error = True
                                    break
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫—É –±—É–∫–≤ (–∞–Ω–∞–≥—Ä–∞–º–º—ã —Å –æ—à–∏–±–∫–∞–º–∏)
                    if len(word) == len(correct_word):
                        # –ï—Å–ª–∏ —Å–ª–æ–≤–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã –∏ –∏–º–µ—é—Ç –º–Ω–æ–≥–æ –æ–±—â–∏—Ö –±—É–∫–≤, –Ω–æ –ø–æ—Ä—è–¥–æ–∫ –Ω–∞—Ä—É—à–µ–Ω
                        word_chars = sorted(word)
                        correct_chars = sorted(correct_word)
                        if word_chars == correct_chars and word != correct_word:
                            # –≠—Ç–æ –∞–Ω–∞–≥—Ä–∞–º–º–∞ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –æ—à–∏–±–∫–∞
                            matches = sum(1 for a, b in zip(word, correct_word) if a == b)
                            similarity = matches / max(len(word), len(correct_word))
                            max_similarity = max(max_similarity, similarity)
                            if similarity >= 0.5:  # –î–∞–∂–µ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –ø–æ—Ö–æ–∂–µ—Å—Ç–∏, –µ—Å–ª–∏ —ç—Ç–æ –∞–Ω–∞–≥—Ä–∞–º–º–∞
                                has_error = True
                                break
                
                if has_error:
                    break
            
            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–ª–æ–≤–∞ (–º–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è)
            # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–µ –ø–æ—Ö–æ–∂–µ –Ω–∏ –Ω–∞ –æ–¥–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ (–æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å), —ç—Ç–æ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–ª–æ–≤–æ
            if not word_is_valid and not has_error and len(word) >= 5:  # –¢–æ–ª—å–∫–æ –¥–ª—è —Å–ª–æ–≤ –¥–ª–∏–Ω–æ–π >= 5
                # –ï—Å–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Å–æ –≤—Å–µ–º–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ < 0.3, —ç—Ç–æ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–ª–æ–≤–æ
                # –ü–æ–≤—ã—à–µ–Ω –ø–æ—Ä–æ–≥ —Å 0.5 –¥–æ 0.3, —á—Ç–æ–±—ã –Ω–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
                if max_similarity < 0.3:
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —Å–ª–æ–≤–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –±—É–∫–≤
                    # –∏–ª–∏ –Ω–µ –ø–æ—Ö–æ–∂–µ –Ω–∏ –Ω–∞ –æ–¥–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –µ–≥–æ
                    has_error = True
                    break
            
            if has_error:
                break
        
        # –ú–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏:
        # 1. –ï—Å—Ç—å —è–≤–Ω–∞—è –æ—à–∏–±–∫–∞ (–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ–ø–µ—á–∞—Ç–∫–∞) –ò–õ–ò
        # 2. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Å–ª–æ–≤ (>= 50%) –∏–º–µ—é—Ç –æ—à–∏–±–∫–∏ –ò–õ–ò
        # 3. –í—Å–µ —Å–ª–æ–≤–∞ –¥–ª–∏–Ω–æ–π >= 4 –∏–º–µ—é—Ç –æ—à–∏–±–∫–∏
        words_with_errors = 0
        total_checkable_words = 0
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–æ–≤–∞ —Å –æ—à–∏–±–∫–∞–º–∏
        for word in words:
            if len(word) >= 4:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ –¥–ª–∏–Ω–æ–π >= 4
                total_checkable_words += 1
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–æ —Å–ª–æ–≤–æ –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ–ø–µ—á–∞—Ç–∫–∞—Ö
                if word in known_typos:
                    words_with_errors += 1
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
                elif word not in correct_words:
                    # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–µ –≤ —Å–ø–∏—Å–∫–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö, –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ö–æ–∂–µ—Å—Ç—å
                    max_sim = 0.0
                    for correct_word in correct_words:
                        if len(word) >= 2 and len(correct_word) >= 2:
                            matches = sum(1 for a, b in zip(word, correct_word) if a == b)
                            similarity = matches / max(len(word), len(correct_word))
                            max_sim = max(max_sim, similarity)
                    # –ï—Å–ª–∏ –ø–æ—Ö–æ–∂–µ—Å—Ç—å –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è (< 0.3), —Å—á–∏—Ç–∞–µ–º –æ—à–∏–±–∫–æ–π
                    if max_sim < 0.3:
                        words_with_errors += 1
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏:
        # - –ï—Å—Ç—å —è–≤–Ω–∞—è –æ—à–∏–±–∫–∞ (–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ–ø–µ—á–∞—Ç–∫–∞) –ò–õ–ò
        # - –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã—Ö —Å–ª–æ–≤ (>= 50%) –∏–º–µ—é—Ç –æ—à–∏–±–∫–∏ –ò–õ–ò
        # - –í—Å–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–µ —Å–ª–æ–≤–∞ –∏–º–µ—é—Ç –æ—à–∏–±–∫–∏
        if has_error:  # –Ø–≤–Ω–∞—è –æ—à–∏–±–∫–∞ (–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ–ø–µ—á–∞—Ç–∫–∞)
            mask_garbage[idx] = True
        elif total_checkable_words > 0:
            error_ratio = words_with_errors / total_checkable_words
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ >= 50% —Å–ª–æ–≤ –∏–º–µ—é—Ç –æ—à–∏–±–∫–∏
            if error_ratio >= 0.5:
                mask_garbage[idx] = True
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–ª–æ–≤
        elif valid_words_count == 0 and len(words) > 0:
            long_words = [w for w in words if len(w) >= 5]
            if len(long_words) >= 2:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –º–∏–Ω–∏–º—É–º 2 –¥–ª–∏–Ω–Ω—ã—Ö —Å–ª–æ–≤–∞
                mask_garbage[idx] = True
    
    return mask_garbage

def get_clothing_keywords_pattern():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ–¥–µ–∂–¥–æ–π"""
    clothing_keywords = [
        '–ø–ª–∞—Ç—å–µ', '–ø–ª–∞—Ç—å—è', '–∫—É—Ä—Ç–∫–∞', '—à—É–±–∞', '–Ω–∞—Ä—è–¥', '–æ–¥–µ–∂–¥–∞',
        '–∫–æ—Å—Ç—é–º', '–±—Ä—é–∫–∏', '—é–±–∫–∞', '—Ä—É–±–∞—à–∫–∞', '—Ñ—É—Ç–±–æ–ª–∫–∞', '—Å–≤–∏—Ç–µ—Ä',
        '–ø–∞–ª—å—Ç–æ', '–ø–∏–¥–∂–∞–∫', '–±–ª—É–∑–∫–∞', '—Å–∞—Ä–∞—Ñ–∞–Ω', '–∫–æ–º–±–∏–Ω–µ–∑–æ–Ω',
        '—Ç–æ–ø', '–º–∞–π–∫–∞', '–¥–∂–µ–º–ø–µ—Ä', '–∫–∞—Ä–¥–∏–≥–∞–Ω', '–∂–∏–ª–µ—Ç', '–±–æ–º–±–µ—Ä',
        '–ø—É—Ö–æ–≤–∏–∫', '–≤–µ—Ç—Ä–æ–≤–∫–∞', '–¥–∂–∏–Ω—Å—ã', '—à–æ—Ä—Ç—ã', '–±–ª—É–∑–∞', '—Ç—É–Ω–∏–∫–∞',
        '—Ö–∞–ª–∞—Ç', '–∫–∏–º–æ–Ω–æ', '–ø–ª–∞—â', '—Ç—Ä–µ–Ω—á', '–¥—É–±–ª–µ–Ω–∫–∞', '–ø–æ–ª—É—à—É–±–æ–∫',
        '–∂–∞–∫–µ—Ç', '–±–ª–µ–π–∑–µ—Ä', '–∫–æ—Ñ—Ç–∞', '—Ç–æ–ª—Å—Ç–æ–≤–∫–∞', '—Ö—É–¥–∏', '—Å–≤–∏—Ç—à–æ—Ç',
        '–≤–æ–¥–æ–ª–∞–∑–∫–∞', '–±–æ–¥–∏', '–∫–æ–º–ø–ª–µ–∫—Ç', '–∞–Ω—Å–∞–º–±–ª—å', '–ª—É–∫', '–æ–±—Ä–∞–∑',
        '–≥–∞—Ä–¥–µ—Ä–æ–±', '–∂–µ–Ω—Å–∫', '–º—É–∂—Å–∫', '–¥–µ—Ç—Å–∫', '–≤–µ—Ä—Ö–Ω—è—è –æ–¥–µ–∂–¥–∞',
        '–Ω–∏–∂–Ω–µ–µ –±–µ–ª—å–µ', '—Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è –æ–¥–µ–∂–¥–∞', '–¥–æ–º–∞—à–Ω—è—è –æ–¥–µ–∂–¥–∞',
        '—Ä–∞–±–æ—á–∞—è –æ–¥–µ–∂–¥–∞', '–¥–µ–ª–æ–≤–∞—è –æ–¥–µ–∂–¥–∞', '–ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è –æ–¥–µ–∂–¥–∞',
        '–≤–µ—á–µ—Ä–Ω—è—è –æ–¥–µ–∂–¥–∞', '–ø—Ä–∞–∑–¥–Ω–∏—á–Ω–∞—è –æ–¥–µ–∂–¥–∞', '–Ω–æ–≤–æ–≥–æ–¥–Ω', '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤'
    ]
    return '|'.join(clothing_keywords)

def apply_filters(df, minus_words_dict, clothing_filter, use_garbage_filter, products_min, products_max, frequency_wb_min, frequency_wb_max, use_automatic_filters=False, use_brand_filter=False, english_queries_to_keep=None):
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ - –ø—Ä–∏–º–µ–Ω—è–µ—Ç –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥
    
    Args:
        english_queries_to_keep: –°–ø–∏—Å–æ–∫ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å (None = –Ω–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å)
    """
    # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –æ–¥–∏–Ω —Ä–∞–∑, –ø—Ä–∏–º–µ–Ω—è–µ–º –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã —Å—Ä–∞–∑—É
    mask = pd.Series([True] * len(df), index=df.index)
    
    # –§–∏–ª—å—Ç—Ä –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    if english_queries_to_keep is not None and "–ó–∞–ø—Ä–æ—Å" in df.columns:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã —è–≤–ª—è—é—Ç—Å—è –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–º–∏
        english_df = detect_english_queries(df)
        english_indices = set(english_df.index) if not english_df.empty else set()
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–∏–∑ —Ñ–∞–π–ª–∞):
        if len(english_queries_to_keep) > 0:
            # 1. –û—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ –Ω–µ–∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            # 2. –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            queries_lower = df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.lower().str.strip()
            queries_to_keep_set = {q.lower().strip() for q in english_queries_to_keep}
            
            # –ú–∞—Å–∫–∞: –Ω–µ–∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –ò–õ–ò —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ
            is_not_english = ~df.index.isin(english_indices)
            is_selected_english = queries_lower.isin(queries_to_keep_set) & df.index.isin(english_indices)
            mask = mask & (is_not_english | is_selected_english)
        else:
            # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç–æ–π, –∏—Å–∫–ª—é—á–∞–µ–º –≤—Å–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            if english_indices:
                mask = mask & ~df.index.isin(english_indices)
    
    # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –§–ò–õ–¨–¢–†–´: –ü—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã
    if use_automatic_filters and "–ó–∞–ø—Ä–æ—Å" in df.columns:
        # –ü–ï–†–í–ò–ß–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã –∏–∑ 1-3 –±—É–∫–≤ (–º—É—Å–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã)
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∑–∞–ø—Ä–æ—Å–∞
        query_lengths = df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.strip().str.len()
        # –ò—Å–∫–ª—é—á–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã –¥–ª–∏–Ω–æ–π 1-3 —Å–∏–º–≤–æ–ª–∞ (—ç—Ç–æ –ø—Ä–µ–¥–ª–æ–≥–∏, —Å–æ—é–∑—ã, –±—É–∫–≤—ã)
        mask = mask & (query_lengths > 3)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: —Ñ–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ—Å—Ç–æ—è—Ç —Ç–æ–ª—å–∫–æ –∏–∑ –ø—Ä–µ–¥–ª–æ–≥–æ–≤/—Å–æ—é–∑–æ–≤
        prepositions_short = ['–≤', '–∫', '—Å', '–æ—Ç', '–ø–æ', '–Ω–∞', '–∑–∞', '–¥–ª—è', '–¥–æ', '–Ω–µ', '–Ω–æ', '–æ–±', '—Ç–µ', '–¥–∞', '–æ', '—É', '–∏–∑', '—Å–æ', '–ø–æ–¥', '–Ω–∞–¥', '–ø—Ä–∏', '–ø—Ä–æ', '–±–µ–∑', '–≤–æ']
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å –æ–¥–Ω–∏–º –∏–∑ –ø—Ä–µ–¥–ª–æ–≥–æ–≤/—Å–æ—é–∑–æ–≤
        queries_lower = df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.lower().str.strip()
        is_preposition = queries_lower.isin(prepositions_short)
        mask = mask & ~is_preposition
        
        # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï: –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏
        garbage_mask = detect_garbage_queries(df)
        mask = mask & ~garbage_mask
        
        # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫
        # –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –Ω–∞–π—Ç–∏ –∑–∞–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –æ—à–∏–±–∫–∏ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–≤–∞—Ö
        queries_lower = df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.lower().str.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏
        known_garbage_phrases = [
            '—É–≥–∏ –¥–µ—à–µ–≤—ã–µ', '–¥–∂–∏–Ω—Ü–≤', '–ø–∞—Ä—É–∞', '–¥–∂—ã–Ω—Ü—ã', '—é–≥–≥–∏', '—É–≥–≥—É', 
            '—É–≥—à–∏', '—É–≥–Ω–º', '–∞–ª—Ç—Å–∞', '–∂–∏–Ω—Å–∏', '–¥–∂–∏–Ω—Å—Ü', '–ø–ª–∞—å–µ', '–ø–∞—Ç—å–µ'
        ]
        for phrase in known_garbage_phrases:
            mask = mask & ~queries_lower.str.contains(phrase, case=False, na=False)
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –º–∏–Ω—É—Å —Å–ª–æ–≤–∞ (–±—Ä–µ–Ω–¥–æ–≤—ã–µ + –æ—Å—Ç–∞–ª—å–Ω—ã–µ)
    all_minus_words = get_all_minus_words(minus_words_dict) if minus_words_dict else []
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ –∏–∑ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ OpenAI (–≤—Å–µ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è)
    openai_typos = load_openai_typos()
    for word in openai_typos:
        if word not in all_minus_words:
            all_minus_words.append(word)
    
    # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ñ–∏–ª—å—Ç—Ä –º—É—Å–æ—Ä–Ω—ã—Ö —Å–ª–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –∫ –º–∏–Ω—É—Å —Å–ª–æ–≤–∞–º
    if use_garbage_filter:
        garbage_words = get_default_garbage_words()
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ
        for word in garbage_words:
            if word not in all_minus_words:
                all_minus_words.append(word)
    
    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 1: –ú–∏–Ω—É—Å —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –æ–¥–Ω–æ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ (–≤–º–µ—Å—Ç–æ —Ü–∏–∫–ª–∞)
    if all_minus_words:
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ —Å–æ–∑–¥–∞–µ–º –æ–¥–Ω–æ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
        escaped_words = [re.escape(word.strip()) for word in all_minus_words if word.strip()]
        if escaped_words:
            pattern = '|'.join(escaped_words)
            mask = mask & ~df["–ó–∞–ø—Ä–æ—Å"].str.contains(pattern, case=False, na=False, regex=True)
    
    # –§–∏–ª—å—Ç—Ä –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    if use_brand_filter and "–ó–∞–ø—Ä–æ—Å" in df.columns:
        brand_queries = load_brand_queries()
        if brand_queries:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ —Å–æ–∑–¥–∞–µ–º –æ–¥–Ω–æ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
            escaped_brands = [re.escape(brand.strip()) for brand in brand_queries if brand.strip()]
            if escaped_brands:
                pattern = '|'.join(escaped_brands)
                mask = mask & ~df["–ó–∞–ø—Ä–æ—Å"].str.contains(pattern, case=False, na=False, regex=True)
    
    # –§–∏–ª—å—Ç—Ä –ø–æ –æ–¥–µ–∂–¥–µ —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é (–≤–º–µ—Å—Ç–æ apply)
    clothing_mask = None
    if clothing_filter is not None and "–ó–∞–ø—Ä–æ—Å" in df.columns:
        if clothing_filter in ["–¢–æ–ª—å–∫–æ –æ–¥–µ–∂–¥–∞", "–ë–µ–∑ –æ–¥–µ–∂–¥—ã"]:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞
            pattern = get_clothing_keywords_pattern()
            clothing_mask = df["–ó–∞–ø—Ä–æ—Å"].str.contains(pattern, case=False, na=False, regex=True)
            
            if clothing_filter == "–¢–æ–ª—å–∫–æ –æ–¥–µ–∂–¥–∞":
                mask = mask & clothing_mask
            elif clothing_filter == "–ë–µ–∑ –æ–¥–µ–∂–¥—ã":
                mask = mask & ~clothing_mask
    
    # –§–∏–ª—å—Ç—Ä –ø–æ –≤—ã—Ä—É—á–∫–µ —É–¥–∞–ª–µ–Ω
    
    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 5: –¢–æ–≤–∞—Ä—ã - –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–¥–∏–Ω —Ä–∞–∑, —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Å—Ä–∞–∑—É
    if "–¢–æ–≤–∞—Ä—ã" in df.columns:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü, –µ—Å–ª–∏ –æ–Ω —á–∏—Å–ª–æ–≤–æ–π
        if pd.api.types.is_numeric_dtype(df["–¢–æ–≤–∞—Ä—ã"]):
            products_numeric = df["–¢–æ–≤–∞—Ä—ã"]
        else:
            # –ï—Å–ª–∏ —Å—Ç–æ–ª–±–µ—Ü —Å—Ç—Ä–æ–∫–æ–≤—ã–π, –æ—á–∏—â–∞–µ–º –æ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ç—ã—Å—è—á –ø–µ—Ä–µ–¥ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º
            products_series = df["–¢–æ–≤–∞—Ä—ã"].astype(str).str.replace(r'[\s,]', '', regex=True)
            products_numeric = pd.to_numeric(products_series, errors="coerce")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –∑–∞–¥–∞–Ω—ã
        # –£–±–∏—Ä–∞–µ–º NaN –∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–æ–Ω–∏ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä)
        if products_min is not None:
            mask = mask & (products_numeric >= products_min) & products_numeric.notna()
        if products_max is not None:
            mask = mask & (products_numeric <= products_max) & products_numeric.notna()
    
    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 6: –§–∏–ª—å—Ç—Ä –ø–æ —á–∞—Å—Ç–æ—Ç–µ WB
    if "–ß–∞—Å—Ç–æ—Ç–∞ WB" in df.columns:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        frequency_wb_numeric = pd.to_numeric(df["–ß–∞—Å—Ç–æ—Ç–∞ WB"], errors="coerce")
        if frequency_wb_min is not None:
            mask = mask & (frequency_wb_numeric >= frequency_wb_min)
        if frequency_wb_max is not None:
            mask = mask & (frequency_wb_numeric <= frequency_wb_max)
    
    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 7: –§–∏–ª—å—Ç—Ä –ø–æ —á–∞—Å—Ç–æ—Ç–µ Ozon
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã –û–î–ò–ù —Ä–∞–∑ –≤–º–µ—Å—Ç–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–π
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame –∏ –º–∞—Å–∫—É –æ–¥–µ–∂–¥—ã –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    return df[mask].copy(), clothing_mask

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.title("üîç –ü–æ–∏—Å–∫ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
st.sidebar.header("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

# –¢–µ—Å—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ —Å–∞–π—Ç–µ
with st.sidebar.expander("üîê –¢–µ—Å—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏", expanded=False):
    st.info("üí° –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ service-analytic.com")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    try:
        test_username = st.secrets.get("service_analytic_username", "")
        test_password = st.secrets.get("service_analytic_password", "")
    except:
        test_username = ""
        test_password = ""
    
    if not test_username or not test_password:
        test_username = st.text_input("–õ–æ–≥–∏–Ω", value=test_username, key="test_username")
        test_password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password", value=test_password, key="test_password")
    else:
        st.success("‚úÖ –£—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫")
        if st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", key="use_custom_credentials"):
            test_username = st.text_input("–õ–æ–≥–∏–Ω", key="test_username_custom")
            test_password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password", key="test_password_custom")
    
    headless_mode = st.checkbox("–ó–∞–ø—É—Å–∫ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ", value=True, help="–ë—Ä–∞—É–∑–µ—Ä –Ω–µ –±—É–¥–µ—Ç –≤–∏–¥–µ–Ω")
    
    # –ö–Ω–æ–ø–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
    if st.button("üöÄ –¢–µ—Å—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏", use_container_width=True, key="test_auth_button"):
        if test_username and test_password:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if "auth_test_result" not in st.session_state:
                st.session_state["auth_test_result"] = None
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            status_container = st.container()
            progress_container = st.container()
            
            with status_container:
                st.info("üîÑ –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ç–µ—Å—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏...")
            
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ selenium
                try:
                    import selenium
                    selenium_version = selenium.__version__
                    with status_container:
                        st.success(f"‚úÖ Selenium —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–≤–µ—Ä—Å–∏—è {selenium_version})")
                except ImportError:
                    with status_container:
                        st.error("‚ùå Selenium –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ —Ç–µ–∫—É—â–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏ Python!")
                        st.info("üí° Streamlit –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥—Ä—É–≥–æ–π Python, —á–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π")
                        st.info("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Selenium –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–µ Streamlit:")
                        import sys
                        python_version = f"{sys.version_info.major}.{sys.version_info.minor}"
                        st.code(f"python{python_version} -m pip install selenium webdriver-manager --user", language="bash")
                        st.info("üí° –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞")
                        st.stop()
                
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é
                try:
                    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞–ø—Ä—è–º—É—é, –º–∏–Ω—É—è __init__.py
                    import importlib.util
                    auto_download_path = os.path.join(project_root, 'utils', 'auto_download.py')
                    if not os.path.exists(auto_download_path):
                        raise ImportError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {auto_download_path}")
                    
                    spec = importlib.util.spec_from_file_location("auto_download", auto_download_path)
                    auto_download_module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(auto_download_module)
                    test_authorization = auto_download_module.test_authorization
                    
                    with status_container:
                        st.success("‚úÖ –ú–æ–¥—É–ª—å auto_download –∑–∞–≥—Ä—É–∂–µ–Ω")
                except ImportError as e:
                    with status_container:
                        st.error(f"‚ùå –ú–æ–¥—É–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
                        st.info("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª utils/auto_download.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                        st.info(f"üí° –ü—É—Ç—å: {auto_download_path if 'auto_download_path' in locals() else '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω'}")
                        st.stop()
                except Exception as e:
                    with status_container:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥—É–ª—è: {e}")
                        import traceback
                        with st.expander("üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
                            st.code(traceback.format_exc())
                        st.stop()
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
                with progress_container:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    status_text.info("‚è≥ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞...")
                    progress_bar.progress(10)
                    
                    status_text.info("‚è≥ –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è...")
                    progress_bar.progress(30)
                    
                    result = test_authorization(
                        username=test_username,
                        password=test_password,
                        headless=headless_mode
                    )
                    
                    progress_bar.progress(100)
                    status_text.empty()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ session_state
                st.session_state["auth_test_result"] = result
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                with status_container:
                    if result and result.get('success'):
                        st.success(f"‚úÖ {result.get('message', '–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!')}")
                        if result.get('current_url'):
                            st.info(f"üìç –¢–µ–∫—É—â–∏–π URL: {result['current_url']}")
                    else:
                        st.error(f"‚ùå {result.get('message', '–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å') if result else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}")
                        if result and result.get('current_url'):
                            st.info(f"üìç –¢–µ–∫—É—â–∏–π URL: {result['current_url']}")
                        if result and result.get('trace'):
                            with st.expander("üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
                                st.code(result['trace'])
                            
            except Exception as e:
                error_msg = str(e)
                with status_container:
                    st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {error_msg}")
                import traceback
                with status_container:
                    with st.expander("üîç –ü–æ–ª–Ω—ã–π traceback"):
                        st.code(traceback.format_exc())
                st.session_state["auth_test_result"] = {
                    'success': False,
                    'message': f'–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {error_msg}',
                    'current_url': None
                }
        else:
            st.error("‚ùå –í–≤–µ–¥–∏—Ç–µ –ª–æ–≥–∏–Ω –∏ –ø–∞—Ä–æ–ª—å")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å
    if "auth_test_result" in st.session_state and st.session_state["auth_test_result"]:
        result = st.session_state["auth_test_result"]
        if result.get('success'):
            st.success(f"‚úÖ –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result.get('message', '–£—Å–ø–µ—à–Ω–æ')}")
        else:
            st.warning(f"‚ö†Ô∏è –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result.get('message', '–ù–µ —É–¥–∞–ª–æ—Å—å')}")

st.sidebar.markdown("---")

# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏
st.sidebar.subheader("üíæ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏")

# –°–ø–∏—Å–æ–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤
projects_list = list_projects()
if projects_list:
    st.sidebar.caption(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø—Ä–æ–µ–∫—Ç–æ–≤: {len(projects_list)}")
else:
    st.sidebar.caption("–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤")

# –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏
project_tab1, project_tab2 = st.sidebar.tabs(["üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å", "üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç—å"])

with project_tab1:
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
    project_name = st.text_input(
        "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞",
        value="",
        key="project_name_input",
        help="–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞"
    )
    
    if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–µ–∫—Ç", use_container_width=True, key="save_project_button"):
        if not project_name or not project_name.strip():
            st.sidebar.error("‚ùå –í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞")
        elif "df" not in globals() or df is None or df.empty:
            st.sidebar.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥.")
        else:
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            file_key = filename if filename else "default"
            settings = {
                "selected_month": selected_month,
                "selected_year": selected_year,
                "filename": filename,
                "clothing_filter": st.session_state.get("clothing_filter", "–í—Å–µ"),
                "products_min": st.session_state.get(f"products_min_{file_key}", 0),
                "products_max": st.session_state.get(f"products_max_{file_key}", 1000),
                "frequency_wb_min": st.session_state.get(f"frequency_wb_min_{file_key}", 0.0),
                "frequency_wb_max": st.session_state.get(f"frequency_wb_max_{file_key}", 1000000.0),
                "use_brand_filter": st.session_state.get("use_brand_filter", True),
                "use_garbage_filter": st.session_state.get("use_garbage_filter", False),
                "use_english_filter": st.session_state.get("use_english_filter", True),
                "use_automatic_filters": st.session_state.get("use_automatic_filters", False),
                "english_queries_to_keep": st.session_state.get("english_queries_to_keep", [])
            }
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –∏—Å—Ö–æ–¥–Ω—ã–µ
            df_to_save = df
            if 'df_processed' in globals() and df_processed is not None and not df_processed.empty:
                df_to_save = df_processed
            
            success, result = save_project(project_name.strip(), df_to_save, settings)
            if success:
                st.sidebar.success(f"‚úÖ –ü—Ä–æ–µ–∫—Ç '{project_name.strip()}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
                st.rerun()
            else:
                st.sidebar.error(f"‚ùå {result}")

with project_tab2:
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞
    if projects_list:
        project_names = [p["name"] for p in projects_list]
        project_info = {p["name"]: p["created_at"] for p in projects_list}
        
        selected_project = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç",
            options=project_names,
            key="load_project_select",
            format_func=lambda x: f"{x} ({project_info[x]})"
        )
        
        col_load, col_delete = st.columns(2)
        with col_load:
            if st.button("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç—å", use_container_width=True, key="load_project_button"):
                loaded_df, loaded_settings, error = load_project(selected_project)
                if error:
                    st.sidebar.error(f"‚ùå {error}")
                else:
                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    if loaded_df is not None:
                        st.session_state["loaded_project_df"] = loaded_df
                        st.session_state["loaded_project_settings"] = loaded_settings
                        st.session_state["project_loaded"] = True
                        st.sidebar.success(f"‚úÖ –ü—Ä–æ–µ–∫—Ç '{selected_project}' –∑–∞–≥—Ä—É–∂–µ–Ω!")
                        st.rerun()
                    else:
                        st.sidebar.error("‚ùå –î–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        with col_delete:
            if st.button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å", use_container_width=True, key="delete_project_button"):
                success, error = delete_project(selected_project)
                if success:
                    st.sidebar.success(f"‚úÖ –ü—Ä–æ–µ–∫—Ç '{selected_project}' —É–¥–∞–ª–µ–Ω!")
                    st.rerun()
                else:
                    st.sidebar.error(f"‚ùå {error}")
    else:
        st.info("üí° –ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤")

st.sidebar.markdown("---")

# –í—ã–±–æ—Ä –º–µ—Å—è—Ü–∞ –∏ –≥–æ–¥–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
st.sidebar.subheader("üìÖ –í—ã–±–æ—Ä –ø–µ—Ä–∏–æ–¥–∞")

# –°–ø–∏—Å–æ–∫ –º–µ—Å—è—Ü–µ–≤
months = [
    "–Ø–Ω–≤–∞—Ä—å", "–§–µ–≤—Ä–∞–ª—å", "–ú–∞—Ä—Ç", "–ê–ø—Ä–µ–ª—å", "–ú–∞–π", "–ò—é–Ω—å",
    "–ò—é–ª—å", "–ê–≤–≥—É—Å—Ç", "–°–µ–Ω—Ç—è–±—Ä—å", "–û–∫—Ç—è–±—Ä—å", "–ù–æ—è–±—Ä—å", "–î–µ–∫–∞–±—Ä—å"
]

# –í—ã–±–æ—Ä –º–µ—Å—è—Ü–∞
selected_month = st.sidebar.selectbox(
    "–ú–µ—Å—è—Ü",
    options=["–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (new.xlsx)"] + months,
    index=0,
    key="selected_month",
    help="–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Å—è—Ü –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ '—Ä–æ—Å—Ç' –∏ '–ø–∞–¥–µ–Ω–∏–µ'"
)

# –í—ã–±–æ—Ä –≥–æ–¥–∞
selected_year = st.sidebar.number_input(
    "–ì–æ–¥",
    min_value=2020,
    max_value=2030,
    value=2025,
    step=1,
    key="selected_year",
    help="–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤"
)

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
if selected_month == "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (new.xlsx)":
    default_df, default_filename, file_info = load_default_file(month=None)
else:
    default_df, default_filename, file_info = load_default_file(month=selected_month, year=selected_year)

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
if file_info:
    if file_info.get('error'):
        if "–Ω–µ –Ω–∞–π–¥–µ–Ω—ã" in file_info['error']:
            st.sidebar.warning(f"‚ö†Ô∏è {file_info['error']}")
            if selected_month != "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (new.xlsx)":
                st.sidebar.info(f"üí° –ò—â—É—Ç—Å—è —Ñ–∞–π–ª—ã: '{selected_month} —Ä–æ—Å—Ç {selected_year}.xlsx' –∏ '{selected_month} –ø–∞–¥–µ–Ω–∏–µ {selected_year}.xlsx'")
        else:
            st.sidebar.warning(f"‚ö†Ô∏è {file_info['error']}")
    elif default_df is not None:
        if file_info.get('growth_file') and file_info.get('decline_file'):
            st.sidebar.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –æ–±–∞ —Ñ–∞–π–ª–∞: —Ä–æ—Å—Ç –∏ –ø–∞–¥–µ–Ω–∏–µ")
        elif file_info.get('growth_file'):
            st.sidebar.info(f"‚ÑπÔ∏è –ó–∞–≥—Ä—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª —Ä–æ—Å—Ç–∞: {os.path.basename(file_info['growth_file'])}")
        elif file_info.get('decline_file'):
            st.sidebar.info(f"‚ÑπÔ∏è –ó–∞–≥—Ä—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª –ø–∞–¥–µ–Ω–∏—è: {os.path.basename(file_info['decline_file'])}")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
uploaded_file = st.sidebar.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª",
    type=["csv", "xlsx", "xls"],
    help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –∑–∞–ø—Ä–æ—Å–∞—Ö"
)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç
if st.session_state.get("project_loaded", False) and "loaded_project_df" in st.session_state:
    loaded_df = st.session_state["loaded_project_df"]
    loaded_settings = st.session_state.get("loaded_project_settings", {})
    
    if loaded_df is not None and not loaded_df.empty:
        df = loaded_df
        filename = loaded_settings.get("filename", "–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç")
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if "selected_month" in loaded_settings:
            st.session_state["selected_month"] = loaded_settings["selected_month"]
        if "selected_year" in loaded_settings:
            st.session_state["selected_year"] = loaded_settings["selected_year"]
        
        st.sidebar.success(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç: {filename}")
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        st.session_state["project_loaded"] = False
    else:
        st.sidebar.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö")

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–æ–π DataFrame –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith('.csv'):
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            try:
                df = pd.read_csv(uploaded_file, sep=";", encoding="utf-8")
            except:
                try:
                    uploaded_file.seek(0)  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é —Ñ–∞–π–ª–∞
                    df = pd.read_csv(uploaded_file, sep=";", encoding="utf-8-sig")
                except:
                    uploaded_file.seek(0)
                    df = pd.read_csv(uploaded_file, sep=",", encoding="utf-8")
            
            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –æ–¥–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
            if df.shape[1] == 1:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, sep=",", encoding="utf-8")
        else:
            uploaded_file.seek(0)
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å Excel —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å—Ç—Ä–æ–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            try:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                import tempfile
                with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    tmp_path = tmp_file.name
                
                # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
                header_row = find_header_row(tmp_path)
                
                # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —Å –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                uploaded_file.seek(0)
                df = pd.read_excel(uploaded_file, header=header_row)
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                try:
                    os.unlink(tmp_path)
                except:
                    pass
            except Exception as e:
                uploaded_file.seek(0)
                # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —á—Ç–µ–Ω–∏–µ
                try:
                    df = pd.read_excel(uploaded_file, header=0)
                except:
                    uploaded_file.seek(0)
                    df = pd.read_excel(uploaded_file)
        filename = uploaded_file.name
        st.sidebar.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {filename}")
    except Exception as e:
        st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        df = None
        filename = None
elif default_df is not None:
    df = default_df
    filename = default_filename
    st.sidebar.info(f"üìÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {filename}")
else:
    df = None
    filename = None
    if selected_month == "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (new.xlsx)":
        st.sidebar.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ –ø–∞–ø–∫–µ trend –µ—Å—Ç—å —Ñ–∞–π–ª new.xlsx")
    else:
        st.sidebar.warning(f"‚ö†Ô∏è –§–∞–π–ª—ã –¥–ª—è {selected_month} {selected_year} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ '—Ä–æ—Å—Ç' –∏ '–ø–∞–¥–µ–Ω–∏–µ' –≤ –ø–∞–ø–∫–µ trend")

if df is not None and not df.empty:
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df_processed = process_dataframe(df)
    
    if df_processed is not None:
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞, –µ—Å–ª–∏ –µ—Å—Ç—å
        loaded_settings = st.session_state.get("loaded_project_settings", {})
        if loaded_settings and st.session_state.get("project_loaded", False):
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
            file_key = filename if filename else "default"
            if "clothing_filter" in loaded_settings:
                st.session_state["clothing_filter"] = loaded_settings["clothing_filter"]
            if f"products_min_{file_key}" in loaded_settings:
                st.session_state[f"products_min_{file_key}"] = loaded_settings.get("products_min", 0)
            if f"products_max_{file_key}" in loaded_settings:
                st.session_state[f"products_max_{file_key}"] = loaded_settings.get("products_max", 1000)
            if f"frequency_wb_min_{file_key}" in loaded_settings:
                st.session_state[f"frequency_wb_min_{file_key}"] = loaded_settings.get("frequency_wb_min", 0.0)
            if f"frequency_wb_max_{file_key}" in loaded_settings:
                st.session_state[f"frequency_wb_max_{file_key}"] = loaded_settings.get("frequency_wb_max", 1000000.0)
            if "use_brand_filter" in loaded_settings:
                st.session_state["use_brand_filter"] = loaded_settings["use_brand_filter"]
            if "use_garbage_filter" in loaded_settings:
                st.session_state["use_garbage_filter"] = loaded_settings["use_garbage_filter"]
            if "use_english_filter" in loaded_settings:
                st.session_state["use_english_filter"] = loaded_settings["use_english_filter"]
            if "use_automatic_filters" in loaded_settings:
                st.session_state["use_automatic_filters"] = loaded_settings["use_automatic_filters"]
            if "english_queries_to_keep" in loaded_settings:
                st.session_state["english_queries_to_keep"] = loaded_settings["english_queries_to_keep"]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∏–Ω—É—Å —Å–ª–æ–≤–∞
        minus_words = load_minus_words()
        
        # –§–∏–ª—å—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        st.header("üîß –§–∏–ª—å—Ç—Ä—ã")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
        filter_col1, filter_col2 = st.columns(2)
        
        with filter_col1:
            # –§–∏–ª—å—Ç—Ä –ø–æ –æ–¥–µ–∂–¥–µ
            st.subheader("üëî –§–∏–ª—å—Ç—Ä –ø–æ –æ–¥–µ–∂–¥–µ")
            clothing_options = ["–í—Å–µ", "–¢–æ–ª—å–∫–æ –æ–¥–µ–∂–¥–∞", "–ë–µ–∑ –æ–¥–µ–∂–¥—ã"]
            clothing_filter_default = loaded_settings.get("clothing_filter", "–í—Å–µ") if loaded_settings else "–í—Å–µ"
            clothing_filter = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø",
                clothing_options,
                index=clothing_options.index(clothing_filter_default) if clothing_filter_default in clothing_options else 0,
                key="clothing_filter",
                label_visibility="collapsed"
            )
            
            # –§–∏–ª—å—Ç—Ä –ø–æ –≤—ã—Ä—É—á–∫–µ —É–¥–∞–ª–µ–Ω
        
        with filter_col2:
            # –î–∏–∞–ø–∞–∑–æ–Ω –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–≤–∞—Ä–æ–≤
            st.subheader("üì¶ –î–∏–∞–ø–∞–∑–æ–Ω –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–≤–∞—Ä–æ–≤")
            # –í—ã—á–∏—Å–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Ñ–∞–π–ª–∞
            if "–¢–æ–≤–∞—Ä—ã" in df_processed.columns:
                products_series = df_processed["–¢–æ–≤–∞—Ä—ã"].astype(str).str.replace(r'[\s,]', '', regex=True)
                products_numeric = pd.to_numeric(products_series, errors="coerce")
                products_max_default = int(products_numeric.max()) if not products_numeric.isna().all() else 1000
            else:
                products_max_default = 1000
            file_key = filename if filename else "default"
            products_min_default = loaded_settings.get("products_min", 0) if loaded_settings else 0
            products_min = st.number_input(
                "–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ",
                min_value=0,
                value=products_min_default,
                step=100,
                key=f"products_min_{file_key}",
                help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)"
            )
            products_max_default_value = loaded_settings.get("products_max", products_max_default) if loaded_settings else products_max_default
            products_max = st.number_input(
                "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ",
                min_value=0,
                value=products_max_default_value,
                step=100,
                key=f"products_max_{file_key}",
                help=f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: {products_max_default}. –ï—Å–ª–∏ –Ω–µ –º–µ–Ω—è—Ç—å - —Ñ–∏–ª—å—Ç—Ä –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è."
            )
            
            # –§–∏–ª—å—Ç—Ä –ø–æ —á–∞—Å—Ç–æ—Ç–µ WB
            if "–ß–∞—Å—Ç–æ—Ç–∞ WB" in df_processed.columns:
                st.subheader("üìä –î–∏–∞–ø–∞–∑–æ–Ω —á–∞—Å—Ç–æ—Ç—ã WB")
                frequency_wb_max_default = float(df_processed["–ß–∞—Å—Ç–æ—Ç–∞ WB"].max()) if not df_processed["–ß–∞—Å—Ç–æ—Ç–∞ WB"].isna().all() else 1000000.0
                file_key = filename if filename else "default"
                frequency_wb_min_default = loaded_settings.get("frequency_wb_min", 0.0) if loaded_settings else 0.0
                frequency_wb_min = st.number_input(
                    "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ WB",
                    min_value=0.0,
                    value=frequency_wb_min_default,
                    step=100.0,
                    key=f"frequency_wb_min_{file_key}",
                    format="%.0f"
                )
                frequency_wb_max_default_value = loaded_settings.get("frequency_wb_max", frequency_wb_max_default) if loaded_settings else frequency_wb_max_default
                frequency_wb_max = st.number_input(
                    "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ WB",
                    min_value=0.0,
                    value=frequency_wb_max_default_value,
                    step=100.0,
                    key=f"frequency_wb_max_{file_key}",
                    format="%.0f"
                )
            else:
                frequency_wb_min = 0.0
                frequency_wb_max = 1000000.0  # –í–æ–∑–≤—Ä–∞—â–µ–Ω–æ: –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                frequency_wb_max_default = 1000000.0
            
            # –§–∏–ª—å—Ç—Ä –ø–æ —á–∞—Å—Ç–æ—Ç–µ Ozon —É–¥–∞–ª–µ–Ω
        
        # –û—á–∏—Å—Ç–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
        st.subheader("üîç –û—á–∏—Å—Ç–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫")
        use_automatic_filters_default = loaded_settings.get("use_automatic_filters", False) if loaded_settings else False
        use_automatic_filters = st.checkbox(
            "‚úÖ –í–∫–ª—é—á–∏—Ç—å –æ—á–∏—Å—Ç–∫—É –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫",
            value=use_automatic_filters_default,
            help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å—ã —Å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏: –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã (1-3 —Å–∏–º–≤–æ–ª–∞), –ø—Ä–µ–¥–ª–æ–≥–∏/—Å–æ—é–∑—ã, –æ–ø–µ—á–∞—Ç–∫–∏ –∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –º—É—Å–æ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã",
            key="use_automatic_filters"
        )
        
        if use_automatic_filters:
            st.info("‚úÖ **–û—á–∏—Å—Ç–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ –≤–∫–ª—é—á–µ–Ω–∞:**")
            st.markdown("""
            - –§–∏–ª—å—Ç—Ä –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (1-3 —Å–∏–º–≤–æ–ª–∞)
            - –§–∏–ª—å—Ç—Ä –ø—Ä–µ–¥–ª–æ–≥–æ–≤/—Å–æ—é–∑–æ–≤
            - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
            - –§–∏–ª—å—Ç—Ä –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –º—É—Å–æ—Ä–Ω—ã—Ö —Ñ—Ä–∞–∑ (–¥–∂–∏–Ω—Å—Ü, –ø–ª–∞—å–µ, –ø–∞—Ç—å–µ –∏ –¥—Ä.)
            """)
        else:
            st.info("‚ÑπÔ∏è **–û—á–∏—Å—Ç–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ –æ—Ç–∫–ª—é—á–µ–Ω–∞** - –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –±—É–¥—É—Ç –ø–æ–∫–∞–∑–∞–Ω—ã –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫")
        
        # –§–∏–ª—å—Ç—Ä –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        with st.expander("üè∑Ô∏è –§–∏–ª—å—Ç—Ä –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤", expanded=False):
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±—Ä–µ–Ω–¥–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            brand_queries = load_brand_queries()
            
            # –ß–µ–∫–±–æ–∫—Å –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞ (–≤–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            use_brand_filter = st.checkbox(
                "‚úÖ –í–∫–ª—é—á–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤",
                value=True,
                help="–ò—Å–∫–ª—é—á–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –±—Ä–µ–Ω–¥—ã (nike, –Ω–∞–π–∫, adidas, –∞–¥–∏–¥–∞—Å, lime –∏ –¥—Ä.)",
                key="use_brand_filter"
            )
            
            if use_brand_filter:
                st.info(f"‚úÖ **–§–∏–ª—å—Ç—Ä –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤–∫–ª—é—á–µ–Ω** - –±—É–¥–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–æ {len(brand_queries)} –±—Ä–µ–Ω–¥–æ–≤")
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–æ–≤
            if df_processed is not None and not df_processed.empty and "–ó–∞–ø—Ä–æ—Å" in df_processed.columns:
                with st.expander("üîç –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–æ–≤", expanded=False):
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤
                    if "detected_brands" not in st.session_state:
                        st.session_state["detected_brands"] = {}
                    if "potential_brands" not in st.session_state:
                        st.session_state["potential_brands"] = {}
                    if "show_detected_brands" not in st.session_state:
                        st.session_state["show_detected_brands"] = False
                    
                    col_detect1, col_detect2 = st.columns([2, 1])
                    with col_detect1:
                        if st.button("üîç –ù–∞–π—Ç–∏ –±—Ä–µ–Ω–¥—ã –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö", key="detect_brands_button", use_container_width=True):
                            with st.spinner("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –±—Ä–µ–Ω–¥–æ–≤..."):
                                # –ò—â–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã
                                detected = detect_brands_in_queries(df_processed)
                                # –ò—â–µ–º –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–µ –±—Ä–µ–Ω–¥—ã (–∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∏ –¥—Ä.)
                                potential = detect_potential_brands(df_processed)
                                
                                st.session_state["detected_brands"] = detected
                                st.session_state["potential_brands"] = potential
                                st.session_state["show_detected_brands"] = True
                                
                                total_found = len(detected) + len(potential)
                                if total_found > 0:
                                    st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(detected)} –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏ {len(potential)} –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã—Ö –±—Ä–µ–Ω–¥–æ–≤!")
                                else:
                                    st.info("‚ÑπÔ∏è –ë—Ä–µ–Ω–¥—ã –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
                    
                    with col_detect2:
                        if st.session_state["detected_brands"] or st.session_state["potential_brands"]:
                            total_mentions = sum(st.session_state["detected_brands"].values()) + sum(st.session_state["potential_brands"].values())
                            st.metric("–£–ø–æ–º–∏–Ω–∞–Ω–∏–π", total_mentions)
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –±—Ä–µ–Ω–¥—ã
                    if st.session_state["show_detected_brands"]:
                        detected_brands = st.session_state["detected_brands"]
                        potential_brands = st.session_state["potential_brands"]
                        existing_brands_list = [b.lower() for b in brand_queries]
                        
                        # === –ò–ó–í–ï–°–¢–ù–´–ï –ë–†–ï–ù–î–´ ===
                        if detected_brands:
                            st.markdown("---")
                            st.markdown("#### ‚úÖ –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã")
                            
                            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –∏ –Ω–æ–≤—ã–µ
                            new_known_brands = {k: v for k, v in detected_brands.items() if k not in existing_brands_list}
                            already_added_known = {k: v for k, v in detected_brands.items() if k in existing_brands_list}
                            
                            if new_known_brands:
                                st.markdown(f"**üìã –ù–∞–π–¥–µ–Ω–æ {len(new_known_brands)} –Ω–æ–≤—ã—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤:**")
                                
                                # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                num_cols_display = 3
                                for i in range(0, len(new_known_brands), num_cols_display):
                                    cols = st.columns(num_cols_display)
                                    brands_list = list(new_known_brands.items())[i:i+num_cols_display]
                                    for j, (brand, count) in enumerate(brands_list):
                                        with cols[j]:
                                            st.markdown(f"**{brand}** ({count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)")
                                
                                # –ö–Ω–æ–ø–∫–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
                                col_add_all_known, col_add_selected_known = st.columns(2)
                                with col_add_all_known:
                                    if st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤—Å–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã", key="add_all_known_brands", use_container_width=True):
                                        added_count = 0
                                        for brand in new_known_brands.keys():
                                            if brand not in brand_queries:
                                                brand_queries.append(brand)
                                                added_count += 1
                                        
                                        if added_count > 0:
                                            brand_queries = sorted(list(set(brand_queries)))
                                            if save_brand_queries(brand_queries):
                                                st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –±—Ä–µ–Ω–¥–æ–≤!")
                                                st.session_state["detected_brands"] = {}
                                                if not st.session_state["potential_brands"]:
                                                    st.session_state["show_detected_brands"] = False
                                                st.rerun()
                                
                                with col_add_selected_known:
                                    # –ú—É–ª—å—Ç–∏—Å–µ–ª–µ–∫—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –±—Ä–µ–Ω–¥–æ–≤
                                    selected_known_brands = st.multiselect(
                                        "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è:",
                                        options=list(new_known_brands.keys()),
                                        default=[],
                                        key="select_known_brands_to_add",
                                        format_func=lambda x: f"{x} ({new_known_brands[x]} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)"
                                    )
                                    
                                    if selected_known_brands and st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ", key="add_selected_known_brands", use_container_width=True):
                                        added_count = 0
                                        for brand in selected_known_brands:
                                            if brand not in brand_queries:
                                                brand_queries.append(brand)
                                                added_count += 1
                                        
                                        if added_count > 0:
                                            brand_queries = sorted(list(set(brand_queries)))
                                            if save_brand_queries(brand_queries):
                                                st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –±—Ä–µ–Ω–¥–æ–≤!")
                                                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                                                for brand in selected_known_brands:
                                                    if brand in st.session_state["detected_brands"]:
                                                        del st.session_state["detected_brands"][brand]
                                                if not st.session_state["detected_brands"] and not st.session_state["potential_brands"]:
                                                    st.session_state["show_detected_brands"] = False
                                                st.rerun()
                            
                            if already_added_known:
                                st.markdown(f"**‚úÖ –£–∂–µ –≤ —Å–ø–∏—Å–∫–µ ({len(already_added_known)} –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤):**")
                                already_text = ", ".join([f"{k} ({v})" for k, v in list(already_added_known.items())[:10]])
                                if len(already_added_known) > 10:
                                    already_text += f" –∏ –µ—â–µ {len(already_added_known) - 10}..."
                                st.caption(already_text)
                        
                        # === –ü–†–ï–î–ü–û–õ–ê–ì–ê–ï–ú–´–ï –ë–†–ï–ù–î–´ (–∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∏ –¥—Ä.) ===
                        if potential_brands:
                            st.markdown("---")
                            st.markdown("#### üîç –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–µ –±—Ä–µ–Ω–¥—ã (–∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã)")
                            st.caption("üí° –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –±—Ä–µ–Ω–¥–∞–º–∏ (–∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ —Å–ª–æ–≤–∞, –Ω–µ —è–≤–ª—è—é—â–∏–µ—Å—è –æ–±—ã—á–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏)")
                            
                            # –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ
                            new_potential_brands = {k: v for k, v in potential_brands.items() if k not in existing_brands_list}
                            already_added_potential = {k: v for k, v in potential_brands.items() if k in existing_brands_list}
                            
                            if new_potential_brands:
                                st.markdown(f"**üìã –ù–∞–π–¥–µ–Ω–æ {len(new_potential_brands)} –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã—Ö –±—Ä–µ–Ω–¥–æ–≤:**")
                                
                                # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                num_cols_display = 3
                                for i in range(0, len(new_potential_brands), num_cols_display):
                                    cols = st.columns(num_cols_display)
                                    brands_list = list(new_potential_brands.items())[i:i+num_cols_display]
                                    for j, (brand, count) in enumerate(brands_list):
                                        with cols[j]:
                                            st.markdown(f"**{brand}** ({count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)")
                                
                                # –ö–Ω–æ–ø–∫–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
                                col_add_all_potential, col_add_selected_potential = st.columns(2)
                                with col_add_all_potential:
                                    if st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤—Å–µ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–µ –±—Ä–µ–Ω–¥—ã", key="add_all_potential_brands", use_container_width=True):
                                        added_count = 0
                                        for brand in new_potential_brands.keys():
                                            if brand not in brand_queries:
                                                brand_queries.append(brand)
                                                added_count += 1
                                        
                                        if added_count > 0:
                                            brand_queries = sorted(list(set(brand_queries)))
                                            if save_brand_queries(brand_queries):
                                                st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã—Ö –±—Ä–µ–Ω–¥–æ–≤!")
                                                st.session_state["potential_brands"] = {}
                                                if not st.session_state["detected_brands"]:
                                                    st.session_state["show_detected_brands"] = False
                                                st.rerun()
                                
                                with col_add_selected_potential:
                                    # –ú—É–ª—å—Ç–∏—Å–µ–ª–µ–∫—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –±—Ä–µ–Ω–¥–æ–≤
                                    selected_potential_brands = st.multiselect(
                                        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–µ –±—Ä–µ–Ω–¥—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è:",
                                        options=list(new_potential_brands.keys()),
                                        default=[],
                                        key="select_potential_brands_to_add",
                                        format_func=lambda x: f"{x} ({new_potential_brands[x]} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)"
                                    )
                                    
                                    if selected_potential_brands and st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–µ", key="add_selected_potential_brands", use_container_width=True):
                                        added_count = 0
                                        for brand in selected_potential_brands:
                                            if brand not in brand_queries:
                                                brand_queries.append(brand)
                                                added_count += 1
                                        
                                        if added_count > 0:
                                            brand_queries = sorted(list(set(brand_queries)))
                                            if save_brand_queries(brand_queries):
                                                st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã—Ö –±—Ä–µ–Ω–¥–æ–≤!")
                                                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                                                for brand in selected_potential_brands:
                                                    if brand in st.session_state["potential_brands"]:
                                                        del st.session_state["potential_brands"][brand]
                                                if not st.session_state["detected_brands"] and not st.session_state["potential_brands"]:
                                                    st.session_state["show_detected_brands"] = False
                                                st.rerun()
                            
                            if already_added_potential:
                                st.markdown(f"**‚úÖ –£–∂–µ –≤ —Å–ø–∏—Å–∫–µ ({len(already_added_potential)} –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã—Ö –±—Ä–µ–Ω–¥–æ–≤):**")
                                already_text = ", ".join([f"{k} ({v})" for k, v in list(already_added_potential.items())[:10]])
                                if len(already_added_potential) > 10:
                                    already_text += f" –∏ –µ—â–µ {len(already_added_potential) - 10}..."
                                st.caption(already_text)
        
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–æ–≤—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
        brand_query_col1, brand_query_col2 = st.columns([3, 1])
        with brand_query_col1:
            new_brand_query = st.text_input(
                "–î–æ–±–∞–≤–∏—Ç—å –±—Ä–µ–Ω–¥",
                    placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: nike/–Ω–∞–π–∫/adidas/–∞–¥–∏–¥–∞—Å/lime (–Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ /)",
                key="new_brand_query",
                    label_visibility="collapsed",
                    help="–ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –±—Ä–µ–Ω–¥–æ–≤ —Å—Ä–∞–∑—É, —Ä–∞–∑–¥–µ–ª–∏–≤ –∏—Ö —Å–∏–º–≤–æ–ª–æ–º /"
            )
        with brand_query_col2:
            st.write("")
            st.write("")
            col_add_brand_query, col_clear_brand_query = st.columns(2)
            if col_add_brand_query.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å", key="add_brand_query", use_container_width=True):
                if new_brand_query and new_brand_query.strip():
                    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ "/" –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –±—Ä–µ–Ω–¥
                    brands_to_add = [b.strip().lower() for b in new_brand_query.split("/") if b.strip()]
                    added_brands = []
                    skipped_brands = []
                    
                    for brand in brands_to_add:
                        if brand not in brand_queries:
                            brand_queries.append(brand)
                            added_brands.append(brand)
                        else:
                            skipped_brands.append(brand)
                    
                    if added_brands:
                        brand_queries = sorted(list(set(brand_queries)))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
                        if save_brand_queries(brand_queries):
                            if len(added_brands) == 1:
                                st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {added_brands[0]}")
                            else:
                                st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(added_brands)} –±—Ä–µ–Ω–¥–æ–≤: {', '.join(added_brands)}")
                            if skipped_brands:
                                st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –≤ —Å–ø–∏—Å–∫–µ): {', '.join(skipped_brands)}")
                            st.rerun()
                    else:
                        if skipped_brands:
                            if len(skipped_brands) == 1:
                                st.warning(f"‚ö†Ô∏è –ë—Ä–µ–Ω–¥ —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ: {skipped_brands[0]}")
                            else:
                                st.warning(f"‚ö†Ô∏è –í—Å–µ –±—Ä–µ–Ω–¥—ã —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ: {', '.join(skipped_brands)}")
            if col_clear_brand_query.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", key="clear_brand_queries", use_container_width=True):
                brand_queries = []
                if save_brand_queries(brand_queries):
                    st.success("‚úÖ –°–ø–∏—Å–æ–∫ –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –æ—á–∏—â–µ–Ω")
                    st.rerun()
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –±—Ä–µ–Ω–¥–æ–≤
        if brand_queries:
            st.caption(f"–í—Å–µ–≥–æ –±—Ä–µ–Ω–¥–æ–≤: {len(brand_queries)}")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤
            if "selected_brand_queries" not in st.session_state:
                st.session_state["selected_brand_queries"] = []
            
            # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            col_select_all, col_deselect_all, col_delete, col_download_json, col_download_csv = st.columns(5)
            with col_select_all:
                if st.button("‚úÖ –í—ã–±—Ä–∞—Ç—å –≤—Å–µ", key="select_all_brand_queries", use_container_width=True):
                    st.session_state["selected_brand_queries"] = brand_queries.copy()
                    st.rerun()
            with col_deselect_all:
                if st.button("‚ùå –°–Ω—è—Ç—å –≤—ã–±–æ—Ä", key="deselect_all_brand_queries", use_container_width=True):
                    st.session_state["selected_brand_queries"] = []
                    st.rerun()
            with col_delete:
                if st.button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ", key="delete_selected_brand_queries", use_container_width=True, disabled=len(st.session_state["selected_brand_queries"]) == 0):
                    if st.session_state["selected_brand_queries"]:
                        for brand in st.session_state["selected_brand_queries"]:
                            if brand in brand_queries:
                                brand_queries.remove(brand)
                        brand_queries = sorted(list(set(brand_queries)))
                        if save_brand_queries(brand_queries):
                            st.session_state["selected_brand_queries"] = []
                            st.rerun()
            with col_download_json:
                # JSON —ç–∫—Å–ø–æ—Ä—Ç
                brand_queries_json = json.dumps(brand_queries, ensure_ascii=False, indent=2)
                st.download_button(
                    "üì• JSON",
                    data=brand_queries_json,
                    file_name="brand_queries.json",
                    mime="application/json",
                    use_container_width=True,
                    key="download_brand_queries_json"
                )
            with col_download_csv:
                # CSV —ç–∫—Å–ø–æ—Ä—Ç
                if brand_queries:
                    brand_queries_df = pd.DataFrame({"–ë—Ä–µ–Ω–¥": brand_queries})
                    brand_queries_csv = brand_queries_df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        "üìä CSV",
                        data=brand_queries_csv,
                        file_name="brand_queries.csv",
                        mime="text/csv",
                        use_container_width=True,
                        key="download_brand_queries_csv"
                    )
            
            st.caption(f"–í—ã–±—Ä–∞–Ω–æ: {len(st.session_state['selected_brand_queries'])}")
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –±—Ä–µ–Ω–¥—ã —Å —á–µ–∫–±–æ–∫—Å–∞–º–∏
            num_cols = 4
            selected_brands_from_checkboxes = []
            for i in range(0, len(brand_queries), num_cols):
                cols = st.columns(num_cols)
                for j, col in enumerate(cols):
                    if i + j < len(brand_queries):
                        brand = brand_queries[i + j]
                        with col:
                            is_selected = brand in st.session_state["selected_brand_queries"]
                            checkbox_value = st.checkbox(brand, key=f"cb_brand_query_{i+j}_{brand}", value=is_selected)
                            if checkbox_value:
                                selected_brands_from_checkboxes.append(brand)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º session_state –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π —á–µ–∫–±–æ–∫—Å–æ–≤
            st.session_state["selected_brand_queries"] = selected_brands_from_checkboxes
        else:
            st.info("üí° –î–æ–±–∞–≤—å—Ç–µ –±—Ä–µ–Ω–¥—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (nike, –Ω–∞–π–∫, adidas, –∞–¥–∏–¥–∞—Å, lime –∏ –¥—Ä.)")
        
        # –§–∏–ª—å—Ç—Ä –ø–æ –º–∏–Ω—É—Å —Å–ª–æ–≤–∞–º
        with st.expander("üö´ –ú–∏–Ω—É—Å —Å–ª–æ–≤–∞", expanded=False):
            # –ß–µ–∫–±–æ–∫—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ –º—É—Å–æ—Ä–Ω—ã—Ö —Å–ª–æ–≤ (–æ—Ç–∫–ª—é—á–µ–Ω, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ –Ω–µ—Ç)
            garbage_words_count = len(get_default_garbage_words())
            use_garbage_filter = st.checkbox(
                "üóëÔ∏è –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞",
                value=False,
                help="–ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ –æ—Ç–∫–ª—é—á–µ–Ω—ã. –î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–∏ —Å–ª–æ–≤–∞ –≤—Ä—É—á–Ω—É—é.",
                key="use_garbage_filter",
                disabled=True  # –û—Ç–∫–ª—é—á–∞–µ–º, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ –Ω–µ—Ç
            )
            
            if use_garbage_filter:
                st.info(f"‚ÑπÔ∏è –ê–∫—Ç–∏–≤–µ–Ω —Ñ–∏–ª—å—Ç—Ä –º—É—Å–æ—Ä–Ω—ã—Ö —Å–ª–æ–≤: –±—É–¥–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–æ {garbage_words_count} –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤")
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –±—Ä–µ–Ω–¥–æ–≤—ã–µ –∏ –æ—Å—Ç–∞–ª—å–Ω—ã–µ
            brand_words = minus_words.get("brand_words", [])
            other_words = minus_words.get("other_words", [])
            total_words = len(brand_words) + len(other_words)
            
            # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∏ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
            tab1, tab2 = st.tabs([f"üè∑Ô∏è –ë—Ä–µ–Ω–¥–æ–≤—ã–µ ({len(brand_words)})", f"üìù –û—Å—Ç–∞–ª—å–Ω—ã–µ ({len(other_words)})"])
            
            # –í–∫–ª–∞–¥–∫–∞ –±—Ä–µ–Ω–¥–æ–≤—ã—Ö —Å–ª–æ–≤
            with tab1:
                brand_col1, brand_col2 = st.columns([3, 1])
                with brand_col1:
                    new_brand_word = st.text_input(
                        "–î–æ–±–∞–≤–∏—Ç—å –±—Ä–µ–Ω–¥–æ–≤–æ–µ —Å–ª–æ–≤–æ",
                        placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: adidas/zarina/nike (–Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ /)",
                        key="new_brand_word",
                        label_visibility="collapsed",
                        help="–ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ —Å—Ä–∞–∑—É, —Ä–∞–∑–¥–µ–ª–∏–≤ –∏—Ö —Å–∏–º–≤–æ–ª–æ–º /"
                    )
                with brand_col2:
                    st.write("")
                    st.write("")
                    col_add_brand, col_clear_brand = st.columns(2)
                    if col_add_brand.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å", key="add_brand_word", use_container_width=True):
                        if new_brand_word and new_brand_word.strip():
                            # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ "/" –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ
                            words_to_add = [w.strip().lower() for w in new_brand_word.split("/") if w.strip()]
                            added_words = []
                            skipped_words = []
                            
                            for word in words_to_add:
                                if word not in brand_words and word not in other_words:
                                    brand_words.append(word)
                                    added_words.append(word)
                                else:
                                    skipped_words.append(word)
                            
                            if added_words:
                                minus_words["brand_words"] = brand_words
                                if save_minus_words(minus_words):
                                    if len(added_words) == 1:
                                        st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {added_words[0]}")
                                    else:
                                        st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(added_words)} —Å–ª–æ–≤: {', '.join(added_words)}")
                                    if skipped_words:
                                        st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –≤ —Å–ø–∏—Å–∫–µ): {', '.join(skipped_words)}")
                                    st.rerun()
                            else:
                                if skipped_words:
                                    if len(skipped_words) == 1:
                                        st.warning(f"‚ö†Ô∏è –°–ª–æ–≤–æ —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ: {skipped_words[0]}")
                                    else:
                                        st.warning(f"‚ö†Ô∏è –í—Å–µ —Å–ª–æ–≤–∞ —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ: {', '.join(skipped_words)}")
                    if col_clear_brand.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", key="clear_brand_words", use_container_width=True):
                        minus_words["brand_words"] = []
                        if save_minus_words(minus_words):
                            st.success("‚úÖ –°–ø–∏—Å–æ–∫ –±—Ä–µ–Ω–¥–æ–≤—ã—Ö —Å–ª–æ–≤ –æ—á–∏—â–µ–Ω")
                            st.rerun()
            
            if brand_words:
                st.caption(f"–í—Å–µ–≥–æ –±—Ä–µ–Ω–¥–æ–≤—ã—Ö —Å–ª–æ–≤: {len(brand_words)}")
                
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
                if "selected_brand_words" not in st.session_state:
                    st.session_state["selected_brand_words"] = []
                
                # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                col_select_all, col_deselect_all, col_delete, col_move, col_download_json, col_download_csv = st.columns(6)
                with col_select_all:
                    if st.button("‚úÖ –í—ã–±—Ä–∞—Ç—å –≤—Å–µ", key="select_all_brand", use_container_width=True):
                        st.session_state["selected_brand_words"] = brand_words.copy()
                        st.rerun()
                with col_deselect_all:
                    if st.button("‚ùå –°–Ω—è—Ç—å –≤—ã–±–æ—Ä", key="deselect_all_brand", use_container_width=True):
                        st.session_state["selected_brand_words"] = []
                        st.rerun()
                with col_delete:
                    if st.button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ", key="delete_selected_brand", use_container_width=True, disabled=len(st.session_state["selected_brand_words"]) == 0):
                        if st.session_state["selected_brand_words"]:
                            for word in st.session_state["selected_brand_words"]:
                                if word in brand_words:
                                    brand_words.remove(word)
                            minus_words["brand_words"] = brand_words
                            save_minus_words(minus_words)
                            st.session_state["selected_brand_words"] = []
                            st.rerun()
                with col_move:
                    if st.button("‚û°Ô∏è –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤ –æ—Å—Ç–∞–ª—å–Ω—ã–µ", key="move_selected_brand", use_container_width=True, disabled=len(st.session_state["selected_brand_words"]) == 0):
                        if st.session_state["selected_brand_words"]:
                            for word in st.session_state["selected_brand_words"]:
                                if word in brand_words:
                                    brand_words.remove(word)
                                if word not in other_words:
                                    other_words.append(word)
                            minus_words["brand_words"] = brand_words
                            minus_words["other_words"] = other_words
                            save_minus_words(minus_words)
                            st.session_state["selected_brand_words"] = []
                            st.rerun()
                with col_download_json:
                    # JSON —ç–∫—Å–ø–æ—Ä—Ç
                    brand_json = json.dumps(brand_words, ensure_ascii=False, indent=2)
                    st.download_button(
                        "üì• JSON",
                        data=brand_json,
                        file_name="brand_words.json",
                        mime="application/json",
                        use_container_width=True,
                        key="download_brand_json"
                    )
                with col_download_csv:
                    # CSV —ç–∫—Å–ø–æ—Ä—Ç
                    if brand_words:
                        brand_df = pd.DataFrame({"–°–ª–æ–≤–æ": brand_words})
                        brand_csv = brand_df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            "üìä CSV",
                            data=brand_csv,
                            file_name="brand_words.csv",
                            mime="text/csv",
                            use_container_width=True,
                            key="download_brand_csv"
                        )
                
                st.caption(f"–í—ã–±—Ä–∞–Ω–æ: {len(st.session_state['selected_brand_words'])}")
                
                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–ª–æ–≤–∞ —Å —á–µ–∫–±–æ–∫—Å–∞–º–∏
                num_cols = 4
                selected_brand_words_from_checkboxes = []
                for i in range(0, len(brand_words), num_cols):
                    cols = st.columns(num_cols)
                    for j, col in enumerate(cols):
                        if i + j < len(brand_words):
                            word = brand_words[i + j]
                            with col:
                                is_selected = word in st.session_state["selected_brand_words"]
                                checkbox_value = st.checkbox(word, key=f"cb_brand_{i+j}_{word}", value=is_selected)
                                if checkbox_value:
                                    selected_brand_words_from_checkboxes.append(word)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º session_state –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π —á–µ–∫–±–æ–∫—Å–æ–≤
                st.session_state["selected_brand_words"] = selected_brand_words_from_checkboxes
            else:
                st.info("üí° –î–æ–±–∞–≤—å—Ç–µ –±—Ä–µ–Ω–¥–æ–≤—ã–µ —Å–ª–æ–≤–∞ (adidas, zarina –∏ —Ç.–¥.)")
        
        # –í–∫–ª–∞–¥–∫–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
        with tab2:
            other_col1, other_col2 = st.columns([3, 1])
            with other_col1:
                new_other_word = st.text_input(
                    "–î–æ–±–∞–≤–∏—Ç—å —Å–ª–æ–≤–æ",
                    placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –æ–±—É–≤—å/–∞–∫—Å–µ—Å—Å—É–∞—Ä—ã/—Å—É–º–∫–∞ (–Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ /)",
                    key="new_other_word",
                    label_visibility="collapsed",
                    help="–ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ —Å—Ä–∞–∑—É, —Ä–∞–∑–¥–µ–ª–∏–≤ –∏—Ö —Å–∏–º–≤–æ–ª–æ–º /"
                )
            with other_col2:
                st.write("")
                st.write("")
                col_add_other, col_clear_other = st.columns(2)
                if col_add_other.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å", key="add_other_word", use_container_width=True):
                    if new_other_word and new_other_word.strip():
                        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ "/" –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ
                        words_to_add = [w.strip().lower() for w in new_other_word.split("/") if w.strip()]
                        added_words = []
                        skipped_words = []
                        
                        for word in words_to_add:
                            if word not in other_words and word not in brand_words:
                                other_words.append(word)
                                added_words.append(word)
                            else:
                                skipped_words.append(word)
                        
                        if added_words:
                            minus_words["other_words"] = other_words
                            if save_minus_words(minus_words):
                                if len(added_words) == 1:
                                    st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {added_words[0]}")
                                else:
                                    st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(added_words)} —Å–ª–æ–≤: {', '.join(added_words)}")
                                if skipped_words:
                                    st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –≤ —Å–ø–∏—Å–∫–µ): {', '.join(skipped_words)}")
                                st.rerun()
                        else:
                            if skipped_words:
                                if len(skipped_words) == 1:
                                    st.warning(f"‚ö†Ô∏è –°–ª–æ–≤–æ —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ: {skipped_words[0]}")
                                else:
                                    st.warning(f"‚ö†Ô∏è –í—Å–µ —Å–ª–æ–≤–∞ —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ: {', '.join(skipped_words)}")
                if col_clear_other.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", key="clear_other_words", use_container_width=True):
                    minus_words["other_words"] = []
                    if save_minus_words(minus_words):
                        st.success("‚úÖ –°–ø–∏—Å–æ–∫ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –æ—á–∏—â–µ–Ω")
                        st.rerun()
            
            if other_words:
                st.caption(f"–í—Å–µ–≥–æ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(other_words)}")
                
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
                if "selected_other_words" not in st.session_state:
                    st.session_state["selected_other_words"] = []
                
                # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                col_select_all, col_deselect_all, col_delete, col_move, col_download_json, col_download_csv = st.columns(6)
                with col_select_all:
                    if st.button("‚úÖ –í—ã–±—Ä–∞—Ç—å –≤—Å–µ", key="select_all_other", use_container_width=True):
                        st.session_state["selected_other_words"] = other_words.copy()
                        st.rerun()
                with col_deselect_all:
                    if st.button("‚ùå –°–Ω—è—Ç—å –≤—ã–±–æ—Ä", key="deselect_all_other", use_container_width=True):
                        st.session_state["selected_other_words"] = []
                        st.rerun()
                with col_delete:
                    if st.button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ", key="delete_selected_other", use_container_width=True, disabled=len(st.session_state["selected_other_words"]) == 0):
                        if st.session_state["selected_other_words"]:
                            for word in st.session_state["selected_other_words"]:
                                if word in other_words:
                                    other_words.remove(word)
                            minus_words["other_words"] = other_words
                            save_minus_words(minus_words)
                            st.session_state["selected_other_words"] = []
                            st.rerun()
                with col_move:
                    if st.button("‚û°Ô∏è –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤ –±—Ä–µ–Ω–¥–æ–≤—ã–µ", key="move_selected_other", use_container_width=True, disabled=len(st.session_state["selected_other_words"]) == 0):
                        if st.session_state["selected_other_words"]:
                            for word in st.session_state["selected_other_words"]:
                                if word in other_words:
                                    other_words.remove(word)
                                if word not in brand_words:
                                    brand_words.append(word)
                            minus_words["other_words"] = other_words
                            minus_words["brand_words"] = brand_words
                            save_minus_words(minus_words)
                            st.session_state["selected_other_words"] = []
                            st.rerun()
                with col_download_json:
                    # JSON —ç–∫—Å–ø–æ—Ä—Ç
                    other_json = json.dumps(other_words, ensure_ascii=False, indent=2)
                    st.download_button(
                        "üì• JSON",
                        data=other_json,
                        file_name="other_words.json",
                        mime="application/json",
                        use_container_width=True,
                        key="download_other_json"
                    )
                with col_download_csv:
                    # CSV —ç–∫—Å–ø–æ—Ä—Ç
                    if other_words:
                        other_df = pd.DataFrame({"–°–ª–æ–≤–æ": other_words})
                        other_csv = other_df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            "üìä CSV",
                            data=other_csv,
                            file_name="other_words.csv",
                            mime="text/csv",
                            use_container_width=True,
                            key="download_other_csv"
                        )
                
                st.caption(f"–í—ã–±—Ä–∞–Ω–æ: {len(st.session_state['selected_other_words'])}")
                
                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–ª–æ–≤–∞ —Å —á–µ–∫–±–æ–∫—Å–∞–º–∏
                num_cols = 4
                selected_other_words_from_checkboxes = []
                for i in range(0, len(other_words), num_cols):
                    cols = st.columns(num_cols)
                    for j, col in enumerate(cols):
                        if i + j < len(other_words):
                            word = other_words[i + j]
                            with col:
                                is_selected = word in st.session_state["selected_other_words"]
                                checkbox_value = st.checkbox(word, key=f"cb_other_{i+j}_{word}", value=is_selected)
                                if checkbox_value:
                                    selected_other_words_from_checkboxes.append(word)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º session_state –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π —á–µ–∫–±–æ–∫—Å–æ–≤
                st.session_state["selected_other_words"] = selected_other_words_from_checkboxes
            else:
                st.info("üí° –î–æ–±–∞–≤—å—Ç–µ –º–∏–Ω—É—Å —Å–ª–æ–≤–∞ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –∏–∑ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ OpenAI (—Å–≤–µ—Ä–Ω—É—Ç–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        openai_typos = load_openai_typos()
        
        # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–æ–º –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        with st.expander("üîç –í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞", expanded=False):
            openai_col1, openai_col2 = st.columns([3, 1])
            
            with openai_col1:
                new_openai_word = st.text_input(
                    "–î–æ–±–∞–≤–∏—Ç—å —Å–ª–æ–≤–æ –≤ —Å–ø–∏—Å–æ–∫ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏",
                    placeholder="–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è",
                    key="new_openai_word",
                    label_visibility="collapsed"
                )
            
            with openai_col2:
                st.write("")  # –û—Ç—Å—Ç—É–ø
                st.write("")  # –û—Ç—Å—Ç—É–ø
                col_add_openai, col_clear_openai = st.columns(2)
                if col_add_openai.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å", key="add_openai_word", use_container_width=True):
                    if new_openai_word and new_openai_word.strip():
                        if new_openai_word.strip() not in openai_typos:
                            openai_typos.append(new_openai_word.strip())
                            openai_typos = sorted(list(set(openai_typos)))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
                            if save_openai_typos(openai_typos):
                                st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {new_openai_word.strip()}")
                                st.rerun()
                            else:
                                st.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                        else:
                            st.warning("‚ö†Ô∏è –°–ª–æ–≤–æ —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ")
                
                if col_clear_openai.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", key="clear_openai_typos", use_container_width=True):
                    openai_typos = []
                    if save_openai_typos(openai_typos):
                        st.success("‚úÖ –°–ø–∏—Å–æ–∫ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—á–∏—â–µ–Ω")
                        st.rerun()
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ —Å–ª–æ–≤–∞ –∏–∑ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (—Å–≤–µ—Ä–Ω—É—Ç–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        if openai_typos:
            with st.expander(f"üìã –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤ ({len(openai_typos)})", expanded=False):
                st.caption("üí° –°–ª–æ–≤–∞, –Ω–∞–π–¥–µ–Ω–Ω—ã–µ OpenAI –ø—Ä–∏ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
                # –°–æ–∑–¥–∞–µ–º —Å–µ—Ç–∫—É –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–ª–æ–≤ —Å –∫–Ω–æ–ø–∫–∞–º–∏ —É–¥–∞–ª–µ–Ω–∏—è
                num_cols = 4
                for i in range(0, len(openai_typos), num_cols):
                    cols = st.columns(num_cols)
                    for j, col in enumerate(cols):
                        if i + j < len(openai_typos):
                            word = openai_typos[i + j]
                            with col:
                                col_word, col_del = st.columns([4, 1])
                                col_word.write(f"‚Ä¢ {word}")
                                if col_del.button("‚ùå", key=f"del_openai_{i+j}_{word}", use_container_width=True):
                                    # –£–¥–∞–ª—è–µ–º —Å–ª–æ–≤–æ –∏–∑ —Å–ø–∏—Å–∫–∞
                                    openai_typos.remove(word)
                                    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
                                    openai_typos = sorted(list(set(openai_typos)))
                                    if save_openai_typos(openai_typos):
                                        st.rerun()
        else:
            st.info("üí° –°–ø–∏—Å–æ–∫ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—É—Å—Ç. –°–ª–æ–≤–∞ –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —á–µ—Ä–µ–∑ OpenAI.")
        
        # –ö–Ω–æ–ø–∫–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –º—É—Å–æ—Ä–Ω—ã—Ö —Å–ª–æ–≤
        st.write("")
        garbage_col1, garbage_col2, garbage_col3 = st.columns([2, 1, 1])
        with garbage_col1:
            st.caption("üí° –î–æ–±–∞–≤–∏—Ç—å –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞")
            # –ö–Ω–æ–ø–∫–∞ "–ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ" —É–±—Ä–∞–Ω–∞, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –æ—Ç–∫–ª—é—á–µ–Ω—ã
        with garbage_col2:
            if st.button("üîç –ù–∞–π—Ç–∏ –≤ –¥–∞–Ω–Ω—ã—Ö", key="find_typos_in_data", use_container_width=True):
                with st.spinner("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—à–∏–±–æ–∫..."):
                    typos = find_typos_in_data(df_processed)
                    if typos:
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–ª–æ–≤–∞
                        all_words = get_all_minus_words(minus_words)
                        new_typos = [w for w in typos if w not in all_words]
                        if new_typos:
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
                            for word in new_typos:
                                if word not in other_words and word not in brand_words:
                                    other_words.append(word)
                            minus_words["other_words"] = other_words
                            if save_minus_words(minus_words):
                                st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(new_typos)} —Å–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏")
                                st.rerun()
                            else:
                                st.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                        else:
                            st.info("‚ÑπÔ∏è –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ")
                    else:
                        st.warning("‚ö†Ô∏è –°–ª–æ–≤–∞ —Å –æ—à–∏–±–∫–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        with garbage_col3:
            # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á OpenAI
            api_key = st.session_state.get('openai_api_key', '')
            if not api_key:
                try:
                    api_key = st.secrets.get('openai_api_key', '')
                except:
                    pass
            
            if api_key and OPENAI_AVAILABLE:
                # –ö–Ω–æ–ø–∫–∞ –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
                if st.button("ü§ñ OpenAI –ø—Ä–æ–≤–µ—Ä–∫–∞", key="find_typos_openai", use_container_width=True):
                    st.session_state['openai_check_requested'] = True
            else:
                if not OPENAI_AVAILABLE:
                    st.caption("‚ö†Ô∏è OpenAI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                else:
                    st.caption("‚ö†Ô∏è –ù–µ—Ç API –∫–ª—é—á–∞")
        
        # –§–∏–ª—å—Ç—Ä –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        with st.expander("üåê –ê–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã", expanded=False):
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            english_queries = load_english_queries()
            
            # –ß–µ–∫–±–æ–∫—Å –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞ (–≤–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            use_english_filter = st.checkbox(
                "‚úÖ –í–∫–ª—é—á–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤",
                value=True,
                help="–ò—Å–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã, –∫—Ä–æ–º–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –≤ —Å–ø–∏—Å–∫–µ",
                key="use_english_filter"
            )
            
            if use_english_filter:
                st.info(f"‚úÖ **–§–∏–ª—å—Ç—Ä –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤–∫–ª—é—á–µ–Ω** - –±—É–¥–µ—Ç –æ—Å—Ç–∞–≤–ª–µ–Ω–æ {len(english_queries)} –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            if df_processed is not None and not df_processed.empty and "–ó–∞–ø—Ä–æ—Å" in df_processed.columns:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                if "detected_english_queries" not in st.session_state:
                    st.session_state["detected_english_queries"] = []
                if "show_detected_english" not in st.session_state:
                    st.session_state["show_detected_english"] = False
                
                col_detect1, col_detect2 = st.columns([2, 1])
                with col_detect1:
                    if st.button("üîç –ù–∞–π—Ç–∏ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã", key="detect_english_queries_button", use_container_width=True):
                        with st.spinner("üîç –ò—â—É –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã..."):
                            english_df = detect_english_queries(df_processed)
                            if not english_df.empty:
                                detected_queries = english_df["–ó–∞–ø—Ä–æ—Å"].astype(str).tolist()
                                st.session_state["detected_english_queries"] = detected_queries
                                st.session_state["show_detected_english"] = True
                                st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(detected_queries)} –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤!")
                            else:
                                st.info("‚ÑπÔ∏è –ê–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
                
                with col_detect2:
                    if st.session_state["detected_english_queries"]:
                        st.metric("–ù–∞–π–¥–µ–Ω–æ", len(st.session_state["detected_english_queries"]))
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                if st.session_state["show_detected_english"] and st.session_state["detected_english_queries"]:
                    detected_queries = st.session_state["detected_english_queries"]
                    
                    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –∏ –Ω–æ–≤—ã–µ
                    existing_queries_list = [q.lower() for q in english_queries]
                    new_queries = [q for q in detected_queries if q.lower() not in existing_queries_list]
                    already_added = [q for q in detected_queries if q.lower() in existing_queries_list]
                    
                    if new_queries:
                        st.markdown(f"**üìã –ù–∞–π–¥–µ–Ω–æ {len(new_queries)} –Ω–æ–≤—ã—Ö –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:**")
                        
                        # –ö–Ω–æ–ø–∫–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
                        col_add_all_eng, col_add_selected_eng = st.columns(2)
                        with col_add_all_eng:
                            if st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã", key="add_all_english_queries", use_container_width=True):
                                added_count = 0
                                for query in new_queries:
                                    if query not in english_queries:
                                        english_queries.append(query)
                                        added_count += 1
                                
                                if added_count > 0:
                                    english_queries = sorted(list(set(english_queries)))
                                    if save_english_queries(english_queries):
                                        st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –∑–∞–ø—Ä–æ—Å–æ–≤!")
                                        st.session_state["detected_english_queries"] = []
                                        st.session_state["show_detected_english"] = False
                                        st.rerun()
                        
                        with col_add_selected_eng:
                            # –ú—É–ª—å—Ç–∏—Å–µ–ª–µ–∫—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
                            selected_queries = st.multiselect(
                                "–í—ã–±–µ—Ä–∏—Ç–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è:",
                                options=new_queries,
                                default=[],
                                key="select_english_queries_to_add",
                                format_func=lambda x: x
                            )
                            
                            if selected_queries and st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ", key="add_selected_english_queries", use_container_width=True):
                                added_count = 0
                                for query in selected_queries:
                                    if query not in english_queries:
                                        english_queries.append(query)
                                        added_count += 1
                                
                                if added_count > 0:
                                    english_queries = sorted(list(set(english_queries)))
                                    if save_english_queries(english_queries):
                                        st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –∑–∞–ø—Ä–æ—Å–æ–≤!")
                                        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                                        for q in selected_queries:
                                            if q in st.session_state["detected_english_queries"]:
                                                st.session_state["detected_english_queries"].remove(q)
                                        if not st.session_state["detected_english_queries"]:
                                            st.session_state["show_detected_english"] = False
                                        st.rerun()
                    
                    if already_added:
                        st.markdown(f"**‚úÖ –£–∂–µ –≤ —Å–ø–∏—Å–∫–µ ({len(already_added)} –∑–∞–ø—Ä–æ—Å–æ–≤):**")
                        already_text = ", ".join(already_added[:10])
                        if len(already_added) > 10:
                            already_text += f" –∏ –µ—â–µ {len(already_added) - 10}..."
                        st.caption(already_text)
            
            # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
            english_query_col1, english_query_col2 = st.columns([3, 1])
            with english_query_col1:
                new_english_query = st.text_input(
                    "–î–æ–±–∞–≤–∏—Ç—å –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
                    placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: leather jacket/women dress/summer shoes (–Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ /)",
                    key="new_english_query",
                    label_visibility="collapsed",
                    help="–ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å—Ä–∞–∑—É, —Ä–∞–∑–¥–µ–ª–∏–≤ –∏—Ö —Å–∏–º–≤–æ–ª–æ–º /"
                )
            with english_query_col2:
                st.write("")
                st.write("")
                col_add_english, col_clear_english = st.columns(2)
                if col_add_english.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å", key="add_english_query", use_container_width=True):
                    if new_english_query and new_english_query.strip():
                        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ "/" –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å
                        queries_to_add = [q.strip() for q in new_english_query.split("/") if q.strip()]
                        added_queries = []
                        skipped_queries = []
                        
                        for query in queries_to_add:
                            if query not in english_queries:
                                english_queries.append(query)
                                added_queries.append(query)
                            else:
                                skipped_queries.append(query)
                        
                        if added_queries:
                            english_queries = sorted(list(set(english_queries)))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
                            if save_english_queries(english_queries):
                                if len(added_queries) == 1:
                                    st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {added_queries[0]}")
                                else:
                                    st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(added_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤: {', '.join(added_queries)}")
                                if skipped_queries:
                                    st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –≤ —Å–ø–∏—Å–∫–µ): {', '.join(skipped_queries)}")
                                st.rerun()
                        else:
                            if skipped_queries:
                                if len(skipped_queries) == 1:
                                    st.warning(f"‚ö†Ô∏è –ó–∞–ø—Ä–æ—Å —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ: {skipped_queries[0]}")
                                else:
                                    st.warning(f"‚ö†Ô∏è –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ: {', '.join(skipped_queries)}")
                if col_clear_english.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", key="clear_english_queries", use_container_width=True):
                    english_queries = []
                    if save_english_queries(english_queries):
                        st.success("‚úÖ –°–ø–∏—Å–æ–∫ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –æ—á–∏—â–µ–Ω")
                        st.rerun()
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
            if english_queries:
                st.caption(f"–í—Å–µ–≥–æ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {len(english_queries)}")
                
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                if "selected_english_queries" not in st.session_state:
                    st.session_state["selected_english_queries"] = []
                
                # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                col_select_all_eng, col_deselect_all_eng, col_delete_eng, col_download_json_eng, col_download_csv_eng = st.columns(5)
                with col_select_all_eng:
                    if st.button("‚úÖ –í—ã–±—Ä–∞—Ç—å –≤—Å–µ", key="select_all_english_queries", use_container_width=True):
                        st.session_state["selected_english_queries"] = english_queries.copy()
                        st.rerun()
                with col_deselect_all_eng:
                    if st.button("‚ùå –°–Ω—è—Ç—å –≤—ã–±–æ—Ä", key="deselect_all_english_queries", use_container_width=True):
                        st.session_state["selected_english_queries"] = []
                        st.rerun()
                with col_delete_eng:
                    if st.button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ", key="delete_selected_english_queries", use_container_width=True, disabled=len(st.session_state["selected_english_queries"]) == 0):
                        if st.session_state["selected_english_queries"]:
                            for query in st.session_state["selected_english_queries"]:
                                if query in english_queries:
                                    english_queries.remove(query)
                            english_queries = sorted(list(set(english_queries)))
                            if save_english_queries(english_queries):
                                st.session_state["selected_english_queries"] = []
                                st.rerun()
                with col_download_json_eng:
                    # JSON —ç–∫—Å–ø–æ—Ä—Ç
                    english_queries_json = json.dumps(english_queries, ensure_ascii=False, indent=2)
                    st.download_button(
                        "üì• JSON",
                        data=english_queries_json,
                        file_name="english_queries.json",
                        mime="application/json",
                        use_container_width=True,
                        key="download_english_queries_json"
                    )
                with col_download_csv_eng:
                    # CSV —ç–∫—Å–ø–æ—Ä—Ç
                    if english_queries:
                        english_queries_df = pd.DataFrame({"–ó–∞–ø—Ä–æ—Å": english_queries})
                        english_queries_csv = english_queries_df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            "üìä CSV",
                            data=english_queries_csv,
                            file_name="english_queries.csv",
                            mime="text/csv",
                            use_container_width=True,
                            key="download_english_queries_csv"
                        )
                
                st.caption(f"–í—ã–±—Ä–∞–Ω–æ: {len(st.session_state['selected_english_queries'])}")
                
                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã —Å —á–µ–∫–±–æ–∫—Å–∞–º–∏
                num_cols = 2
                selected_queries_from_checkboxes = []
                for i in range(0, len(english_queries), num_cols):
                    cols = st.columns(num_cols)
                    for j, col in enumerate(cols):
                        if i + j < len(english_queries):
                            query = english_queries[i + j]
                            with col:
                                is_selected = query in st.session_state["selected_english_queries"]
                                checkbox_value = st.checkbox(query, key=f"cb_english_query_{i+j}_{query}", value=is_selected)
                                if checkbox_value:
                                    selected_queries_from_checkboxes.append(query)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º session_state –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π —á–µ–∫–±–æ–∫—Å–æ–≤
                st.session_state["selected_english_queries"] = selected_queries_from_checkboxes
            else:
                st.info("üí° –î–æ–±–∞–≤—å—Ç–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–æ—Å—Ç–∞–ª—å–Ω—ã–µ –±—É–¥—É—Ç –∏—Å–∫–ª—é—á–µ–Ω—ã)")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            english_queries_to_keep = english_queries if use_english_filter else None
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        st.markdown("---")
        additional_check_col1, additional_check_col2 = st.columns([3, 1])
        with additional_check_col1:
            st.caption("üí° **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞** - –±–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ—Å–ª–µ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤")
        with additional_check_col2:
            use_additional_check = st.button(
                "üîç –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞",
                key="additional_check",
                use_container_width=True,
                help="–ü—Ä–∏–º–µ–Ω—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –∫ —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º"
            )
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        # –§–∏–ª—å—Ç—Ä –ø–æ –≤—ã—Ä—É—á–∫–µ —É–¥–∞–ª–µ–Ω
        
        # –î–ª—è —Ç–æ–≤–∞—Ä–æ–≤: –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏–∑–º–µ–Ω–∏–ª –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–≤–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É –∏–∑ —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
        if products_max == products_max_default:
            # –ó–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –∏–∑–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º, –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
            use_products_max = None
        else:
            # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏–ª –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ, –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–æ 0 (–¥–ª—è —è–≤–Ω–æ–≥–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
            use_products_max = products_max
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤ —á–∞—Å—Ç–æ—Ç—ã
        if "–ß–∞—Å—Ç–æ—Ç–∞ WB" in df_processed.columns:
            use_frequency_wb_min = frequency_wb_min if frequency_wb_min and frequency_wb_min > 0 else None
            use_frequency_wb_max = frequency_wb_max if frequency_wb_max and frequency_wb_max < frequency_wb_max_default else None
        else:
            use_frequency_wb_min = None
            use_frequency_wb_max = None
        
        filtered_df, clothing_mask = apply_filters(
            df_processed,
            minus_words,
            clothing_filter,
            use_garbage_filter,
            products_min,  # –ü–µ—Ä–µ–¥–∞–µ–º –≤—Å–µ–≥–¥–∞, –¥–∞–∂–µ –µ—Å–ª–∏ 0
            use_products_max,
            use_frequency_wb_min,
            use_frequency_wb_max,
            use_automatic_filters,  # –ü–µ—Ä–µ–¥–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
            use_brand_filter,  # –ü–µ—Ä–µ–¥–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä —Ñ–∏–ª—å—Ç—Ä–∞ –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            english_queries_to_keep  # –ü–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        )
        
        # –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º—É—Å–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ—Å–ª–µ –≤—Å–µ—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
        # –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∞–ª –∫–Ω–æ–ø–∫—É "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞"
        if use_additional_check and filtered_df is not None and not filtered_df.empty and "–ó–∞–ø—Ä–æ—Å" in filtered_df.columns:
            with st.spinner("üîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞..."):
                initial_count = len(filtered_df)
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –µ—â–µ —Ä–∞–∑ –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º
                final_garbage_mask = detect_garbage_queries(filtered_df)
                if final_garbage_mask.any():
                    # –£–¥–∞–ª—è–µ–º –∑–∞–ø—Ä–æ—Å—ã —Å –æ—à–∏–±–∫–∞–º–∏
                    filtered_df = filtered_df[~final_garbage_mask].copy()
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                queries_lower = filtered_df["–ó–∞–ø—Ä–æ—Å"].astype(str).str.lower().str.strip()
                known_garbage_phrases = [
                    '—É–≥–∏ –¥–µ—à–µ–≤—ã–µ', '–¥–∂–∏–Ω—Ü–≤', '–ø–∞—Ä—É–∞', '–¥–∂—ã–Ω—Ü—ã', '—é–≥–≥–∏', '—É–≥–≥—É', 
                    '—É–≥—à–∏', '—É–≥–Ω–º', '–∞–ª—Ç—Å–∞', '–∂–∏–Ω—Å–∏', '–¥–∂–∏–Ω—Å—Ü', '–ø–ª–∞—å–µ', '–ø–∞—Ç—å–µ',
                    '–¥—É–±–ª–µ–Ω–∫—É –±–æ–ª—å—à–∏—Ö —Ä–∞–∑–º–µ—Ä–æ–≤', '—à–∞—Ç–Ω—ã –∫–ª–µ—à', '—É—É–≥–∏', '—é–±—É–∞',
                    '–¥—É—å–∏–∫–∏', '–ª—É—Ç–∏–∫–∏', '–¥–∫—Ç–∏–∫–∏', '–¥—É—Ç–∏—É–∏', '–¥—É—Ç–º–∫–∏', '–ø–∏–Ω–¥–∂–∞–∫', '—ç—É–¥–∏'
                ]
                for phrase in known_garbage_phrases:
                    mask_phrase = ~queries_lower.str.contains(phrase, case=False, na=False)
                    filtered_df = filtered_df[mask_phrase].copy()
                
                final_count = len(filtered_df)
                removed_count = initial_count - final_count
                
                if removed_count > 0:
                    st.success(f"‚úÖ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: —É–¥–∞–ª–µ–Ω–æ {removed_count} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏ (–æ—Å—Ç–∞–ª–æ—Å—å {final_count})")
                else:
                    st.info("‚ÑπÔ∏è –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–æ–≤—ã—Ö –æ—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ OpenAI –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
        if st.session_state.get('openai_check_requested', False):
            st.session_state['openai_check_requested'] = False  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥
            
            api_key = st.session_state.get('openai_api_key', '')
            if not api_key:
                try:
                    api_key = st.secrets.get('openai_api_key', '')
                except:
                    pass
            
            if api_key and OPENAI_AVAILABLE:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                typos, report = find_typos_with_openai(filtered_df, api_key)
                if typos:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Å–ø–∏—Å–æ–∫ –∏–∑ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                    openai_typos = load_openai_typos()
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–ª–æ–≤–∞
                    new_typos = [w for w in typos if w not in openai_typos]
                    if new_typos:
                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ä—ã–µ –∏ –Ω–æ–≤—ã–µ —Å–ª–æ–≤–∞
                        openai_typos.extend(new_typos)
                        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
                        openai_typos = sorted(list(set(openai_typos)))
                        if save_openai_typos(openai_typos):
                            st.success(f"‚úÖ OpenAI –Ω–∞—à–µ–ª {len(new_typos)} –Ω–æ–≤—ã—Ö —Å–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏ (–≤—Å–µ–≥–æ –≤ —Å–ø–∏—Å–∫–µ: {len(openai_typos)})")
                            
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç –≤ —Å–≤–µ—Ä–Ω—É—Ç–æ–º –≤–∏–¥–µ
                            with st.expander("üìã –û—Ç—á–µ—Ç OpenAI (–≤—Ç–æ—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)", expanded=False):
                                st.text(report)
                                st.caption("üí° –≠—Ç–æ –≤—Ç–æ—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞. OpenAI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å—ã, –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤.")
                            
                            st.rerun()
                        else:
                            st.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                    else:
                        st.info("‚ÑπÔ∏è –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ —É–∂–µ –≤ —Å–ø–∏—Å–∫–µ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç –¥–∞–∂–µ –µ—Å–ª–∏ —Å–ª–æ–≤–∞ –Ω–µ –¥–æ–±–∞–≤–∏–ª–∏—Å—å
                        if report:
                            with st.expander("üìã –û—Ç—á–µ—Ç OpenAI (–≤—Ç–æ—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)", expanded=False):
                                st.text(report)
                else:
                    if report:
                        st.warning("‚ö†Ô∏è OpenAI –Ω–µ –Ω–∞—à–µ–ª —Å–ª–æ–≤–∞ —Å –æ—à–∏–±–∫–∞–º–∏ –≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö")
                        with st.expander("üìã –û—Ç—á–µ—Ç OpenAI", expanded=False):
                            st.text(report)
                    else:
                        st.warning("‚ö†Ô∏è OpenAI –Ω–µ –Ω–∞—à–µ–ª —Å–ª–æ–≤–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
        st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–∞—Ö
        with st.expander("‚ÑπÔ∏è –ü—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã", expanded=False):
            st.markdown("**–°–ª–µ–¥—É—é—â–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è:**")
            filter_list = []
            
            if use_automatic_filters:
                filter_list.append("1. **–û—á–∏—Å—Ç–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ (–≤–∫–ª—é—á–µ–Ω–∞):**")
                filter_list.append("   - –§–∏–ª—å—Ç—Ä –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (1-3 —Å–∏–º–≤–æ–ª–∞)")
                filter_list.append("   - –§–∏–ª—å—Ç—Ä –ø—Ä–µ–¥–ª–æ–≥–æ–≤/—Å–æ—é–∑–æ–≤")
                filter_list.append("   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏")
                filter_list.append("   - –§–∏–ª—å—Ç—Ä –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –º—É—Å–æ—Ä–Ω—ã—Ö —Ñ—Ä–∞–∑ (–¥–∂–∏–Ω—Å—Ü, –ø–ª–∞—å–µ, –ø–∞—Ç—å–µ –∏ –¥—Ä.)")
            else:
                filter_list.append("1. **–û—á–∏—Å—Ç–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ (–æ—Ç–∫–ª—é—á–µ–Ω–∞)**")
            
            if use_brand_filter:
                brand_queries_count = len(load_brand_queries())
                filter_list.append(f"2. **–§–∏–ª—å—Ç—Ä –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–≤–∫–ª—é—á–µ–Ω)** - –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –∑–∞–ø—Ä–æ—Å—ã —Å {brand_queries_count} –±—Ä–µ–Ω–¥–∞–º–∏")
            else:
                filter_list.append("2. **–§–∏–ª—å—Ç—Ä –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ—Ç–∫–ª—é—á–µ–Ω)**")
            
            if use_english_filter:
                saved_english_queries = load_english_queries()
                if len(saved_english_queries) > 0:
                    filter_list.append(f"3. **–§–∏–ª—å—Ç—Ä –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–≤–∫–ª—é—á–µ–Ω)** - –æ—Å—Ç–∞–≤–ª–µ–Ω–æ {len(saved_english_queries)} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
                else:
                    filter_list.append("3. **–§–∏–ª—å—Ç—Ä –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–≤–∫–ª—é—á–µ–Ω)** - –∏—Å–∫–ª—é—á–µ–Ω—ã –≤—Å–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (—Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç)")
            else:
                filter_list.append("3. **–§–∏–ª—å—Ç—Ä –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ—Ç–∫–ª—é—á–µ–Ω)**")
            
            filter_list.append("4. **–ú–∏–Ω—É—Å —Å–ª–æ–≤–∞ –∏–∑ —Ñ–∞–π–ª–∞** - –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —Å–ª–æ–≤–∞ –∏–∑ `minus_words.json` (–±—Ä–µ–Ω–¥–æ–≤—ã–µ –∏ –¥—Ä—É–≥–∏–µ)")
            filter_list.append("5. **–ú–∏–Ω—É—Å —Å–ª–æ–≤–∞ –∏–∑ OpenAI** - –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —Å–ª–æ–≤–∞, –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞—Ö —á–µ—Ä–µ–∑ OpenAI")
            
            st.markdown("\n".join(filter_list))
            
            if minus_words:
                brand_count = len(minus_words.get("brand_words", []))
                other_count = len(minus_words.get("other_words", []))
                if brand_count > 0 or other_count > 0:
                    st.info(f"üìù –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è {brand_count} –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∏ {other_count} –¥—Ä—É–≥–∏—Ö –º–∏–Ω—É—Å —Å–ª–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞")
            openai_typos = load_openai_typos()
            if openai_typos:
                st.info(f"ü§ñ –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è {len(openai_typos)} —Å–ª–æ–≤ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ OpenAI")
            if minus_words:
                brand_count = len(minus_words.get("brand_words", []))
                other_count = len(minus_words.get("other_words", []))
                if brand_count > 0 or other_count > 0:
                    st.info(f"üìù –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è {brand_count} –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∏ {other_count} –¥—Ä—É–≥–∏—Ö –º–∏–Ω—É—Å —Å–ª–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞")
            openai_typos = load_openai_typos()
            if openai_typos:
                st.info(f"ü§ñ –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è {len(openai_typos)} —Å–ª–æ–≤ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ OpenAI")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ filtered_df —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –Ω–µ –ø—É—Å—Ç–æ–π
        if filtered_df is None or filtered_df.empty:
            st.warning("‚ö†Ô∏è –ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
        else:
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –æ–¥–µ–∂–¥–µ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—É—é –º–∞—Å–∫—É)
            if clothing_mask is not None:
                clothing_count = clothing_mask.sum()
                non_clothing_count = len(df_processed) - clothing_count
            elif "–ó–∞–ø—Ä–æ—Å" in df_processed.columns:
                # –ï—Å–ª–∏ –º–∞—Å–∫–∞ –Ω–µ –±—ã–ª–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∞, –≤—ã—á–∏—Å–ª—è–µ–º –æ–¥–∏–Ω —Ä–∞–∑
                pattern = get_clothing_keywords_pattern()
                clothing_mask = df_processed["–ó–∞–ø—Ä–æ—Å"].str.contains(pattern, case=False, na=False, regex=True)
                clothing_count = clothing_mask.sum()
                non_clothing_count = len(df_processed) - clothing_count
            else:
                clothing_count = 0
                non_clothing_count = 0
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤", f"{len(df_processed):,}")
            with col2:
                st.metric("–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤", f"{len(filtered_df):,}")
            with col3:
                st.metric("–° –æ–¥–µ–∂–¥–æ–π", f"{clothing_count:,}", 
                         help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ–¥–µ–∂–¥–æ–π")
            with col4:
                # –ú–µ—Ç—Ä–∏–∫–∞ —É–¥–∞–ª–µ–Ω–∞
                pass
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ —Ñ–∏–ª—å—Ç—Ä—É –æ–¥–µ–∂–¥—ã (–∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—É—é –º–∞—Å–∫—É)
            if clothing_filter in ["–¢–æ–ª—å–∫–æ –æ–¥–µ–∂–¥–∞", "–ë–µ–∑ –æ–¥–µ–∂–¥—ã"] and "–ó–∞–ø—Ä–æ—Å" in df_processed.columns and clothing_mask is not None:
                if clothing_filter == "–¢–æ–ª—å–∫–æ –æ–¥–µ–∂–¥–∞":
                    # –ò—Å–∫–ª—é—á–µ–Ω—ã –∑–∞–ø—Ä–æ—Å—ã –ë–ï–ó –æ–¥–µ–∂–¥—ã
                    excluded_queries = df_processed[~clothing_mask]["–ó–∞–ø—Ä–æ—Å"].tolist()
                    filter_description = "–ë–µ–∑ –æ–¥–µ–∂–¥—ã"
                else:  # "–ë–µ–∑ –æ–¥–µ–∂–¥—ã"
                    # –ò—Å–∫–ª—é—á–µ–Ω—ã –∑–∞–ø—Ä–æ—Å—ã –° –æ–¥–µ–∂–¥–æ–π
                    excluded_queries = df_processed[clothing_mask]["–ó–∞–ø—Ä–æ—Å"].tolist()
                    filter_description = "–° –æ–¥–µ–∂–¥–æ–π"
                
                if excluded_queries:
                    with st.expander(f"üö´ –ò—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã ({len(excluded_queries)}): {filter_description}", expanded=False):
                        st.caption(f"–ó–∞–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —Å–∫—Ä—ã—Ç—ã —Ñ–∏–ª—å—Ç—Ä–æ–º '{clothing_filter}'")
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
                        num_cols = 3
                        for i in range(0, len(excluded_queries), num_cols):
                            cols = st.columns(num_cols)
                            for j, col in enumerate(cols):
                                if i + j < len(excluded_queries):
                                    with col:
                                        st.text(f"‚Ä¢ {excluded_queries[i + j]}")
            
            # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (—Å–≤–µ—Ä–Ω—É—Ç—ã–π)
            if "–ó–∞–ø—Ä–æ—Å" in filtered_df.columns:
                all_queries = filtered_df["–ó–∞–ø—Ä–æ—Å"].tolist()
                if all_queries:
                    with st.expander(f"üìã –í—Å–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã ({len(all_queries)})", expanded=False):
                        st.caption(f"–ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–∑ {len(all_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤, –ø—Ä–æ—à–µ–¥—à–∏—Ö –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã")
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
                        num_cols = 3
                        for i in range(0, len(all_queries), num_cols):
                            cols = st.columns(num_cols)
                            for j, col in enumerate(cols):
                                if i + j < len(all_queries):
                                    with col:
                                        st.text(f"‚Ä¢ {all_queries[i + j]}")
        
            # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            st.subheader("üìã –¢–∞–±–ª–∏—Ü–∞ –∑–∞–ø—Ä–æ—Å–æ–≤")
            
            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ –∏—Ö —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                column_order = []
                column_rename = {}
                
                # –°–æ–∑–¥–∞–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ Wildberries
                if "–ó–∞–ø—Ä–æ—Å" in filtered_df.columns:
                    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å—Å—ã–ª–∫–∏ –Ω–∞ Wildberries
                    def create_wb_link(query):
                        if pd.isna(query) or not query:
                            return ""
                        query_str = str(query).strip()
                        if not query_str:
                            return ""
                        # URL-–∫–æ–¥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
                        encoded_query = quote(query_str)
                        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É
                        return f"https://www.wildberries.ru/catalog/0/search.aspx?search={encoded_query}"
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å–æ —Å—Å—ã–ª–∫–∞–º–∏
                    filtered_df = filtered_df.copy()
                    filtered_df["–°—Å—ã–ª–∫–∞"] = filtered_df["–ó–∞–ø—Ä–æ—Å"].apply(create_wb_link)
                
                # –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –≤ –Ω—É–∂–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
                if "–ó–∞–ø—Ä–æ—Å" in filtered_df.columns:
                    column_order.append("–ó–∞–ø—Ä–æ—Å")
                    column_rename["–ó–∞–ø—Ä–æ—Å"] = "–ó–∞–ø—Ä–æ—Å"
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å–æ —Å—Å—ã–ª–∫–æ–π –ø–æ—Å–ª–µ "–ó–∞–ø—Ä–æ—Å"
                if "–°—Å—ã–ª–∫–∞" in filtered_df.columns:
                    column_order.append("–°—Å—ã–ª–∫–∞")
                    column_rename["–°—Å—ã–ª–∫–∞"] = "–°—Å—ã–ª–∫–∞"
                
                if "–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª" in filtered_df.columns:
                    column_order.append("–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª")
                    column_rename["–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª"] = "–ß. –Ω–∞ 1 –∞—Ä—Ç."
                elif "–ß. –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª" in filtered_df.columns:
                    column_order.append("–ß. –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª")
                    column_rename["–ß. –Ω–∞ 1 –∞—Ä—Ç–∏–∫—É–ª"] = "–ß. –Ω–∞ 1 –∞—Ä—Ç."
                
                if "–ß–∞—Å—Ç–æ—Ç–∞ WB" in filtered_df.columns:
                    column_order.append("–ß–∞—Å—Ç–æ—Ç–∞ WB")
                    column_rename["–ß–∞—Å—Ç–æ—Ç–∞ WB"] = "–ß–∞—Å—Ç–æ—Ç–∞"
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü "–¢–æ–≤–∞—Ä—ã" —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ "–ß–∞—Å—Ç–æ—Ç–∞"
                if "–¢–æ–≤–∞—Ä—ã" in filtered_df.columns:
                    column_order.append("–¢–æ–≤–∞—Ä—ã")
                    column_rename["–¢–æ–≤–∞—Ä—ã"] = "–¢–æ–≤–∞—Ä—ã"
                
                if "–¢—Ä–µ–Ω–¥ 30 –¥–Ω–µ–π" in filtered_df.columns:
                    column_order.append("–¢—Ä–µ–Ω–¥ 30 –¥–Ω–µ–π")
                    column_rename["–¢—Ä–µ–Ω–¥ 30 –¥–Ω–µ–π"] = "–¢—Ä–µ–Ω–¥ 30"
                
                if "–¢—Ä–µ–Ω–¥ 60 –¥–Ω–µ–π" in filtered_df.columns:
                    column_order.append("–¢—Ä–µ–Ω–¥ 60 –¥–Ω–µ–π")
                    column_rename["–¢—Ä–µ–Ω–¥ 60 –¥–Ω–µ–π"] = "–¢—Ä–µ–Ω–¥ 60"
                
                if "–¢—Ä–µ–Ω–¥ 90 –¥–Ω–µ–π" in filtered_df.columns:
                    column_order.append("–¢—Ä–µ–Ω–¥ 90 –¥–Ω–µ–π")
                    column_rename["–¢—Ä–µ–Ω–¥ 90 –¥–Ω–µ–π"] = "–¢—Ä–µ–Ω–¥ 90"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                other_columns = ["–°—Ä. —Ü–µ–Ω–∞", "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª", "–í—ã—Ä—É—á–∫–∞"]
                for col in other_columns:
                    if col in filtered_df.columns and col not in column_order:
                        column_order.append(col)
                        column_rename[col] = col
                
                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã –≤ –Ω—É–∂–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
                available_columns = [col for col in column_order if col in filtered_df.columns]
                
                if not available_columns:
                    st.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                    st.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –≤ –¥–∞–Ω–Ω—ã—Ö: {', '.join(filtered_df.columns.tolist())}")
                elif len(filtered_df) == 0:
                    st.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞ –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤")
                else:
                    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                    display_df = filtered_df[available_columns].copy()
                    
                    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
                    display_df = display_df.rename(columns=column_rename)
                    
                    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –∏ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
                    col_cfg = {}
                    if "–°—Å—ã–ª–∫–∞" in display_df.columns:
                        col_cfg["–°—Å—ã–ª–∫–∞"] = cc.LinkColumn(
                            "–°—Å—ã–ª–∫–∞",
                            display_text="üîó",
                            width=60,
                            help="–û—Ç–∫—Ä—ã—Ç—å –ø–æ–∏—Å–∫ –Ω–∞ Wildberries"
                        )
                    
                    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–æ–ª–±—Ü–∞ "–¢–æ–≤–∞—Ä—ã" –∫–∞–∫ —á–∏—Å–ª–æ–≤–æ–≥–æ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
                    if "–¢–æ–≤–∞—Ä—ã" in display_df.columns:
                        col_cfg["–¢–æ–≤–∞—Ä—ã"] = cc.NumberColumn(
                            "–¢–æ–≤–∞—Ä—ã",
                            format="%d",  # –¶–µ–ª–æ–µ —á–∏—Å–ª–æ –±–µ–∑ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ç—ã—Å—è—á
                            help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤"
                        )
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ —Ç—ã—Å—è—á (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ)
                    # –¢–æ–≤–∞—Ä—ã –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –ë–ï–ó —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ç—ã—Å—è—á
                    columns_with_thousands = ["–í—ã—Ä—É—á–∫–∞", "–°—Ä. —Ü–µ–Ω–∞", 
                                              "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª", "–ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞", "–°—Ä. —Ü–µ–Ω–∞ —Å –°–ü–ü", "–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞"]
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ —Ç—ã—Å—è—á —Ç–æ–ª—å–∫–æ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ (–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ)
                    for col in columns_with_thousands:
                        if col in display_df.columns:
                            try:
                                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Å—Ç–æ–ª–±–µ—Ü —á–∏—Å–ª–æ–≤–æ–π
                                if not pd.api.types.is_numeric_dtype(display_df[col]):
                                    display_df[col] = pd.to_numeric(display_df[col], errors="coerce")
                                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ —Ç—ã—Å—è—á (–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ —á–µ—Ä–µ–∑ map)
                                display_df[col] = display_df[col].map(lambda x: f"{x:,.0f}" if pd.notna(x) and x != "" else "", na_action='ignore')
                            except Exception as e:
                                # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü –∫–∞–∫ –µ—Å—Ç—å
                                pass
                    
                    # "–ß–∞—Å—Ç–æ—Ç–∞" –∏ "–ß. –Ω–∞ 1 –∞—Ä—Ç." –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã (–±–µ–∑ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è)
                    frequency_columns = ["–ß–∞—Å—Ç–æ—Ç–∞", "–ß. –Ω–∞ 1 –∞—Ä—Ç."]
                    for col in frequency_columns:
                        if col in display_df.columns:
                            # –ù–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏ –Ω–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                            pass
                    
                    # "–¢–æ–≤–∞—Ä—ã" –æ—Å—Ç–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–º –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
                    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–æ —á–µ—Ä–µ–∑ column_config
                    if "–¢–æ–≤–∞—Ä—ã" in display_df.columns:
                        try:
                            if not pd.api.types.is_numeric_dtype(display_df["–¢–æ–≤–∞—Ä—ã"]):
                                display_df["–¢–æ–≤–∞—Ä—ã"] = pd.to_numeric(display_df["–¢–æ–≤–∞—Ä—ã"], errors="coerce")
                            # –ù–ï —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É - –æ—Å—Ç–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–º –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
                        except Exception as e:
                            pass
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥—ã —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏ –∏ —Ü–≤–µ—Ç–æ–≤—ã–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                    trend_columns_display = ["–¢—Ä–µ–Ω–¥ 30", "–¢—Ä–µ–Ω–¥ 60", "–¢—Ä–µ–Ω–¥ 90"]
                    trend_columns_original = {
                        "–¢—Ä–µ–Ω–¥ 30": "–¢—Ä–µ–Ω–¥ 30 –¥–Ω–µ–π",
                        "–¢—Ä–µ–Ω–¥ 60": "–¢—Ä–µ–Ω–¥ 60 –¥–Ω–µ–π",
                        "–¢—Ä–µ–Ω–¥ 90": "–¢—Ä–µ–Ω–¥ 90 –¥–Ω–µ–π"
                    }
                    
                    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ —á–∏—Å–ª–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                    styled_df = display_df.copy()
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–æ–≤ –¥–ª—è —Ü–≤–µ—Ç–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                    trend_numeric_values = {}
                    for col_display, col_original in trend_columns_original.items():
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è —Å—Ç–æ–ª–±—Ü–∞ –≤ filtered_df
                        if col_original in filtered_df.columns:
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ filtered_df
                            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã–µ (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float)
                            numeric_col = pd.to_numeric(filtered_df[col_original], errors="coerce")
                            
                            # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –∏–Ω–¥–µ–∫—Å—ã, —á—Ç–æ –∏ –≤ display_df (–∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞–Ω –∏–∑ filtered_df)
                            # –ò–Ω–¥–µ–∫—Å—ã –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å, —Ç–∞–∫ –∫–∞–∫ display_df —Å–æ–∑–¥–∞–µ—Ç—Å—è –∏–∑ filtered_df
                            # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —Å display_df –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
                            numeric_col_aligned = numeric_col.reindex(display_df.index)
                            trend_numeric_values[col_display] = numeric_col_aligned
                            
                            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –≤ styled_df (–µ—Å–ª–∏ —Å—Ç–æ–ª–±–µ—Ü –µ—Å—Ç—å –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è)
                            if col_display in styled_df.columns:
                                try:
                                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                                    styled_df[col_display] = numeric_col_aligned.map(
                                        lambda x: f"{x:+.1f}%" if pd.notna(x) else "",
                                        na_action='ignore'
                                    )
                                except Exception:
                                    pass
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ü–≤–µ—Ç–æ–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ pandas Styler
                    has_trends = any(col in styled_df.columns for col in trend_columns_display)
                    
                    if has_trends:
                        # –°–æ–∑–¥–∞–µ–º Styler –æ–±—ä–µ–∫—Ç
                        styler = styled_df.style
                        
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ü–≤–µ—Ç–æ–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –∫–∞–∂–¥–æ–º—É —Å—Ç–æ–ª–±—Ü—É —Ç—Ä–µ–Ω–¥–æ–≤
                        for col_display in trend_columns_display:
                            if col_display in styled_df.columns and col_display in trend_numeric_values:
                                numeric_vals = trend_numeric_values[col_display].copy()
                                
                                # –í—ã—á–∏—Å–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏
                                valid_values = numeric_vals.dropna()
                                if len(valid_values) > 0:
                                    max_abs_value = valid_values.abs().max()
                                    if max_abs_value == 0:
                                        max_abs_value = 50  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                                else:
                                    max_abs_value = 50
                                
                                # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∏–ª–µ–π –∫ —Å—Ç–æ–ª–±—Ü—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∑–∞–º—ã–∫–∞–Ω–∏–µ–º
                                def make_style_func(numeric_series, max_abs):
                                    """–°–æ–∑–¥–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∏–ª–µ–π —Å –∑–∞–º—ã–∫–∞–Ω–∏–µ–º"""
                                    def apply_trend_style_col(col_series):
                                        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ü–≤–µ—Ç–æ–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ —Å—Ç–æ–ª–±—Ü—É —Ç—Ä–µ–Ω–¥–æ–≤"""
                                        styles = []
                                        for idx in col_series.index:
                                            if idx in numeric_series.index:
                                                num_value = numeric_series.loc[idx]
                                                if pd.notna(num_value) and num_value != 0:
                                                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç –∏ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–±—Å–æ–ª—é—Ç–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
                                                    abs_value = abs(num_value)
                                                    
                                                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –æ—Ç 0 –¥–æ 1
                                                    intensity = min(abs_value / max_abs, 1.0)
                                                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –∫–æ—Ä–µ–Ω—å –¥–ª—è –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞
                                                    intensity = intensity ** 0.7
                                                    
                                                    # –õ–û–ì–ò–ö–ê: –∑–Ω–∞—á–µ–Ω–∏–µ > 0 -> –ó–ï–õ–ï–ù–´–ô, –∑–Ω–∞—á–µ–Ω–∏–µ < 0 -> –ö–†–ê–°–ù–´–ô
                                                    if num_value < 0:
                                                        # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, -13) - –æ—Ç—Ç–µ–Ω–∫–∏ –ö–†–ê–°–ù–û–ì–û
                                                        # –ß–µ–º –±–æ–ª—å—à–µ –ø–æ –º–æ–¥—É–ª—é –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–µ–µ –∫—Ä–∞—Å–Ω—ã–π
                                                        r = int(255 - (intensity * 55))  # –û—Ç 255 –¥–æ 200
                                                        g = int(230 - (intensity * 230))  # –û—Ç 230 –¥–æ 0
                                                        b = int(230 - (intensity * 230))  # –û—Ç 230 –¥–æ 0
                                                        text_r = int(150 - (intensity * 50))  # –û—Ç 150 –¥–æ 100
                                                        styles.append(f'background-color: rgb({r}, {g}, {b}); color: rgb({text_r}, 0, 0); font-weight: bold;')
                                                    else:
                                                        # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2) - –æ—Ç—Ç–µ–Ω–∫–∏ –ó–ï–õ–ï–ù–û–ì–û
                                                        # –ß–µ–º –±–æ–ª—å—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–µ–µ –∑–µ–ª–µ–Ω—ã–π
                                                        r = int(230 - (intensity * 230))  # –û—Ç 230 –¥–æ 0
                                                        g = int(255 - (intensity * 55))  # –û—Ç 255 –¥–æ 200
                                                        b = int(230 - (intensity * 230))  # –û—Ç 230 –¥–æ 0
                                                        text_g = int(100 + (intensity * 50))  # –û—Ç 100 –¥–æ 150
                                                        styles.append(f'background-color: rgb({r}, {g}, {b}); color: rgb(0, {text_g}, 0); font-weight: bold;')
                                                else:
                                                    # –ù–æ–ª—å –∏–ª–∏ NaN - –±–µ–∑ —Ü–≤–µ—Ç–∞
                                                    styles.append('')
                                            else:
                                                styles.append('')
                                        return styles
                                    return apply_trend_style_col
                                
                                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª–∏ –∫ —Å—Ç–æ–ª–±—Ü—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∑–∞–º—ã–∫–∞–Ω–∏–µ–º
                                style_func = make_style_func(numeric_vals, max_abs_value)
                                styler = styler.apply(style_func, subset=[col_display], axis=0)
                        
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —á–µ—Ä–µ–∑ st.dataframe –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
                        # st.dataframe –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç pandas Styler –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                        st.dataframe(
                            styler,
                            use_container_width=True,
                            height=600,
                            column_config=col_cfg if col_cfg else None
                        )
                    else:
                        # –ï—Å–ª–∏ –Ω–µ—Ç —Ç—Ä–µ–Ω–¥–æ–≤, –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ–±—ã—á–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                        if len(display_df) > 0:
                            st.dataframe(
                                display_df,
                                use_container_width=True,
                                height=600,
                                column_config=col_cfg if col_cfg else None
                            )
                        else:
                            st.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞ –ø–æ—Å–ª–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü—ã: {e}")
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
                if filtered_df is not None and not filtered_df.empty:
                    st.dataframe(filtered_df, use_container_width=True, height=600)
            
            # –ö–Ω–æ–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞
            st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
            csv = filtered_df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (CSV)",
                data=csv,
                file_name=f"prospective_queries_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
else:
    if selected_month == "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (new.xlsx)":
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –∏–ª–∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ –ø–∞–ø–∫–µ trend –µ—Å—Ç—å —Ñ–∞–π–ª new.xlsx")
    else:
        st.info(f"üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π –º–µ—Å—è—Ü/–≥–æ–¥. –ò—â—É—Ç—Å—è —Ñ–∞–π–ª—ã: '{selected_month} —Ä–æ—Å—Ç {selected_year}.xlsx' –∏ '{selected_month} –ø–∞–¥–µ–Ω–∏–µ {selected_year}.xlsx'")
