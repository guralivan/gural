# -*- coding: utf-8 -*-
import os
import json
import base64
from io import BytesIO
import urllib.parse as _urlparse

import pandas as pd
import numpy as np
import streamlit as st
import requests

try:
    from PIL import Image
except Exception:
    Image = None

st.set_page_config(page_title="–î–∞—à–±–æ—Ä–¥ —Ç–æ–≤–∞—Ä–æ–≤ ‚Äî —Å–∫—Ä–∏–Ω—à–æ—Ç—ã", layout="wide")

def _cache_root():
    return os.path.join(os.path.dirname(os.path.abspath(__file__)), "wb_cache")
def _cache_dir():
    d = _cache_root()
    os.makedirs(d, exist_ok=True)
    os.makedirs(os.path.join(d, "imgs"), exist_ok=True)
    return d
def _url_cache_path():
    return os.path.join(_cache_dir(), "image_cache.json")
def load_url_cache():
    p = _url_cache_path()
    if os.path.exists(p):
        try:
            with open(p, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}
def save_url_cache(m: dict):
    try:
        with open(_url_cache_path(), "w", encoding="utf-8") as f:
            json.dump(m, f, ensure_ascii=False, indent=2)
    except Exception:
        pass
def get_url_cache():
    if "img_url_cache" not in st.session_state:
        st.session_state["img_url_cache"] = load_url_cache()
    return st.session_state["img_url_cache"]

def img_path_for(nm: str, fmt: str = "JPEG"):
    nm = str(nm).replace(".0", "")
    ext = "jpg" if fmt.upper() == "JPEG" else "png"
    return os.path.join(_cache_dir(), "imgs", f"{nm}.{ext}")
def get_cached_image_path(nm: str):
    nm = str(nm).replace(".0", "")
    for ext in ("jpg", "png", "jpeg", "webp"):
        p = os.path.join(_cache_dir(), "imgs", f"{nm}.{ext}")
        if os.path.exists(p):
            return p
    return ""
def ensure_image_cached(nm: str, url: str, fmt: str = "JPEG", timeout: int = 25) -> str:
    try:
        p_exist = get_cached_image_path(nm)
        if p_exist:
            return p_exist
        if not url:
            return ""
        path = img_path_for(nm, fmt)
        headers = {"User-Agent": "WB-Dashboard/1.0"}
        with requests.get(url, headers=headers, timeout=timeout, stream=True) as r:
            if r.status_code != 200:
                return ""
            with open(path, "wb") as f:
                for chunk in r.iter_content(8192):
                    if chunk:
                        f.write(chunk)
        return path
    except Exception:
        return ""
def load_image_bytes(path: str, max_w: int | None = None) -> bytes:
    if not path or not os.path.exists(path):
        return b""
    if Image is None or max_w is None:
        try:
            with open(path, "rb") as f:
                return f.read()
        except Exception:
            return b""
    try:
        im = Image.open(path)
        if im.mode not in ("RGB", "RGBA"):
            im = im.convert("RGB")
        if max_w and im.width > max_w:
            ratio = max_w / float(im.width)
            im = im.resize((int(im.width * ratio), int(im.height * ratio)))
        bio = BytesIO()
        im.save(bio, format="JPEG", quality=85)
        return bio.getvalue()
    except Exception:
        try:
            with open(path, "rb") as f:
                return f.read()
        except Exception:
            return b""
def img_data_uri(nm: str, max_w: int | None = None) -> str:
    p = get_cached_image_path(nm)
    if not p:
        return ""
    try:
        data = load_image_bytes(p, max_w=max_w)
        if not data:
            return ""
        b64 = base64.b64encode(data).decode("ascii")
        return f"data:image/jpeg;base64,{b64}"
    except Exception:
        return ""

def build_wb_product_url(nm, host="https://global.wildberries.ru"):
    return f"{host.rstrip('/')}/catalog/{str(nm).replace('.0','')}/detail.aspx"
def build_screenshot_url(page_url: str, key: str,
                         w: int = 400, h: int = 600,
                         fmt: str = "JPEG", profile: str = "D4",
                         base: str = "https://api.s-shot.ru"):
    q = _urlparse.quote(page_url, safe="")
    return f"{base.rstrip('/')}/{int(w)}x{int(h)}/{fmt}/{key}/{profile}/?{q}"
def screenshot_for_article(nm, conf):
    if not conf.get("key"):
        return ""
    page = build_wb_product_url(nm, conf.get("wb_host", "https://global.wildberries.ru"))
    return build_screenshot_url(
        page, conf.get("key", ""), conf.get("w", 400), conf.get("h", 600),
        conf.get("fmt", "JPEG"), conf.get("profile", "D4"), conf.get("base", "https://api.s-shot.ru")
    )

@st.cache_data(show_spinner=False)
def read_table(file_bytes: bytes, filename: str):
    try:
        if filename.lower().endswith((".xlsx", ".xls")):
            df_raw = pd.read_excel(BytesIO(file_bytes), sheet_name=0, header=None)
        else:
            df_raw = pd.read_csv(BytesIO(file_bytes), header=None, sep=None, engine="python")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return None, None, {}
    key_candidates = ["–ê—Ä—Ç–∏–∫—É–ª", "–í—ã—Ä—É—á–∫–∞", "–ó–∞–∫–∞–∑—ã", "–ù–∞–∑–≤–∞–Ω–∏–µ"]
    header_row = None
    for i in range(min(30, len(df_raw))):
        vals = df_raw.iloc[i].astype(str).str.strip().tolist()
        if any(k in vals for k in key_candidates):
            header_row = i
            break
    if header_row is None:
        header_row = 0
    if filename.lower().endswith((".xlsx", ".xls")):
        df = pd.read_excel(BytesIO(file_bytes), sheet_name=0, header=header_row)
    else:
        df = pd.read_csv(BytesIO(file_bytes), header=header_row, sep=None, engine="python")
    df = df.loc[:, ~df.columns.astype(str).str.startswith("Unnamed")]
    df = df.loc[:, df.columns.notna()]
    df.columns = [str(c).strip() for c in df.columns]
    rename_map = {
        "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –±–µ–∑ –°–ü–ü": "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞",
        "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –±–µ–∑ –°–ü–ü, ‚ÇΩ": "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞",
        "–¶–µ–Ω–∞": "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞",
        "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ": "–í—ã—Ä—É—á–∫–∞",
        "Orders": "–ó–∞–∫–∞–∑—ã",
        "Brand": "–ë—Ä–µ–Ω–¥",
        "Supplier": "–ü–æ—Å—Ç–∞–≤—â–∏–∫",
        "Subject": "–ü—Ä–µ–¥–º–µ—Ç",
        "Creation date": "–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è",
        "–î–∞—Ç–∞": "–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è",
        "–ü–æ–∑–∏—Ü–∏—è": "–ü–æ–∑–∏—Ü–∏—è –≤ –≤—ã–¥–∞—á–µ",
        "CPM": "–°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ 1000 –ø–æ–∫–∞–∑–æ–≤",
        "–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞, ‚ÇΩ": "–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞",
    }
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})
    num_cols = ["–í—ã—Ä—É—á–∫–∞","–ó–∞–∫–∞–∑—ã","–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞","–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞",
                "–ü–æ–∑–∏—Ü–∏—è –≤ –≤—ã–¥–∞—á–µ","–°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ 1000 –ø–æ–∫–∞–∑–æ–≤","–ë—É—Å—Ç –Ω–∞ –ø–æ–∑–∏—Ü–∏—é","–ë—É—Å—Ç —Å –ø–æ–∑–∏—Ü–∏–∏"]
    for c in num_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(
                df[c].astype(str).str.replace(r"[^\d,.-]", "", regex=True).str.replace(",", ".", regex=False),
                errors="coerce",
            )
    if "–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è" in df.columns:
        df["–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è"] = pd.to_datetime(df["–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è"], errors="coerce")
    if "–¢–∏–ø —Ä–µ–∫–ª–∞–º—ã" in df.columns:
        df["–¢–∏–ø —Ä–µ–∫–ª–∞–º—ã"] = df["–¢–∏–ø —Ä–µ–∫–ª–∞–º—ã"].replace({"b": "–ü–æ–∏—Å–∫", "c": "–ê–≤—Ç–æ–º–∞—Ç"})
    if ("–ë—É—Å—Ç –Ω–∞ –ø–æ–∑–∏—Ü–∏—é" in df.columns) and ("–ë—É—Å—Ç —Å –ø–æ–∑–∏—Ü–∏–∏" in df.columns) and ("–î–µ–ª—å—Ç–∞" not in df.columns):
        df["–î–µ–ª—å—Ç–∞"] = df["–ë—É—Å—Ç —Å –ø–æ–∑–∏—Ü–∏–∏"] - df["–ë—É—Å—Ç –Ω–∞ –ø–æ–∑–∏—Ü–∏—é"]
    return df, df_raw, {"header_row": header_row, "columns": list(df.columns)}

def format_thousands(x, decimals=0):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return ""
    try:
        xf = float(x)
    except Exception:
        return str(x) if x is not None else ""
    if decimals == 0:
        return f"{int(round(xf)):,}".replace(",", " ")
    return f"{xf:,.{decimals}f}".replace(",", " ").replace(".", ",")
def fmt_rub(x, decimals=0):
    s = format_thousands(x, decimals=decimals)
    return (s + " ‚ÇΩ") if s != "" else ""
def fmt_units(x, unit="—à—Ç."):
    s = format_thousands(x, decimals=0)
    return (s + f" {unit}") if s != "" else ""
def fmt_date(d):
    if d is None or (isinstance(d, float) and np.isnan(d)):
        return ""
    try:
        return pd.to_datetime(d).strftime("%d/%m/%y")
    except Exception:
        return str(d) if d is not None else ""
def parse_thousands_input(s, default_val):
    if s is None or str(s).strip() == "":
        return default_val
    try:
        cleaned = (str(s).replace("\\xa0"," ").replace("\\u00a0"," ").replace(" ", " "))
        cleaned = cleaned.replace(" ", "").replace(",", "").strip()
        return int(float(cleaned))
    except Exception:
        return default_val
def sort_df(df, col, asc):
    if col not in df.columns:
        return df
    if pd.api.types.is_numeric_dtype(df[col]):
        return df.sort_values(by=col, ascending=asc, na_position="last", kind="mergesort")
    return df.sort_values(by=col, ascending=asc, na_position="last", kind="mergesort",
                          key=lambda s: s.astype(str).str.lower())

def get_param_schemas():
    if "param_schemas" not in st.session_state:
        st.session_state["param_schemas"] = {}
    return st.session_state["param_schemas"]
def get_param_values():
    if "param_values" not in st.session_state:
        st.session_state["param_values"] = {}
    return st.session_state["param_values"]

def kpi_row(df):
    total_rev = float(df["–í—ã—Ä—É—á–∫–∞"].sum()) if "–í—ã—Ä—É—á–∫–∞" in df.columns else float('nan')
    total_orders = df["–ó–∞–∫–∞–∑—ã"].sum() if "–ó–∞–∫–∞–∑—ã" in df.columns else np.nan
    avg_check = (df["–í—ã—Ä—É—á–∫–∞"].sum() / df["–ó–∞–∫–∞–∑—ã"].sum()) if ("–í—ã—Ä—É—á–∫–∞" in df.columns and "–ó–∞–∫–∞–∑—ã" in df.columns and df["–ó–∞–∫–∞–∑—ã"].sum() > 0) else np.nan
    lost_rev = df["–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞"].sum() if "–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞" in df.columns else np.nan
    sku_count = (df["–ê—Ä—Ç–∏–∫—É–ª"].nunique() if "–ê—Ä—Ç–∏–∫—É–ª" in df.columns else len(df)) if len(df) > 0 else 0
    rev_per_sku = (total_rev / sku_count) if (isinstance(total_rev, (int,float,np.floating)) and not pd.isna(total_rev) and sku_count > 0) else np.nan
    k1, k2, k3, k4, k5 = st.columns(5)
    k1.metric("–í—ã—Ä—É—á–∫–∞ (–≤ –≤—ã–±–æ—Ä–∫–µ)", fmt_rub(total_rev))
    k2.metric("–ó–∞–∫–∞–∑—ã (–≤ –≤—ã–±–æ—Ä–∫–µ)", fmt_units(total_orders, "—à—Ç."))
    k3.metric("–°—Ä–µ–¥–Ω–∏–π —á–µ–∫", fmt_rub(avg_check))
    k4.metric("–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞", fmt_rub(lost_rev))
    k5.metric("–í—ã—Ä—É—á–∫–∞ / –ö–æ–ª-–≤–æ —Ç–æ–≤–∞—Ä–æ–≤", fmt_rub(rev_per_sku))

# --- UI (—É—Ä–µ–∑–∞–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä, –∫–ª—é—á–µ–≤—ã–µ –º–µ—Å—Ç–∞ —Å –ø—Ä–∏–±—ã–ª—å –∏ –º–∏–Ω–∏–∞—Ç—é—Ä–∞–º–∏) ---
with st.sidebar.expander("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞", expanded=True):
    uploaded = st.file_uploader("Excel/CSV —Å —Ç–æ–≤–∞—Ä–∞–º–∏", type=["xlsx","xls","csv"])
with st.sidebar.expander("–°–∫—Ä–∏–Ω—à–æ—Ç—ã —Å—Ç—Ä–∞–Ω–∏—Ü (s-shot.ru)", expanded=True):
    sc_key = st.text_input("–ö–ª—é—á s-shot", value="")
    sc_base = st.text_input("–ë–∞–∑–æ–≤—ã–π URL", value="https://api.s-shot.ru")
    sc_host = st.text_input("–î–æ–º–µ–Ω –∫–∞—Ä—Ç–æ—á–∫–∏ WB", value="https://global.wildberries.ru")
    sc_w = st.number_input("–®–∏—Ä–∏–Ω–∞", 100, 2000, 400, 10)
    sc_h = st.number_input("–í—ã—Å–æ—Ç–∞", 100, 2000, 600, 10)
    sc_fmt = st.selectbox("–§–æ—Ä–º–∞—Ç", ["JPEG","PNG"], 0)
    sc_profile = st.text_input("–ü—Ä–æ—Ñ–∏–ª—å", value="D4")

if uploaded is None:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏.")
else:
    df, raw, meta = read_table(uploaded.read(), uploaded.name)
    if df is None or df.empty:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É.")
    else:
        st.title("üìä –î–∞—à–±–æ—Ä–¥ (—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä)")
        cols = st.columns([1,1,1,1,1,1])
        search = cols[0].text_input("–ü–æ–∏—Å–∫")
        spp = cols[2].number_input("–°–ü–ü, %", 0, 100, 25, 1)
        buyout_pct = cols[3].number_input("–ü—Ä–æ—Ü–µ–Ω—Ç –≤—ã–∫—É–ø–∞, %", 1, 100, 25, 1)
        show_images = cols[4].checkbox("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å ¬´–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ¬ª", value=False)
        html_mode = cols[5].checkbox("HTML-—Ç–∞–±–ª–∏—Ü–∞", value=False)
        fdf = df.copy()
        if "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞" in fdf.columns:
            fdf["–¶–µ–Ω–∞ (—Å –°–ü–ü)"] = fdf["–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞"] * (1 - float(spp)/100.0)
        buyout_k = float(buyout_pct)/100.0 if buyout_pct else 0.0
        if "–ó–∞–∫–∞–∑—ã" in fdf.columns:
            fdf["–í—ã–∫—É–ø—ã"] = pd.to_numeric(fdf["–ó–∞–∫–∞–∑—ã"], errors="coerce") * buyout_k
        else:
            fdf["–í—ã–∫—É–ø—ã"] = np.nan
        # === FIX: –ü—Ä–∏–±—ã–ª—å = –í—ã—Ä—É—á–∫–∞ * (–ø—Ä–æ—Ü–µ–Ω—Ç –≤—ã–∫—É–ø–∞) ===
        if "–í—ã—Ä—É—á–∫–∞" in fdf.columns and buyout_k > 0:
            fdf["–ü—Ä–∏–±—ã–ª—å"] = pd.to_numeric(fdf["–í—ã—Ä—É—á–∫–∞"], errors="coerce") * buyout_k
        else:
            fdf["–ü—Ä–∏–±—ã–ª—å"] = np.nan
        kpi_row(fdf)
        st.divider()
        # –ú–∏–Ω–∏–∞—Ç—é—Ä—ã –∫—ç—à
        url_cache = get_url_cache()
        if show_images and "–ê—Ä—Ç–∏–∫—É–ª" in fdf.columns:
            imgs = []
            for a in fdf["–ê—Ä—Ç–∏–∫—É–ª"].astype(str):
                k = a.replace(".0","")
                url = url_cache.get(k, "")
                if not url and sc_key:
                    url = screenshot_for_article(k, {"key": sc_key,"w": sc_w,"h": sc_h,"fmt": sc_fmt,"profile": sc_profile,"base": sc_base,"wb_host": sc_host})
                    if url:
                        url_cache[k] = url
                        save_url_cache(url_cache)
                path = get_cached_image_path(k) or (ensure_image_cached(k, url, sc_fmt) if url else "")
                imgs.append(load_image_bytes(path, 140) if path else b"")
            fdf.insert(1, "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", imgs)

        money_cols = ["–í—ã—Ä—É—á–∫–∞","–ü—Ä–∏–±—ã–ª—å","–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞","–¶–µ–Ω–∞ (–¥–æ –°–ü–ü)","–¶–µ–Ω–∞ (—Å –°–ü–ü)"]
        for col in money_cols:
            if col in fdf.columns:
                fdf[col] = fdf[col].apply(fmt_rub)
        if "–ó–∞–∫–∞–∑—ã" in fdf.columns:
            fdf["–ó–∞–∫–∞–∑—ã"] = fdf["–ó–∞–∫–∞–∑—ã"].apply(lambda x: fmt_units(x, "—à—Ç."))
        if "–í—ã–∫—É–ø—ã" in fdf.columns:
            fdf["–í—ã–∫—É–ø—ã"] = fdf["–í—ã–∫—É–ø—ã"].apply(lambda x: fmt_units(x, "—à—Ç."))

        from streamlit import column_config as cc
        col_cfg = {}
        if "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ" in fdf.columns:
            col_cfg["–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"] = cc.ImageColumn(width=140)
        st.dataframe(fdf, use_container_width=True, hide_index=True, column_config=col_cfg)

# end of file
